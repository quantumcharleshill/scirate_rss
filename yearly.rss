<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>Quantum computing 40 years later</title>
    <link>http://arxiv.org/pdf/2106.10522</link>
    <author>John Preskill</author>
    <pubDate>Jun 22 2021</pubDate>
    <description>Forty years ago, Richard Feynman proposed harnessing quantum physics to build a more powerful kind of computer. Realizing Feynman's vision is one of the grand challenges facing 21st century science and technology. In this article, we'll recall Feynman's contribution that launched the quest for a quantum computer, and assess where the field stands 40 years later.</description>
  </item>

  <item>
    <title>A Grand Unification of Quantum Algorithms</title>
    <link>http://arxiv.org/pdf/2105.02859</link>
    <author>John M. Martyn, Zane M. Rossi, Andrew K. Tan, Isaac L. Chuang</author>
    <pubDate>May 07 2021</pubDate>
    <description>Quantum algorithms offer significant speedups over their classical counterparts for a variety of problems. The strongest arguments for this advantage are borne by algorithms for quantum search, quantum phase estimation, and Hamiltonian simulation, which appear as subroutines for large families of composite quantum algorithms. A number of these quantum algorithms were recently tied together by a novel technique known as the quantum singular value transformation (QSVT), which enables one to perform a polynomial transformation of the singular values of a linear operator embedded in a unitary matrix. In the seminal GSLW'19 paper on QSVT [Gily√©n, Su, Low, and Wiebe, ACM STOC 2019], many algorithms are encompassed, including amplitude amplification, methods for the quantum linear systems problem, and quantum simulation. Here, we provide a pedagogical tutorial through these developments, first illustrating how quantum signal processing may be generalized to the quantum eigenvalue transform, from which QSVT naturally emerges. Paralleling GSLW'19, we then employ QSVT to construct intuitive quantum algorithms for search, phase estimation, and Hamiltonian simulation, and also showcase algorithms for the eigenvalue threshold problem and matrix inversion. This overview illustrates how QSVT is a single framework comprising the three major quantum algorithms, thus suggesting a grand unification of quantum algorithms.</description>
  </item>

  <item>
    <title>Provably efficient machine learning for quantum many-body problems</title>
    <link>http://arxiv.org/pdf/2106.12627</link>
    <author>Hsin-Yuan Huang, Richard Kueng, Giacomo Torlai, Victor V. Albert, John Preskill</author>
    <pubDate>Jun 25 2021</pubDate>
    <description>Classical machine learning (ML) provides a potentially powerful approach to solving challenging quantum many-body problems in physics and chemistry. However, the advantages of ML over more traditional methods have not been firmly established. In this work, we prove that classical ML algorithms can efficiently predict ground state properties of gapped Hamiltonians in finite spatial dimensions, after learning from data obtained by measuring other Hamiltonians in the same quantum phase of matter. In contrast, under widely accepted complexity theory assumptions, classical algorithms that do not learn from data cannot achieve the same guarantee. We also prove that classical ML algorithms can efficiently classify a wide range of quantum phases of matter. Our arguments are based on the concept of a classical shadow, a succinct classical description of a many-body quantum state that can be constructed in feasible quantum experiments and be used to predict many properties of the state. Extensive numerical experiments corroborate our theoretical results in a variety of scenarios, including Rydberg atom systems, 2D random Heisenberg models, symmetry-protected topological phases, and topologically ordered phases.</description>
  </item>

  <item>
    <title>Linear growth of quantum circuit complexity</title>
    <link>http://arxiv.org/pdf/2106.05305</link>
    <author>Jonas Haferkamp, Philippe Faist, Naga B. T. Kothakonda, Jens Eisert, Nicole Yunger Halpern</author>
    <pubDate>Jun 11 2021</pubDate>
    <description>Quantifying quantum states' complexity is a key problem in various subfields of science, from quantum computing to black-hole physics. We prove a prominent conjecture by Brown and Susskind about how random quantum circuits' complexity increases. Consider constructing a unitary from Haar-random two-qubit quantum gates. Implementing the unitary exactly requires a circuit of some minimal number of gates - the unitary's exact circuit complexity. We prove that this complexity grows linearly with the number of random gates, with unit probability, until saturating after exponentially many random gates. Our proof is surprisingly short, given the established difficulty of lower-bounding the exact circuit complexity. Our strategy combines differential topology and elementary algebraic geometry with an inductive construction of Clifford circuits.</description>
  </item>

  <item>
    <title>Efficient estimation of Pauli observables by derandomization</title>
    <link>http://arxiv.org/pdf/2103.07510</link>
    <author>Hsin-Yuan Huang, Richard Kueng, John Preskill</author>
    <pubDate>Mar 16 2021</pubDate>
    <description>We consider the problem of jointly estimating expectation values of many Pauli observables, a crucial subroutine in variational quantum algorithms. Starting with randomized measurements, we propose an efficient derandomization procedure that iteratively replaces random single-qubit measurements with fixed Pauli measurements; the resulting deterministic measurement procedure is guaranteed to perform at least as well as the randomized one. In particular, for estimating any $L$ low-weight Pauli observables, a deterministic measurement on only of order $\log(L)$ copies of a quantum state suffices. In some cases, for example when some of the Pauli observables have a high weight, the derandomized procedure is substantially better than the randomized one. Specifically, numerical experiments highlight the advantages of our derandomized protocol over various previous methods for estimating the ground-state energies of small molecules.</description>
  </item>

  <item>
    <title>Quantum advantage in learning from experiments</title>
    <link>http://arxiv.org/pdf/2112.00778</link>
    <author>Hsin-Yuan Huang, Michael Broughton, Jordan Cotler, Sitan Chen, Jerry Li, Masoud Mohseni, Hartmut Neven, Ryan Babbush, Richard Kueng, John Preskill, Jarrod R. McClean</author>
    <pubDate>Dec 03 2021</pubDate>
    <description>Quantum technology has the potential to revolutionize how we acquire and process experimental data to learn about the physical world. An experimental setup that transduces data from a physical system to a stable quantum memory, and processes that data using a quantum computer, could have significant advantages over conventional experiments in which the physical system is measured and the outcomes are processed using a classical computer. We prove that, in various tasks, quantum machines can learn from exponentially fewer experiments than those required in conventional experiments. The exponential advantage holds in predicting properties of physical systems, performing quantum principal component analysis on noisy states, and learning approximate models of physical dynamics. In some tasks, the quantum processing needed to achieve the exponential advantage can be modest; for example, one can simultaneously learn about many noncommuting observables by processing only two copies of the system. Conducting experiments with up to 40 superconducting qubits and 1300 quantum gates, we demonstrate that a substantial quantum advantage can be realized using today's relatively noisy quantum processors. Our results highlight how quantum technology can enable powerful new strategies to learn about nature.</description>
  </item>

  <item>
    <title>On the complexity of quantum partition functions</title>
    <link>http://arxiv.org/pdf/2110.15466</link>
    <author>Sergey Bravyi, Anirban Chowdhury, David Gosset, Pawel Wocjan</author>
    <pubDate>Nov 01 2021</pubDate>
    <description>The partition function and free energy of a quantum many-body system determine its physical properties in thermal equilibrium. Here we study the computational complexity of approximating these quantities for $n$-qubit local Hamiltonians. First, we report a classical algorithm with $\mathrm{poly}(n)$ runtime which approximates the free energy of a given $2$-local Hamiltonian provided that it satisfies a certain denseness condition. Our algorithm combines the variational characterization of the free energy and convex relaxation methods. It contributes to a body of work on efficient approximation algorithms for dense instances of optimization problems which are hard in the general case, and can be viewed as simultaneously extending existing algorithms for (a) the ground energy of dense $2$-local Hamiltonians, and (b) the free energy of dense classical Ising models. Secondly, we establish polynomial-time equivalence between the problem of approximating the free energy of local Hamiltonians and three other natural quantum approximate counting problems, including the problem of approximating the number of witness states accepted by a QMA verifier. These results suggest that simulation of quantum many-body systems in thermal equilibrium may precisely capture the complexity of a broad family of computational problems that has yet to be defined or characterized in terms of known complexity classes. Finally, we summarize state-of-the-art classical and quantum algorithms for approximating the free energy and show how to improve their runtime and memory footprint.</description>
  </item>

  <item>
    <title>Asymptotically Good Quantum and Locally Testable Classical LDPC Codes</title>
    <link>http://arxiv.org/pdf/2111.03654</link>
    <author>Pavel Panteleev, Gleb Kalachev</author>
    <pubDate>Nov 08 2021</pubDate>
    <description>We study classical and quantum LDPC codes of constant rate obtained by the lifted product construction over non-abelian groups. We show that the obtained families of quantum LDPC codes are asymptotically good, which proves the qLDPC conjecture. Moreover, we show that the produced classical LDPC codes are also asymptotically good and locally testable with constant query and soundness parameters, which proves a well-known conjecture in the field of locally testable codes.</description>
  </item>

  <item>
    <title>How to simulate quantum measurement without computing marginals</title>
    <link>http://arxiv.org/pdf/2112.08499</link>
    <author>Sergey Bravyi, David Gosset, Yinchen Liu</author>
    <pubDate>Dec 17 2021</pubDate>
    <description>We describe and analyze algorithms for classically simulating measurement of an $n$-qubit quantum state $\psi$ in the standard basis, that is, sampling a bit string $x$ from the probability distribution $|\langle x|\psi\rangle|^2$. Our algorithms reduce the sampling task to computing poly$(n)$ amplitudes of $n$-qubit states; unlike previously known techniques they do not require computation of marginal probabilities. First we consider the case where $|\psi\rangle=U|0^n\rangle$ is the output state of an $m$-gate quantum circuit $U$. We propose an exact sampling algorithm which involves computing $O(m)$ amplitudes of $n$-qubit states generated by subcircuits of $U$ spanned by the first $t=1,2,\ldots,m$ gates. We show that our algorithm can significantly accelerate quantum circuit simulations based on tensor network contraction methods or low-rank stabilizer decompositions. As another striking consequence we obtain an efficient classical simulation algorithm for measurement-based quantum computation with the surface code resource state on any planar graph, generalizing a previous algorithm which was known to be efficient only under restrictive topological constraints on the ordering of single-qubit measurements. Second, we consider the case in which $\psi$ is the unique ground state of a local Hamiltonian with a spectral gap that is lower bounded by an inverse polynomial function of $n$. We prove that a simple Metropolis-Hastings Markov Chain mixes rapidly to the desired probability distribution provided that $\psi$ obeys a certain technical condition, which we show is satisfied for all sign-problem free Hamiltonians. This gives a sampling algorithm which involves computing $\mathrm{poly}(n)$ amplitudes of $\psi$.</description>
  </item>

  <item>
    <title>Dequantizing the Quantum Singular Value Transformation: Hardness and Applications to Quantum Chemistry and the Quantum PCP Conjecture</title>
    <link>http://arxiv.org/pdf/2111.09079</link>
    <author>Sevag Gharibian, Fran√ßois Le Gall</author>
    <pubDate>Nov 18 2021</pubDate>
    <description>The Quantum Singular Value Transformation (QSVT) is a recent technique that gives a unified framework to describe most quantum algorithms discovered so far, and may lead to the development of novel quantum algorithms. In this paper we investigate the hardness of classically simulating the QSVT. A recent result by Chia, Gily√©n, Li, Lin, Tang and Wang (STOC 2020) showed that the QSVT can be efficiently "dequantized" for low-rank matrices, and discussed its implication to quantum machine learning. In this work, motivated by establishing the superiority of quantum algorithms for quantum chemistry and making progress on the quantum PCP conjecture, we focus on the other main class of matrices considered in applications of the QSVT, sparse matrices. We first show how to efficiently "dequantize", with arbitrarily small constant precision, the QSVT associated with a low-degree polynomial. We apply this technique to design classical algorithms that estimate, with constant precision, the singular values of a sparse matrix. We show in particular that a central computational problem considered by quantum algorithms for quantum chemistry (estimating the ground state energy of a local Hamiltonian when given, as an additional input, a state sufficiently close to the ground state) can be solved efficiently with constant precision on a classical computer. As a complementary result, we prove that with inverse-polynomial precision, the same problem becomes BQP-complete. This gives theoretical evidence for the superiority of quantum algorithms for chemistry, and strongly suggests that said superiority stems from the improved precision achievable in the quantum setting. We also discuss how this dequantization technique may help make progress on the central quantum PCP conjecture.</description>
  </item>

  <item>
    <title>Solving the sampling problem of the Sycamore quantum supremacy circuits</title>
    <link>http://arxiv.org/pdf/2111.03011</link>
    <author>Feng Pan, Keyang Chen, Pan Zhang</author>
    <pubDate>Nov 05 2021</pubDate>
    <description>We study the problem of generating independent samples from the output distribution of Google's Sycamore quantum circuits with a target fidelity, which is believed to be beyond the reach of classical supercomputers and has been used to demonstrate quantum supremacy. We propose a new method to classically solve this problem by contracting the corresponding tensor network just once, and is massively more efficient than existing methods in obtaining a large number of uncorrelated samples with a target fidelity. For the Sycamore quantum supremacy circuit with $53$ qubits and $20$ cycles, we have generated one million uncorrelated bitstrings $\{\mathbf s\}$ which are sampled from a distribution $\widehat P(\mathbf s)=|\widehat \psi(\mathbf s)|^2$, where the approximate state $\widehat \psi$ has fidelity $F\approx 0.0037$. The whole computation has cost about $15$ hours on a computational cluster with $512$ GPUs. The obtained one million samples, the contraction code and contraction order are made public. If our algorithm could be implemented with high efficiency on a modern supercomputer with ExaFLOPS performance, we estimate that ideally, the simulation would cost a few dozens of seconds, which is faster than Google's quantum hardware.</description>
  </item>

  <item>
    <title>Averaged circuit eigenvalue sampling</title>
    <link>http://arxiv.org/pdf/2108.05803</link>
    <author>Steven T. Flammia</author>
    <pubDate>Aug 13 2021</pubDate>
    <description>We introduce ACES, a method for scalable noise metrology of quantum circuits that stands for Averaged Circuit Eigenvalue Sampling. It simultaneously estimates the individual error rates of all the gates in collections of quantum circuits, and can even account for space and time correlations between these gates. ACES strictly generalizes randomized benchmarking (RB), interleaved RB, simultaneous RB, and several other related techniques. However, ACES provides much more information and provably works under strictly weaker assumptions than these techniques. Finally, ACES is extremely scalable: we demonstrate with numerical simulations that it simultaneously and precisely estimates all the Pauli error rates on every gate and measurement in a 100 qubit quantum device using fewer than 20 relatively shallow Clifford circuits and an experimentally feasible number of samples. By learning the detailed gate errors for large quantum devices, ACES opens new possibilities for error mitigation, bespoke quantum error correcting codes and decoders, customized compilers, and more.</description>
  </item>

  <item>
    <title>Lecture Notes on Quantum Algorithms for Scientific Computation</title>
    <link>http://arxiv.org/pdf/2201.08309</link>
    <author>Lin Lin</author>
    <pubDate>Jan 21 2022</pubDate>
    <description>This is a set of lecture notes used in a graduate topic class in applied mathematics called ``Quantum Algorithms for Scientific Computation'' at the Department of Mathematics, UC Berkeley during the fall semester of 2021. These lecture notes focus only on quantum algorithms closely related to scientific computation, and in particular, matrix computation. The main purpose of the lecture notes is to introduce quantum phase estimation (QPE) and ``post-QPE'' methods such as block encoding, quantum signal processing, and quantum singular value transformation, and to demonstrate their applications in solving eigenvalue problems, linear systems of equations, and differential equations. The intended audience is the broad computational science and engineering (CSE) community interested in using fault-tolerant quantum computers to solve challenging scientific computing problems.</description>
  </item>

  <item>
    <title>Dynamically Generated Logical Qubits</title>
    <link>http://arxiv.org/pdf/2107.02194</link>
    <author>Matthew B. Hastings, Jeongwan Haah</author>
    <pubDate>Jul 07 2021</pubDate>
    <description>We present a quantum error correcting code with dynamically generated logical qubits. When viewed as a subsystem code, the code has no logical qubits. Nevertheless, our measurement patterns generate logical qubits, allowing the code to act as a fault-tolerant quantum memory. Our particular code gives a model very similar to the two-dimensional toric code, but each measurement is a two-qubit Pauli measurement.</description>
  </item>

  <item>
    <title>Quantum Low-Density Parity-Check Codes</title>
    <link>http://arxiv.org/pdf/2103.06309</link>
    <author>Nikolas P. Breuckmann, Jens Niklas Eberhardt</author>
    <pubDate>Mar 12 2021</pubDate>
    <description>Quantum error correction is an indispensable ingredient for scalable quantum computing. In this Perspective we discuss a particular class of quantum codes called low-density parity-check (LDPC) quantum codes. The codes we discuss are alternatives to the surface code, which is the currently leading candidate to implement quantum fault-tolerance. We introduce the zoo of LDPC quantum codes and discuss their potential for making quantum computers robust against noise. In particular, we explain recent advances in the theory of LDPC quantum codes related to certain product constructions and discuss open problems in the field.</description>
  </item>

  <item>
    <title>Improved upper bounds on the stabilizer rank of magic states</title>
    <link>http://arxiv.org/pdf/2106.07740</link>
    <author>Hammam Qassim, Hakop Pashayan, David Gosset</author>
    <pubDate>Jun 16 2021</pubDate>
    <description>In this work we improve the runtime of recent classical algorithms for strong simulation of quantum circuits composed of Clifford and T gates. The improvement is obtained by establishing a new upper bound on the stabilizer rank of $m$ copies of the magic state $|T\rangle=\sqrt{2}^{-1}(|0\rangle+e^{i\pi/4}|1\rangle)$ in the limit of large $m$. In particular, we show that $|T\rangle^{\otimes m}$ can be exactly expressed as a superposition of at most $O(2^{\alpha m})$ stabilizer states, where $\alpha\leq 0.3963$, improving on the best previously known bound $\alpha \leq 0.463$. This furnishes, via known techniques, a classical algorithm which approximates output probabilities of an $n$-qubit Clifford + T circuit $U$ with $m$ uses of the T gate to within a given inverse polynomial relative error using a runtime $\mathrm{poly}(n,m)2^{\alpha m}$. We also provide improved upper bounds on the stabilizer rank of symmetric product states $|\psi\rangle^{\otimes m}$ more generally; as a consequence we obtain a strong simulation algorithm for circuits consisting of Clifford gates and $m$ instances of any (fixed) single-qubit $Z$-rotation gate with runtime $\text{poly}(n,m) 2^{m/2}$. We suggest a method to further improve the upper bounds by constructing linear codes with certain properties.</description>
  </item>

  <item>
    <title>Revisiting dequantization and quantum advantage in learning tasks</title>
    <link>http://arxiv.org/pdf/2112.00811</link>
    <author>Jordan Cotler, Hsin-Yuan Huang, Jarrod R. McClean</author>
    <pubDate>Dec 03 2021</pubDate>
    <description>It has been shown that the apparent advantage of some quantum machine learning algorithms may be efficiently replicated using classical algorithms with suitable data access -- a process known as dequantization. Existing works on dequantization compare quantum algorithms which take copies of an n-qubit quantum state $|x\rangle = \sum_{i} x_i |i\rangle$ as input to classical algorithms which have sample and query (SQ) access to the vector $x$. In this note, we prove that classical algorithms with SQ access can accomplish some learning tasks exponentially faster than quantum algorithms with quantum state inputs. Because classical algorithms are a subset of quantum algorithms, this demonstrates that SQ access can sometimes be significantly more powerful than quantum state inputs. Our findings suggest that the absence of exponential quantum advantage in some learning tasks may be due to SQ access being too powerful relative to quantum state inputs. If we compare quantum algorithms with quantum state inputs to classical algorithms with access to measurement data on quantum states, the landscape of quantum advantage can be dramatically different. We remark that when the quantum states are constructed from exponential-size classical data, comparing SQ access and quantum state inputs is appropriate since both require exponential time to prepare.</description>
  </item>

  <item>
    <title>Demonstration of fault-tolerant universal quantum gate operations</title>
    <link>http://arxiv.org/pdf/2111.12654</link>
    <author>Lukas Postler, Sascha Heu√üen, Ivan Pogorelov, Manuel Rispler, Thomas Feldker, Michael Meth, Christian D. Marciniak, Roman Stricker, Martin Ringbauer, Rainer Blatt, Philipp Schindler, Markus M√ºller, Thomas Monz</author>
    <pubDate>Nov 25 2021</pubDate>
    <description>Quantum computers can be protected from noise by encoding the logical quantum information redundantly into multiple qubits using error correcting codes. When manipulating the logical quantum states, it is imperative that errors caused by imperfect operations do not spread uncontrollably through the quantum register. This requires that all operations on the quantum register obey a fault-tolerant circuit design which, in general, increases the complexity of the implementation. Here, we demonstrate a fault-tolerant universal set of gates on two logical qubits in a trapped-ion quantum computer. In particular, we make use of the recently introduced paradigm of flag fault tolerance, where the absence or presence of dangerous errors is heralded by usage of few ancillary 'flag' qubits. We perform a logical two-qubit CNOT-gate between two instances of the seven qubit color code, and we also fault-tolerantly prepare a logical magic state. We then realize a fault-tolerant logical T-gate by injecting the magic state via teleportation from one logical qubit onto the other. We observe the hallmark feature of fault tolerance, a superior performance compared to a non-fault-tolerant implementation. In combination with recently demonstrated repeated quantum error correction cycles these results open the door to error-corrected universal quantum computation.</description>
  </item>

  <item>
    <title>Efficient Universal Quantum Compilation: An Inverse-free Solovay-Kitaev Algorithm</title>
    <link>http://arxiv.org/pdf/2112.02040</link>
    <author>Adam Bouland, Tudor Giurgica-Tiron</author>
    <pubDate>Dec 06 2021</pubDate>
    <description>The Solovay-Kitaev algorithm is a fundamental result in quantum computation. It gives an algorithm for efficiently compiling arbitrary unitaries using universal gate sets: any unitary can be approximated by short gates sequences, whose length scales merely poly-logarithmically with accuracy. As a consequence, the choice of gate set is typically unimportant in quantum computing. However, the Solovay-Kitaev algorithm requires the gate set to be inverse-closed. It has been a longstanding open question if efficient algorithmic compilation is possible without this condition. In this work, we provide the first inverse-free Solovay-Kitaev algorithm, which makes no assumption on the structure within a gate set beyond universality, answering this problem in the affirmative, and providing an efficient compilation algorithm in the absence of inverses for both $\text{SU}(d)$ and $\text{SL}(d, \mathbb{C})$. The algorithm works by showing that approximate gate implementations of the generalized Pauli group can self-correct their errors.</description>
  </item>

  <item>
    <title>Strong quantum computational advantage using a superconducting quantum processor</title>
    <link>http://arxiv.org/pdf/2106.14734</link>
    <author>Yulin Wu, Wan-Su Bao, Sirui Cao, Fusheng Chen, Ming-Cheng Chen, Xiawei Chen, Tung-Hsun Chung, Hui Deng, Yajie Du, Daojin Fan, Ming Gong, Cheng Guo, Chu Guo, Shaojun Guo, Lianchen Han, Linyin Hong, He-Liang Huang, Yong-Heng Huo, Liping Li, Na Li, et al (34)</author>
    <pubDate>Jun 29 2021</pubDate>
    <description>Scaling up to a large number of qubits with high-precision control is essential in the demonstrations of quantum computational advantage to exponentially outpace the classical hardware and algorithmic improvements. Here, we develop a two-dimensional programmable superconducting quantum processor, \textitZuchongzhi, which is composed of 66 functional qubits in a tunable coupling architecture. To characterize the performance of the whole system, we perform random quantum circuits sampling for benchmarking, up to a system size of 56 qubits and 20 cycles. The computational cost of the classical simulation of this task is estimated to be 2-3 orders of magnitude higher than the previous work on 53-qubit Sycamore processor [Nature \textbf574, 505 (2019)]. We estimate that the sampling task finished by \textitZuchongzhi in about 1.2 hours will take the most powerful supercomputer at least 8 years. Our work establishes an unambiguous quantum computational advantage that is infeasible for classical computation in a reasonable amount of time. The high-precision and programmable quantum computing platform opens a new door to explore novel many-body phenomena and implement complex quantum algorithms.</description>
  </item>

  <item>
    <title>Random quantum circuits transform local noise into global white noise</title>
    <link>http://arxiv.org/pdf/2111.14907</link>
    <author>Alexander M. Dalzell, Nicholas Hunter-Jones, Fernando G. S. L. Brand√£o</author>
    <pubDate>Dec 01 2021</pubDate>
    <description>We study the distribution over measurement outcomes of noisy random quantum circuits in the low-fidelity regime. We show that, for local noise that is sufficiently weak and unital, correlations (measured by the linear cross-entropy benchmark) between the output distribution $p_{\text{noisy}}$ of a generic noisy circuit instance and the output distribution $p_{\text{ideal}}$ of the corresponding noiseless instance shrink exponentially with the expected number of gate-level errors, as $F=\text{exp}(-2s\epsilon \pm O(s\epsilon^2))$, where $\epsilon$ is the probability of error per circuit location and $s$ is the number of two-qubit gates. Furthermore, if the noise is incoherent, the output distribution approaches the uniform distribution $p_{\text{unif}}$ at precisely the same rate and can be approximated as $p_{\text{noisy}} \approx Fp_{\text{ideal}} + (1-F)p_{\text{unif}}$, that is, local errors are scrambled by the random quantum circuit and contribute only white noise (uniform output). Importantly, we upper bound the total variation error (averaged over random circuit instance) in this approximation as $O(F\epsilon \sqrt{s})$, so the "white-noise approximation" is meaningful when $\epsilon \sqrt{s} \ll 1$, a quadratically weaker condition than the $\epsilon s\ll 1$ requirement to maintain high fidelity. The bound applies when the circuit size satisfies $s \geq \Omega(n\log(n))$ and the inverse error rate satisfies $\epsilon^{-1} \geq \tilde{\Omega}(n)$. The white-noise approximation is useful for salvaging the signal from a noisy quantum computation; it was an underlying assumption in complexity-theoretic arguments that low-fidelity random quantum circuits cannot be efficiently sampled classically. Our method is based on a map from second-moment quantities in random quantum circuits to expectation values of certain stochastic processes for which we compute upper and lower bounds.</description>
  </item>

  <item>
    <title>A randomized quantum algorithm for statistical phase estimation</title>
    <link>http://arxiv.org/pdf/2110.12071</link>
    <author>Kianna Wan, Mario Berta, Earl T. Campbell</author>
    <pubDate>Oct 26 2021</pubDate>
    <description>Phase estimation is a quantum algorithm for measuring the eigenvalues of a Hamiltonian. We propose and rigorously analyse a randomized phase estimation algorithm with two distinctive features. First, our algorithm has complexity independent of the number of terms L in the Hamiltonian. Second, unlike previous L-independent approaches, such as those based on qDRIFT, all sources of error in our algorithm can be suppressed by collecting more data samples, without increasing the circuit depth.</description>
  </item>

  <item>
    <title>Fundamental limits of quantum error mitigation</title>
    <link>http://arxiv.org/pdf/2109.04457</link>
    <author>Ryuji Takagi, Suguru Endo, Shintaro Minagawa, Mile Gu</author>
    <pubDate>Sep 10 2021</pubDate>
    <description>The inevitable accumulation of errors in near-future quantum devices represents a key obstacle in delivering practical quantum advantages. Yet, such quantum devices are often unable to perform adaptive quantum operations, disallowing quantum error correction. These constraints motivated the development of various quantum error-mitigation methods, each presenting a technique to improve the accuracy of our computation by repeated sampling of various pre-configured circuits. What are the performance limits imposed on such protocols? Here we derive fundamental bounds concerning how such algorithms can reduce the computation error as a function of their extra sampling overhead. We use it to show that (1) the sampling overhead that ensures a certain computational accuracy in mitigating local depolarizing noise for layered circuits -- such as the ones used for variational quantum algorithms -- scales exponentially with the circuit depth for general error-mitigation protocols, and (2) the optimality of probabilistic error cancellation among a wide class of strategies in mitigating a single-qubit dephasing noise. Our results provide a means to identify when a given quantum error-mitigation strategy is optimal and when there is potential room for improvement.</description>
  </item>

  <item>
    <title>Entangling power and quantum circuit complexity</title>
    <link>http://arxiv.org/pdf/2104.03332</link>
    <author>J. Eisert</author>
    <pubDate>Apr 09 2021</pubDate>
    <description>Notions of circuit complexity and cost play a key role in quantum computing and simulation where they capture the (weighted) minimal number of gates that is required to implement a unitary. Similar notions also become increasingly prominent in high energy physics in the study of holography. While notions of entanglement have in general little implications for the quantum circuit complexity and the cost of a unitary, in this note, we discuss a simple such relationship when both the entanglement of a state and the cost of a unitary take small values, building on ideas on how values of entangling power of quantum gates add up. This bound implies that if entanglement entropies grow linearly in time, so does the cost. The implications are two-fold: It provides insights into complexity growth for short times. In the context of quantum simulation, it allows to compare digital and analog quantum simulators. The main technical contribution is a continuous-variable small incremental entangling bound.</description>
  </item>

  <item>
    <title>Open Problems Related to Quantum Query Complexity</title>
    <link>http://arxiv.org/pdf/2109.06917</link>
    <author>Scott Aaronson</author>
    <pubDate>Sep 16 2021</pubDate>
    <description>I offer a case that quantum query complexity still has loads of enticing and fundamental open problems -- from relativized QMA versus QCMA and BQP versus IP, to time/space tradeoffs for collision and element distinctness, to polynomial degree versus quantum query complexity for partial functions, to the Unitary Synthesis Problem and more.</description>
  </item>

  <item>
    <title>Estimating gate-set properties from random sequences</title>
    <link>http://arxiv.org/pdf/2110.13178</link>
    <author>Jonas Helsen, Marios Ioannou, Ingo Roth, Jonas Kitzinger, Emilio Onorati, Albert H. Werner, Jens Eisert</author>
    <pubDate>Oct 27 2021</pubDate>
    <description>With quantum devices for computing and simulation increasing in scale and complexity, there is a growing need for the development of tools that obtain precise diagnostic information about quantum operations. In this work, we show that by measuring random gate sequences, one can accurately and efficiently estimate a wealth of different properties of noisy implementations of gate sets. This simple experimental protocol is independent of the properties one intends to estimate. It generates `sequence shadows' from which gate-set properties can be extracted, through classical post-processing, in a state preparation and measurement error robust way. The proposed classical post-processing schemes include protocols to extract many average gate fidelities with respect to arbitrary unitary channels. This - as a special case - emulates (interleaved) randomized benchmarking, but is vastly more general in its applicability. We establish that the sequence estimation scheme can be used as a primitive for partial, compressive and full process tomography, and the learning of Pauli noise. This gives rise to channel variants of shadow estimation with close-to optimal performance guarantees. Finally, we discuss applications to the engineering cycle for the optimization of quantum gates, for instance as a novel method to diagnose crosstalk.</description>
  </item>

  <item>
    <title>Learnability of the output distributions of local quantum circuits</title>
    <link>http://arxiv.org/pdf/2110.05517</link>
    <author>Marcel Hinsche, Marios Ioannou, Alexander Nietner, Jonas Haferkamp, Yihui Quek, Dominik Hangleiter, Jean-Pierre Seifert, Jens Eisert, Ryan Sweke</author>
    <pubDate>Oct 13 2021</pubDate>
    <description>There is currently a large interest in understanding the potential advantages quantum devices can offer for probabilistic modelling. In this work we investigate, within two different oracle models, the probably approximately correct (PAC) learnability of quantum circuit Born machines, i.e., the output distributions of local quantum circuits. We first show a negative result, namely, that the output distributions of super-logarithmic depth Clifford circuits are not sample-efficiently learnable in the statistical query model, i.e., when given query access to empirical expectation values of bounded functions over the sample space. This immediately implies the hardness, for both quantum and classical algorithms, of learning from statistical queries the output distributions of local quantum circuits using any gate set which includes the Clifford group. As many practical generative modelling algorithms use statistical queries -- including those for training quantum circuit Born machines -- our result is broadly applicable and strongly limits the possibility of a meaningful quantum advantage for learning the output distributions of local quantum circuits. As a positive result, we show that in a more powerful oracle model, namely when directly given access to samples, the output distributions of local Clifford circuits are computationally efficiently PAC learnable by a classical learner. Our results are equally applicable to the problems of learning an algorithm for generating samples from the target distribution (generative modelling) and learning an algorithm for evaluating its probabilities (density modelling). They provide the first rigorous insights into the learnability of output distributions of local quantum circuits from the probabilistic modelling perspective.</description>
  </item>

  <item>
    <title>A Note on the Second Spectral Gap Incompleteness Theorem</title>
    <link>http://arxiv.org/pdf/2105.09854</link>
    <author>Toby S. Cubitt</author>
    <pubDate>May 21 2021</pubDate>
    <description>Pick a formal system. Any formal system. Whatever your favourite formal system is, as long as it's capable of reasoning about elementary arithmetic. The First Spectral Gap Incompleteness Theorem of [CPGW15] proved that there exist Hamiltonians whose spectral gap is independent of that system; your formal system is incapable of proving that the Hamiltonian is gapped, and equally incapable of proving that it's gapless. In this note, I prove a Second Spectral Gap Incompleteness Theorem: I show how to explicitly construct, within the formal system, a concrete example of a Hamiltonian whose spectral gap is independent of that system. Just to be sure, I prove this result three times. Once with G√∂del's help. Once with Zermelo and Fraenkel's help. And finally, doing away with these high-powered friends, I give a simple, direct argument which reveals the inherent self-referential structure at the heart of these results, by asking the Hamiltonian about its own spectral gap.</description>
  </item>

  <item>
    <title>Clifford groups are not always 2-designs</title>
    <link>http://arxiv.org/pdf/2108.04200</link>
    <author>Matthew A. Graydon, Joshua Skanes-Norman, Joel J. Wallman</author>
    <pubDate>Aug 10 2021</pubDate>
    <description>The Clifford group is the quotient of the normalizer of the Weyl-Heisenberg group in dimension $d$ by its centre. We prove that when $d$ is not prime the Clifford group is not a group unitary $2$-design. Furthermore, we prove that the multipartite Clifford group is not a group unitary 2-design except for the known cases wherein the local Hilbert space dimensions are a constant prime number. We also clarify the structure of projective group unitary $2$-designs. We show that the adjoint action induced by a group unitary $2$-design decomposes into exactly two irreducible components; moreover, a group is a unitary 2-design if and only if the character of its so-called $U\overline{U}$ representation is $\sqrt{2}$.</description>
  </item>

  <item>
    <title>Low-overhead fault-tolerant quantum computing using long-range connectivity</title>
    <link>http://arxiv.org/pdf/2110.10794</link>
    <author>Lawrence Z. Cohen, Isaac H. Kim, Stephen D. Bartlett, Benjamin J. Brown</author>
    <pubDate>Oct 22 2021</pubDate>
    <description>Vast numbers of qubits will be needed for large-scale quantum computing using today's fault-tolerant architectures due to the overheads associated with quantum error correction. We present a scheme for low-overhead fault-tolerant quantum computation based on quantum low-density parity-check (LDPC) codes, where the capability of performing long-range entangling interactions allows a large number of logical qubits to be encoded with a modest number of physical qubits. In our approach, quantum logic gates operate via logical Pauli measurements that preserve both the protection of the LDPC codes as well as the low overheads in terms of required number of additional ancilla qubits. Compared with the surface code architecture, resource estimates for our scheme indicate order-of-magnitude improvements in the overheads for encoding and processing around one hundred logical qubits, meaning fault-tolerant quantum computation at this scale may be achievable with a few thousand physical qubits at achievable error rates.</description>
  </item>

  <item>
    <title>A genuinely natural information measure</title>
    <link>http://arxiv.org/pdf/2103.16662</link>
    <author>Andreas Winter</author>
    <pubDate>Apr 01 2021</pubDate>
    <description>The theoretical measuring of information was famously initiated by Shannon in his mathematical theory of communication, in which he proposed a now widely used quantity, the entropy, measured in bits. Yet, in the same paper, Shannon also chose to measure the information in continuous systems in nats, which differ from bits by the use of the natural rather than the binary logarithm. We point out that there is nothing natural about the choice of logarithm basis, rather it is arbitrary. We remedy this problematic state of affairs by proposing a genuinely natural measure of information, which we dub gnats. We show that gnats have many advantages in information theory, and propose to adopt the underlying methodology throughout science, arts and everyday life.</description>
  </item>

  <item>
    <title>Lifting decoders for classical codes to decoders for quantum codes</title>
    <link>http://arxiv.org/pdf/2105.02370</link>
    <author>Armanda O. Quintavalle, Earl T. Campbell</author>
    <pubDate>May 07 2021</pubDate>
    <description>The design of decoding algorithms is a significant technological component in the development of fault-tolerant quantum computers. Often design of quantum decoders is inspired by classical decoding algorithms, but there are no general principles for building quantum decoders from classical decoders. Given any pair of classical codes, we can build a quantum code using the hypergraph product, yielding a hypergraph product code. Here we show we can also lift the decoders for these classical codes. That is, given oracle access to a minimum weight decoder for the relevant classical codes, the corresponding $[[n,k,d]]$ quantum code can be efficiently decoded for any error of weight smaller than $(d-1)/2$. The quantum decoder requires only $O(k)$ oracle calls to the classical decoder and $O(n^2)$ classical resources. The lift and the correctness proof of the decoder have a purely algebraic nature that draws on the discovery of some novel homological invariants of the hypergraph product codespace. While the decoder works perfectly for adversarial errors, it is not suitable for more realistic stochastic noise models and therefore can not be used to establish an error correcting threshold.</description>
  </item>

  <item>
    <title>Limitations of Linear Cross-Entropy as a Measure for Quantum Advantage</title>
    <link>http://arxiv.org/pdf/2112.01657</link>
    <author>Xun Gao, Marcin Kalinowski, Chi-Ning Chou, Mikhail D. Lukin, Boaz Barak, Soonwon Choi</author>
    <pubDate>Dec 06 2021</pubDate>
    <description>Demonstrating quantum advantage requires experimental implementation of a computational task that is hard to achieve using state-of-the-art classical systems. One approach is to perform sampling from a probability distribution associated with a class of highly entangled many-body wavefunctions. It has been suggested that this approach can be certified with the Linear Cross-Entropy Benchmark (XEB). We critically examine this notion. First, in a "benign" setting where an honest implementation of noisy quantum circuits is assumed, we characterize the conditions under which the XEB approximates the fidelity. Second, in an "adversarial" setting where all possible classical algorithms are considered for comparison, we show that achieving relatively high XEB values does not imply faithful simulation of quantum dynamics. We present an efficient classical algorithm that, with 1 GPU within 2s, yields high XEB values, namely 2-12% of those obtained in experiments. By identifying and exploiting several vulnerabilities of the XEB, we achieve high XEB values without full simulation of quantum circuits. Remarkably, our algorithm features better scaling with the system size than noisy quantum devices for commonly studied random circuit ensembles. To quantitatively explain the success of our algorithm and the limitations of the XEB, we use a theoretical framework in which the average XEB and fidelity are mapped to statistical models. We illustrate the relation between the XEB and the fidelity for quantum circuits in various architectures, with different gate choices, and in the presence of noise. Our results show that XEB's utility as a proxy for fidelity hinges on several conditions, which must be checked in the benign setting but cannot be assumed in the adversarial setting. Thus, the XEB alone has limited utility as a benchmark for quantum advantage. We discuss ways to overcome these limitations.</description>
  </item>

  <item>
    <title>Permanent of random matrices from representation theory: moments, numerics, concentration, and comments on hardness of boson-sampling</title>
    <link>http://arxiv.org/pdf/2104.06423</link>
    <author>Sepehr Nezami</author>
    <pubDate>Apr 15 2021</pubDate>
    <description>Computing the distribution of permanents of random matrices has been an outstanding open problem for several decades. In quantum computing, "anti-concentration" of this distribution is an unproven input for the proof of hardness of the task of boson-sampling. We study permanents of random i.i.d. complex Gaussian matrices, and more broadly, submatrices of random unitary matrices. Using a hybrid representation-theoretic and combinatorial approach, we prove strong lower bounds for all moments of the permanent distribution. We provide substantial evidence that our bounds are close to being tight and constitute accurate estimates for the moments. Let $U(d)^{k\times k}$ be the distribution of $k\times k$ submatrices of $d\times d$ random unitary matrices, and $G^{k\times k}$ be the distribution of $k\times k$ complex Gaussian matrices. (1) Using the Schur-Weyl duality (or the Howe duality), we prove an expansion formula for the $2t$-th moment of $|Perm(M)|$ when $M$ is drawn from $U(d)^{k\times k}$ or $G^{k\times k}$. (2) We prove a surprising size-moment duality: the $2t$-th moment of the permanent of random $k\times k$ matrices is equal to the $2k$-th moment of the permanent of $t\times t$ matrices. (3) We design an algorithm to exactly compute high moments of the permanent of small matrices. (4) We prove lower bounds for arbitrary moments of permanents of matrices drawn from $G^{ k\times k}$ or $U(k)$, and conjecture that our lower bounds are close to saturation up to a small multiplicative error. (5) Assuming our conjectures, we use the large deviation theory to compute the tail of the distribution of log-permanent of Gaussian matrices for the first time. (6) We argue that it is unlikely that the permanent distribution can be uniquely determined from the integer moments and one may need to supplement the moment calculations with extra assumptions to prove the anti-concentration conjecture.</description>
  </item>

  <item>
    <title>Symmetry Protected Quantum Computation</title>
    <link>http://arxiv.org/pdf/2105.04649</link>
    <author>Michael H. Freedman, Matthew B. Hastings, Modjtaba Shokrian Zini</author>
    <pubDate>May 12 2021</pubDate>
    <description>We consider a model of quantum computation using qubits where it is possible to measure whether a given pair are in a singlet (total spin $0$) or triplet (total spin $1$) state. The physical motivation is that we can do these measurements in a way that is protected against revealing other information so long as all terms in the Hamiltonian are $SU(2)$-invariant. We conjecture that this model is equivalent to BQP. Towards this goal, we show: (1) this model is capable of universal quantum computation with polylogarithmic overhead if it is supplemented by single qubit $X$ and $Z$ gates. (2) Without any additional gates, it is at least as powerful as the weak model of "permutational quantum computation" of Jordan [14, 18]. (3) With postselection, the model is equivalent to PostBQP.</description>
  </item>

  <item>
    <title>Exponential separations between learning with and without quantum memory</title>
    <link>http://arxiv.org/pdf/2111.05881</link>
    <author>Sitan Chen, Jordan Cotler, Hsin-Yuan Huang, Jerry Li</author>
    <pubDate>Nov 12 2021</pubDate>
    <description>We study the power of quantum memory for learning properties of quantum systems and dynamics, which is of great importance in physics and chemistry. Many state-of-the-art learning algorithms require access to an additional external quantum memory. While such a quantum memory is not required a priori, in many cases, algorithms that do not utilize quantum memory require much more data than those which do. We show that this trade-off is inherent in a wide range of learning problems. Our results include the following: (1) We show that to perform shadow tomography on an $n$-qubit state rho with $M$ observables, any algorithm without quantum memory requires $\Omega(\min(M, 2^n))$ samples of rho in the worst case. Up to logarithmic factors, this matches the upper bound of [HKP20] and completely resolves an open question in [Aar18, AR19]. (2) We establish exponential separations between algorithms with and without quantum memory for purity testing, distinguishing scrambling and depolarizing evolutions, as well as uncovering symmetry in physical dynamics. Our separations improve and generalize prior work of [ACQ21] by allowing for a broader class of algorithms without quantum memory. (3) We give the first tradeoff between quantum memory and sample complexity. We prove that to estimate absolute values of all $n$-qubit Pauli observables, algorithms with $k < n$ qubits of quantum memory require at least $\Omega(2^{(n-k)/3})$ samples, but there is an algorithm using $n$-qubit quantum memory which only requires $O(n)$ samples. The separations we show are sufficiently large and could already be evident, for instance, with tens of qubits. This provides a concrete path towards demonstrating real-world advantage for learning algorithms with quantum memory.</description>
  </item>

  <item>
    <title>Realizing Repeated Quantum Error Correction in a Distance-Three Surface Code</title>
    <link>http://arxiv.org/pdf/2112.03708</link>
    <author>Sebastian Krinner, Nathan Lacroix, Ants Remm, Agustin Di Paolo, Elie Genois, Catherine Leroux, Christoph Hellings, Stefania Lazar, Francois Swiadek, Johannes Herrmann, Graham J. Norris, Christian Kraglund Andersen, Markus M√ºller, Alexandre Blais, Christopher Eichler, Andreas Wallraff</author>
    <pubDate>Dec 08 2021</pubDate>
    <description>Quantum computers hold the promise of solving computational problems which are intractable using conventional methods. For fault-tolerant operation quantum computers must correct errors occurring due to unavoidable decoherence and limited control accuracy. Here, we demonstrate quantum error correction using the surface code, which is known for its exceptionally high tolerance to errors. Using 17 physical qubits in a superconducting circuit we encode quantum information in a distance-three logical qubit building up on recent distance-two error detection experiments. In an error correction cycle taking only $1.1\,\mu$s, we demonstrate the preservation of four cardinal states of the logical qubit. Repeatedly executing the cycle, we measure and decode both bit- and phase-flip error syndromes using a minimum-weight perfect-matching algorithm in an error-model-free approach and apply corrections in postprocessing. We find a low error probability of $3\,\%$ per cycle when rejecting experimental runs in which leakage is detected. The measured characteristics of our device agree well with a numerical model. Our demonstration of repeated, fast and high-performance quantum error correction cycles, together with recent advances in ion traps, support our understanding that fault-tolerant quantum computation will be practically realizable.</description>
  </item>

  <item>
    <title>Concentration for Trotter error</title>
    <link>http://arxiv.org/pdf/2111.05324</link>
    <author>Chi-Fang Chen, Fernando G.S.L. Brand√£o</author>
    <pubDate>Nov 10 2021</pubDate>
    <description>Quantum simulation is expected to be one of the key applications of future quantum computers. Product formulas, or Trotterization, are the oldest and, still today, an appealing method for quantum simulation. For an accurate product formula approximation in the spectral norm, the state-of-the-art gate complexity depends on the number of Hamiltonian terms and a certain 1-norm of its local terms. This work studies the concentration aspects of Trotter error: we prove that, typically, the Trotter error exhibits 2-norm (i.e., incoherent) scaling; the current estimate with 1-norm (i.e., coherent) scaling is for the worst cases. For k-local Hamiltonians and higher-order product formulas, we obtain gate count estimates for input states drawn from a 1-design ensemble (e.g., computational basis states). Our gate count depends on the number of Hamiltonian terms but replaces the 1-norm quantity by its analog in 2-norm, giving significant speedup for systems with large connectivity. Our results generalize to Hamiltonians with Fermionic terms and when the input state is drawn from a low-particle number subspace. Further, when the Hamiltonian itself has Gaussian coefficients (e.g., the SYK models), we show the stronger result that the 2-norm behavior persists even for the worst input state. Our main technical tool is a family of simple but versatile inequalities from non-commutative martingales called uniform smoothness. We use them to derive Hypercontractivity, namely p-norm estimates for low-degree polynomials, which implies concentration via Markov's inequality. In terms of optimality, we give examples that simultaneously match our p-norm bounds and the spectral norm bounds. Therefore, our improvement is due to asking a qualitatively different question from the spectral norm bounds. Our results give evidence that product formulas in practice may generically work much better than expected.</description>
  </item>

  <item>
    <title>Constant-overhead quantum error correction with thin planar connectivity</title>
    <link>http://arxiv.org/pdf/2109.14609</link>
    <author>Maxime A. Tremblay, Nicolas Delfosse, Michael E. Beverland</author>
    <pubDate>Sep 30 2021</pubDate>
    <description>Quantum LDPC codes may provide a path to build low-overhead fault-tolerant quantum computers. However, as general LDPC codes lack geometric constraints, na√Øve layouts couple many distant qubits with crossing connections which could be hard to build in hardware and could result in performance-degrading crosstalk. We propose a 2D layout for quantum LDPC codes by decomposing their Tanner graphs into a small number of planar layers. Each layer contains long-range connections which do not cross. For any CSS code with a degree-$\delta$ Tanner graph, we design stabilizer measurement circuits with depth at most $(2\delta +2)$ using at most $\lceil \delta/2 \rceil$ layers. We observe a circuit-noise threshold of 0.28\% for a positive-rate code family using 49 physical qubits per logical qubit. For a physical error rate of $10^{-4}$, this family reaches a logical error rate of $10^{-15}$ using fourteen times fewer physical qubits than the surface code.</description>
  </item>

  <item>
    <title>Realization of real-time fault-tolerant quantum error correction</title>
    <link>http://arxiv.org/pdf/2107.07505</link>
    <author>C. Ryan-Anderson, J. G. Bohnet, K. Lee, D. Gresh, A. Hankin, J. P. Gaebler, D. Francois, A. Chernoguzov, D. Lucchetti, N. C. Brown, T. M. Gatterman, S. K. Halit, K. Gilmore, J. Gerber, B. Neyenhuis, D. Hayes, R. P. Stutz</author>
    <pubDate>Jul 16 2021</pubDate>
    <description>Correcting errors in real time is essential for reliable large-scale quantum computations. Realizing this high-level function requires a system capable of several low-level primitives, including single-qubit and two-qubit operations, mid-circuit measurements of subsets of qubits, real-time processing of measurement outcomes, and the ability to condition subsequent gate operations on those measurements. In this work, we use a ten qubit QCCD trapped-ion quantum computer to encode a single logical qubit using the $[[7,1,3]]$ color code, first proposed by Steane~\citesteane1996error. The logical qubit is initialized into the eigenstates of three mutually unbiased bases using an encoding circuit, and we measure an average logical SPAM error of $1.7(6) \times 10^{-3}$, compared to the average physical SPAM error $2.4(8) \times 10^{-3}$ of our qubits. We then perform multiple syndrome measurements on the encoded qubit, using a real-time decoder to determine any necessary corrections that are done either as software updates to the Pauli frame or as physically applied gates. Moreover, these procedures are done repeatedly while maintaining coherence, demonstrating a dynamically protected logical qubit memory. Additionally, we demonstrate non-Clifford qubit operations by encoding a logical magic state with an error rate below the threshold required for magic state distillation. Finally, we present system-level simulations that allow us to identify key hardware upgrades that may enable the system to reach the pseudo-threshold.</description>
  </item>

  <item>
    <title>Single-shot quantum error correction with the three-dimensional subsystem toric code</title>
    <link>http://arxiv.org/pdf/2106.02621</link>
    <author>Aleksander Kubica, Michael Vasmer</author>
    <pubDate>Jun 07 2021</pubDate>
    <description>We introduce a new topological quantum code, the three-dimensional subsystem toric code (3D STC), which is a generalization of the stabilizer toric code. The 3D STC can be realized by measuring geometrically-local parity checks of weight at most three on the cubic lattice with open boundary conditions. We prove that single-shot quantum error correction (QEC) is possible with the 3D STC, i.e., one round of local parity-check measurements suffices to perform reliable QEC even in the presence of measurement errors. We also propose an efficient single-shot QEC strategy for the 3D STC and investigate its performance. In particular, we numerically estimate the resulting storage threshold against independent bit-flip, phase-flip and measurement errors to be $p_\text{STC} \approx 1.045\%$. Such a high threshold together with local parity-check measurements of small weight make the 3D STC particularly appealing for realizing fault-tolerant quantum computing.</description>
  </item>

  <item>
    <title>Faster quantum-inspired algorithms for solving linear systems</title>
    <link>http://arxiv.org/pdf/2103.10309</link>
    <author>Changpeng Shao, Ashley Montanaro</author>
    <pubDate>Mar 19 2021</pubDate>
    <description>We establish an improved classical algorithm for solving linear systems in a model analogous to the QRAM that is used by quantum linear solvers. Precisely, for the linear system $A\x = \b$, we show that there is a classical algorithm that outputs a data structure for $\x$ allowing sampling and querying to the entries, where $\x$ is such that $\|\x - A^{-1}\b\|\leq \epsilon \|A^{-1}\b\|$. This output can be viewed as a classical analogue to the output of quantum linear solvers. The complexity of our algorithm is $\widetilde{O}(\kappa_F^6 \kappa^2/\epsilon^2 )$, where $\kappa_F = \|A\|_F\|A^{-1}\|$ and $\kappa = \|A\|\|A^{-1}\|$. This improves the previous best algorithm [Gily√©n, Song and Tang, arXiv:2009.07268] of complexity $\widetilde{O}(\kappa_F^6 \kappa^6/\epsilon^4)$. Our algorithm is based on the randomized Kaczmarz method, which is a particular case of stochastic gradient descent. We also find that when $A$ is row sparse, this method already returns an approximate solution $\x$ in time $\widetilde{O}(\kappa_F^2)$, while the best quantum algorithm known returns $\ket{\x}$ in time $\widetilde{O}(\kappa_F)$ when $A$ is stored in the QRAM data structure. As a result, assuming access to QRAM and if $A$ is row sparse, the speedup based on current quantum algorithms is quadratic.</description>
  </item>

  <item>
    <title>Lower Bounds on Stabilizer Rank</title>
    <link>http://arxiv.org/pdf/2106.03214</link>
    <author>Shir Peleg, Amir Shpilka, Ben Lee Volk</author>
    <pubDate>Jun 08 2021</pubDate>
    <description>The stabilizer rank of a quantum state $\psi$ is the minimal $r$ such that $\left| \psi \right \rangle = \sum_{j=1}^r c_j \left|\varphi_j \right\rangle$ for $c_j \in \mathbb{C}$ and stabilizer states $\varphi_j$. The running time of several classical simulation methods for quantum circuits is determined by the stabilizer rank of the $n$-th tensor power of single-qubit magic states. We prove a lower bound of $\Omega(n)$ on the stabilizer rank of such states, improving a previous lower bound of $\Omega(\sqrt{n})$ of Bravyi, Smith and Smolin (arXiv:1506.01396). Further, we prove that for a sufficiently small constant $\delta$, the stabilizer rank of any state which is $\delta$-close to those states is $\Omega(\sqrt{n}/\log n)$. This is the first non-trivial lower bound for approximate stabilizer rank. Our techniques rely on the representation of stabilizer states as quadratic functions over affine subspaces of $\mathbb{F}_2^n$, and we use tools from analysis of boolean functions and complexity theory. The proof of the first result involves a careful analysis of directional derivatives of quadratic polynomials, whereas the proof of the second result uses Razborov-Smolensky low degree polynomial approximations and correlation bounds against the majority function.</description>
  </item>

  <item>
    <title>Limits of quantum speed-ups for computational geometry and other problems: Fine-grained complexity via quantum walks</title>
    <link>http://arxiv.org/pdf/2106.02005</link>
    <author>Harry Buhrman, Bruno Loff, Subhasree Patro, Florian Speelman</author>
    <pubDate>Jun 04 2021</pubDate>
    <description>Many computational problems are subject to a quantum speed-up: one might find that a problem having an O(n^3)-time or O(n^2)-time classic algorithm can be solved by a known O(n^1.5)-time or O(n)-time quantum algorithm. The question naturally arises: how much quantum speed-up is possible? The area of fine-grained complexity allows us to prove optimal lower-bounds on the complexity of various computational problems, based on the conjectured hardness of certain natural, well-studied problems. This theory has recently been extended to the quantum setting, in two independent papers by Buhrman, Patro, and Speelman (arXiv:1911.05686), and by Aaronson, Chia, Lin, Wang, and Zhang (arXiv:1911.01973). In this paper, we further extend the theory of fine-grained complexity to the quantum setting. A fundamental conjecture in the classical setting states that the 3SUM problem cannot be solved by (classical) algorithms in time O(n^2-a), for any a>0. We formulate an analogous conjecture, the Quantum-3SUM-Conjecture, which states that there exist no sublinear O(n^1-b)-time quantum algorithms for the 3SUM problem. Based on the Quantum-3SUM-Conjecture, we show new lower-bounds on the time complexity of quantum algorithms for several computational problems. Most of our lower-bounds are optimal, in that they match known upper-bounds, and hence they imply tight limits on the quantum speedup that is possible for these problems.</description>
  </item>

  <item>
    <title>Introduction to Quantum Error Correction and Fault Tolerance</title>
    <link>http://arxiv.org/pdf/2111.08894</link>
    <author>Steven M. Girvin</author>
    <pubDate>Nov 18 2021</pubDate>
    <description>These lecture notes from the 2019 Les Houches Summer School on 'Quantum Information Machines' are intended to provide an introduction to classical and quantum error correction with bits and qubits, and with continuous variable systems (harmonic oscillators). The focus on the latter will be on practical examples that can be realized today or in the near future with a modular architecture based on superconducting electrical circuits and microwave photons. The goal and vision is 'hardware-efficient' quantum error correction that does not require exponentially large hardware overhead in order to achieve practical and useful levels of fault tolerance and circuit depth.</description>
  </item>

  <item>
    <title>Improved quantum error correction using soft information</title>
    <link>http://arxiv.org/pdf/2107.13589</link>
    <author>Christopher A. Pattison, Michael E. Beverland, Marcus P. da Silva, Nicolas Delfosse</author>
    <pubDate>Jul 30 2021</pubDate>
    <description>The typical model for measurement noise in quantum error correction is to randomly flip the binary measurement outcome. In experiments, measurements yield much richer information - e.g., continuous current values, discrete photon counts - which is then mapped into binary outcomes by discarding some of this information. In this work, we consider methods to incorporate all of this richer information, typically called soft information, into the decoding of quantum error correction codes, and in particular the surface code. We describe how to modify both the Minimum Weight Perfect Matching and Union-Find decoders to leverage soft information, and demonstrate these soft decoders outperform the standard (hard) decoders that can only access the binary measurement outcomes. Moreover, we observe that the soft decoder achieves a threshold 25\% higher than any hard decoder for phenomenological noise with Gaussian soft measurement outcomes. We also introduce a soft measurement error model with amplitude damping, in which measurement time leads to a trade-off between measurement resolution and additional disturbance of the qubits. Under this model we observe that the performance of the surface code is very sensitive to the choice of the measurement time - for a distance-19 surface code, a five-fold increase in measurement time can lead to a thousand-fold increase in logical error rate. Moreover, the measurement time that minimizes the physical error rate is distinct from the one that minimizes the logical performance, pointing to the benefits of jointly optimizing the physical and quantum error correction layers.</description>
  </item>

  <item>
    <title>Learning quantum many-body systems from a few copies</title>
    <link>http://arxiv.org/pdf/2107.03333</link>
    <author>Cambyse Rouz√©, Daniel Stilck Fran√ßa</author>
    <pubDate>Jul 08 2021</pubDate>
    <description>Estimating physical properties of quantum states from measurements is one of the most fundamental tasks in quantum science. In this work, we identify conditions on states under which it is possible to infer the expectation values of all quasi-local observables of a given locality up to a relative error from a number of samples that grows polylogarithmically with the system's size and polynomially on the locality of the target observables. This constitutes an exponential improvement over known tomography methods in some regimes. We achieve our results by combining one of the most well-established techniques to learn quantum states, namely the maximum entropy method, with tools from the emerging fields of quantum optimal transport and classical shadows. We conjecture that our condition holds for all states exhibiting some form of decay of correlations and establish it for several subsets thereof. These include widely studied classes of states such as one-dimensional thermal and high-temperature Gibbs states of local commuting Hamiltonians on arbitrary hypergraphs or outputs of shallow circuits. Moreover, we show improvements of the maximum entropy method beyond the sample complexity of independent interest. These include identifying regimes in which it is possible to perform the postprocessing efficiently as well as novel bounds on the condition number of covariance matrices of many-body states.</description>
  </item>

  <item>
    <title>Realizing topologically ordered states on a quantum processor</title>
    <link>http://arxiv.org/pdf/2104.01180</link>
    <author>K. J. Satzinger, Y. Liu, A. Smith, C. Knapp, M. Newman, C. Jones, Z. Chen, C. Quintana, X. Mi, A. Dunsworth, C. Gidney, I. Aleiner, F. Arute, K. Arya, J. Atalaya, R. Babbush, J. C. Bardin, R. Barends, J. Basso, A. Bengtsson, et al (78)</author>
    <pubDate>Apr 06 2021</pubDate>
    <description>The discovery of topological order has revolutionized the understanding of quantum matter in modern physics and provided the theoretical foundation for many quantum error correcting codes. Realizing topologically ordered states has proven to be extremely challenging in both condensed matter and synthetic quantum systems. Here, we prepare the ground state of the toric code Hamiltonian using an efficient quantum circuit on a superconducting quantum processor. We measure a topological entanglement entropy near the expected value of $\ln2$, and simulate anyon interferometry to extract the braiding statistics of the emergent excitations. Furthermore, we investigate key aspects of the surface code, including logical state injection and the decay of the non-local order parameter. Our results demonstrate the potential for quantum processors to provide key insights into topological quantum matter and quantum error correction.</description>
  </item>

  <item>
    <title>Interleaving: Modular architectures for fault-tolerant photonic quantum computing</title>
    <link>http://arxiv.org/pdf/2103.08612</link>
    <author>Hector Bombin, Isaac H. Kim, Daniel Litinski, Naomi Nickerson, Mihir Pant, Fernando Pastawski, Sam Roberts, Terry Rudolph</author>
    <pubDate>Mar 17 2021</pubDate>
    <description>Useful fault-tolerant quantum computers require very large numbers of physical qubits. Quantum computers are often designed as arrays of static qubits executing gates and measurements. Photonic qubits require a different approach. In photonic fusion-based quantum computing (FBQC), the main hardware components are resource-state generators (RSGs) and fusion devices connected via waveguides and switches. RSGs produce small entangled states of a few photonic qubits, whereas fusion devices perform entangling measurements between different resource states, thereby executing computations. In addition, low-loss photonic delays such as optical fiber can be used as fixed-time quantum memories simultaneously storing thousands of photonic qubits. Here, we present a modular architecture for FBQC in which these components are combined to form "interleaving modules" consisting of one RSG with its associated fusion devices and a few fiber delays. Exploiting the multiplicative power of delays, each module can add thousands of physical qubits to the computational Hilbert space. Networks of modules are universal fault-tolerant quantum computers, which we demonstrate using surface codes and lattice surgery as a guiding example. Our numerical analysis shows that in a network of modules containing 1-km-long fiber delays, each RSG can generate four logical distance-35 surface-code qubits while tolerating photon loss rates above 2% in addition to the fiber-delay loss. We illustrate how the combination of interleaving with further uses of non-local fiber connections can reduce the cost of logical operations and facilitate the implementation of unconventional geometries such as periodic boundaries or stellated surface codes. Interleaving applies beyond purely optical architectures, and can also turn many small disconnected matter-qubit devices with transduction to photons into a large-scale quantum computer.</description>
  </item>

  <item>
    <title>Planar Floquet Codes</title>
    <link>http://arxiv.org/pdf/2110.05348</link>
    <author>Christophe Vuillot</author>
    <pubDate>Oct 12 2021</pubDate>
    <description>A protocol called the "honeycomb code", or generically a "Floquet code", was introduced by Hastings and Haah in \citehastings_dynamically_2021. The honeycomb code is a subsystem code based on the honeycomb lattice with zero logical qubits but such that there exists a schedule for measuring two-body gauge checks leaving enough room at all times for two protected logical qubits. In this work we show a way to introduce boundaries to the system which curiously presents a rotating dynamics but has constant distance and is therefore not fault-tolerant.</description>
  </item>

</channel>

</rss>
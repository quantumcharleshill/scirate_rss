<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>Computational advantage of quantum random sampling</title>
    <link>http://arxiv.org/pdf/2206.04079</link>
    <author>Dominik Hangleiter, Jens Eisert</author>
    <pubDate>Jun 10 2022</pubDate>
    <description>Quantum random sampling is the leading proposal for demonstrating a computational advantage of quantum computers over classical computers. Recently, first large-scale implementations of quantum random sampling have arguably surpassed the boundary of what can be simulated on existing classical hardware. In this article, we comprehensively review the theoretical underpinning of quantum random sampling in terms of computational complexity and verifiability, as well as the practical aspects of its experimental implementation using superconducting and photonic devices and its classical simulation. We discuss in detail open questions in the field and provide perspectives for the road ahead, including potential applications of quantum random sampling.</description>
  </item>

  <item>
    <title>A construction of Combinatorial NLTS</title>
    <link>http://arxiv.org/pdf/2206.02741</link>
    <author>Anurag Anshu, Nikolas P. Breuckmann</author>
    <pubDate>Jun 07 2022</pubDate>
    <description>The NLTS (No Low-Energy Trivial State) conjecture of Freedman and Hastings [2014] posits that there exist families of Hamiltonians with all low energy states of high complexity (with complexity measured by the quantum circuit depth preparing the state). Here, we prove a weaker version called the combinatorial NLTS, where a quantum circuit lower bound is shown against states that violate a (small) constant fraction of local terms. This generalizes the prior NLETS results (Eldar and Harrow [2017]; Nirkhe, Vazirani and Yuen [2018]). Our construction is obtained by combining tensor networks with expander codes (Sipser and Spielman [1996]). The Hamiltonian is the parent Hamiltonian of a perturbed tensor network, inspired by the `uncle Hamiltonian' of Fernandez-Gonzalez et. al. [2015]. Thus, we deviate from the quantum CSS code Hamiltonians considered in most prior works.</description>
  </item>

  <item>
    <title>Towards near-term quantum simulation of materials</title>
    <link>http://arxiv.org/pdf/2205.15256</link>
    <author>Laura Clinton, Toby Cubitt, Brian Flynn, Filippo Maria Gambetta, Joel Klassen, Ashley Montanaro, Stephen Piddock, Raul A. Santos, Evan Sheridan</author>
    <pubDate>May 31 2022</pubDate>
    <description>Simulation of materials is one of the most promising applications of quantum computers. On near-term hardware the crucial constraint on these simulations is circuit depth. Many quantum simulation algorithms rely on a layer of unitary evolutions generated by each term in a Hamiltonian. This appears in time-dynamics as a single Trotter step, and in variational quantum eigensolvers under the Hamiltonian variational ansatz as a single ansatz layer. We present a new quantum algorithm design for materials modelling where the depth of a layer is independent of the system size. This design takes advantage of the locality of materials in the Wannier basis and employs a tailored fermionic encoding that preserves locality. We analyse the circuit costs of this approach and present a compiler that transforms density functional theory data into quantum circuit instructions -- connecting the physics of the material to the simulation circuit. The compiler automatically optimises circuits at multiple levels, from the base gate level to optimisations derived from the physics of the specific target material. We present numerical results for materials spanning a wide structural and technological range. Our results demonstrate a reduction of many orders of magnitude in circuit depth over standard prior methods that do not consider the structure of the Hamiltonian. For example our results improve resource requirements for Strontium Vanadate (SrVO$_3$) from 864 to 180 qubits for a $3\times3\times3$ lattice, and the circuit depth of a single Trotter or variational layer from $7.5\times 10^8$ to depth $730$. Although this is still beyond current hardware, our results show that materials simulation may be feasible on quantum computers without necessarily requiring scalable, fault-tolerant quantum computers, provided quantum algorithm design incorporates understanding of the materials and applications.</description>
  </item>

  <item>
    <title>Saturation and recurrence of quantum complexity in random quantum circuits</title>
    <link>http://arxiv.org/pdf/2205.09734</link>
    <author>Michał Oszmaniec, Michał Horodecki, Nicholas Hunter-Jones</author>
    <pubDate>May 20 2022</pubDate>
    <description>Quantum complexity is a measure of the minimal number of elementary operations required to approximately prepare a given state or unitary channel. Recently, this concept has found applications beyond quantum computing -- in studying the dynamics of quantum many-body systems and the long-time properties of AdS black holes. In this context Brown and Susskind conjectured that the complexity of a chaotic quantum system grows linearly in time up to times exponential in the system size, saturating at a maximal value, and remaining maximally complex until undergoing recurrences at doubly-exponential times. In this work we prove the saturation and recurrence of the complexity of quantum states and unitaries in a model of chaotic time-evolution based on random quantum circuits, in which a local random unitary transformation is applied to the system at every time step. Importantly, our findings hold for quite general random circuit models, irrespective of the gate set and geometry of qubit interactions. Our results advance an understanding of the long-time behaviour of chaotic quantum systems and could shed light on the physics of black hole interiors. From a technical perspective our results are based on establishing new quantitative connections between the Haar measure and high-degree approximate designs, as well as the fact that random quantum circuits of sufficiently high depth converge to approximate designs.</description>
  </item>

  <item>
    <title>The learnability of Pauli noise</title>
    <link>http://arxiv.org/pdf/2206.06362</link>
    <author>Senrui Chen, Yunchao Liu, Matthew Otten, Alireza Seif, Bill Fefferman, Liang Jiang</author>
    <pubDate>Jun 14 2022</pubDate>
    <description>Recently, several noise benchmarking algorithms have been developed to characterize noisy quantum gates on today's quantum devices. A well-known issue in benchmarking is that not everything about quantum noise is learnable due to the existence of gauge freedom, leaving open the question of what information about noise is learnable and what is not, which has been unclear even for a single CNOT gate. Here we give a precise characterization of the learnability of Pauli noise channels attached to Clifford gates, showing that learnable information corresponds to the cycle space of the pattern transfer graph of the gate set, while unlearnable information corresponds to the cut space. This implies the optimality of cycle benchmarking, in the sense that it can learn all learnable information about Pauli noise. We experimentally demonstrate noise characterization of IBM's CNOT gate up to 2 unlearnable degrees of freedom, for which we obtain bounds using physical constraints. In addition, we give an attempt to characterize the unlearnable information by assuming perfect initial state preparation. However, based on the experimental data, we conclude that this assumption is inaccurate as it yields unphysical estimates, and we obtain a lower bound on state preparation noise.</description>
  </item>

  <item>
    <title>Efficient and robust estimation of many-qubit Hamiltonians</title>
    <link>http://arxiv.org/pdf/2205.09567</link>
    <author>Daniel Stilck França, Liubov A. Markovich, V. V. Dobrovitski, Albert H. Werner, Johannes Borregaard</author>
    <pubDate>May 20 2022</pubDate>
    <description>Characterizing the interactions and dynamics of quantum mechanical systems is an essential task in the development of quantum technologies. We propose a novel protocol for estimating the underlying Hamiltonian dynamics and Markovian noise of a multi-qubit device. It is based on the efficient estimation of the time-derivatives of few qubit observables using polynomial interpolation. For finite range dynamics, our protocol exponentially improves the necessary time-resolution of the measurements and quadratically reduces the overall sample complexity compared to previous approaches. Furthermore, we show that our protocol can characterize the dynamics of systems with algebraically decaying interactions. The implementation of the protocol requires only the preparation of product states and single-qubit measurements, rendering it applicable for the characterization of both current and future quantum devices.</description>
  </item>

  <item>
    <title>Candidate for a self-correcting quantum memory in two dimensions</title>
    <link>http://arxiv.org/pdf/2205.09767</link>
    <author>Simon Lieu, Yu-Jie Liu, Alexey V. Gorshkov</author>
    <pubDate>May 23 2022</pubDate>
    <description>An interesting problem in the field of quantum error correction involves finding a physical system that hosts a "self-correcting quantum memory," defined as an encoded qubit coupled to an environment that naturally wants to correct errors. To date, a quantum memory stable against finite-temperature effects is only known in four spatial dimensions or higher. Here, we take a different approach to realize a stable quantum memory by relying on a driven-dissipative environment. We propose a new model which appears to self correct against both bit-flip and phase-flip errors in two dimensions: A square lattice composed of photonic "cat qubits" coupled via dissipative terms which tend to fix errors locally. Inspired by the presence of two distinct $\mathbb{Z}_2$-symmetry-broken phases, our scheme relies on Ising-like dissipators to protect against bit flips and on a driven-dissipative photonic environment to protect against phase flips.</description>
  </item>

  <item>
    <title>Topological phases of unitary dynamics: Classification in Clifford category</title>
    <link>http://arxiv.org/pdf/2205.09141</link>
    <author>Jeongwan Haah</author>
    <pubDate>May 20 2022</pubDate>
    <description>A quantum cellular automaton (QCA) or a causal unitary is by definition an automorphism of local operator algebra, by which local operators are mapped to local operators. Quantum circuits of small depth, local Hamiltonian evolutions for short time, and translations (shifts) are examples. A Clifford QCA is one that maps any Pauli operator to a finite tensor product of Pauli operators. Here, we obtain a complete table of groups $\mathfrak C(\mathsf d,p)$ of translation invariant Clifford QCA in any spatial dimension $\mathsf d \ge 0$ modulo Clifford quantum circuits and shifts over prime $p$-dimensional qudits, where the circuits and shifts are allowed to obey only coarser translation invariance. The group $\mathfrak C(\mathsf d,p)$ is nonzero only for $\mathsf d = 2k+3$ if $p=2$ and $\mathsf d = 4k+3$ if $p$ is odd where~$k \ge 0$ is any integer, in which case $\mathfrak C(\mathsf d,p) \cong \widetilde{\mathfrak W}(\mathbb F_p)$, the classical Witt group of nonsingular quadratic forms over the finite field $\mathbb F_p$. It is well known that $\widetilde{\mathfrak W}(\mathbb F_2) \cong \mathbb Z/2\mathbb Z$, $\widetilde{\mathfrak W}(\mathbb F_p) \cong \mathbb Z/4\mathbb Z$ if $p = 3 \bmod 4$, and $\widetilde{\mathfrak W}(\mathbb F_p)\cong \mathbb Z/2\mathbb Z \oplus \mathbb Z/2\mathbb Z$ if $p = 1 \bmod 4$. The classification is achieved by a dimensional descent, which is a reduction of Laurent extension theorems for algebraic $L$-groups of surgery theory in topology.</description>
  </item>

  <item>
    <title>Tensor Network Algorithms: a Route Map</title>
    <link>http://arxiv.org/pdf/2205.10345</link>
    <author>Mari Carmen Bañuls</author>
    <pubDate>May 23 2022</pubDate>
    <description>Tensor networks provide extremely powerful tools for the study of complex classical and quantum many-body problems. Over the last two decades, the increment in the number of techniques and applications has been relentless, and especially the last ten years have seen an explosion of new ideas and results that may be overwhelming for the newcomer. This short review introduces the basic ideas, the best established methods and some of the most significant algorithmic developments that are expanding the boundaries of the tensor network potential. The goal is to help the reader not only appreciate the many possibilities offered by tensor networks, but also find their way through state-of-the-art codes, their applicability and some avenues of ongoing progress.</description>
  </item>

  <item>
    <title>An efficient decoder for a linear distance quantum LDPC code</title>
    <link>http://arxiv.org/pdf/2206.06557</link>
    <author>Shouzhen Gu, Christopher A. Pattison, Eugene Tang</author>
    <pubDate>Jun 15 2022</pubDate>
    <description>Recent developments have shown the existence of quantum low-density parity check (qLDPC) codes with constant rate and linear distance. A natural question concerns the efficient decodability of these codes. In this paper, we present a linear time decoder for the recent quantum Tanner codes construction of asymptotically good qLDPC codes, which can correct all errors of weight up to a constant fraction of the blocklength. Our decoder is an iterative algorithm which searches for corrections within constant-sized regions. At each step, the corrections are found by reducing a locally defined and efficiently computable cost function which serves as a proxy for the weight of the remaining error.</description>
  </item>

  <item>
    <title>Tight Bounds for State Tomography with Incoherent Measurements</title>
    <link>http://arxiv.org/pdf/2206.05265</link>
    <author>Sitan Chen, Brice Huang, Jerry Li, Allen Liu, Mark Sellke</author>
    <pubDate>Jun 13 2022</pubDate>
    <description>We consider the classic question of state tomography: given copies of an unknown quantum state $\rho\in\mathbb{C}^{d\times d}$, output $\widehat{\rho}$ for which $\|\rho - \widehat{\rho}\|_{\mathsf{tr}} \le \varepsilon$. When one is allowed to make coherent measurements entangled across all copies, $\Theta(d^2/\varepsilon^2)$ copies are necessary and sufficient [Haah et al. '17, O'Donnell-Wright '16]. Unfortunately, the protocols achieving this rate incur large quantum memory overheads that preclude implementation on current or near-term devices. On the other hand, the best known protocol using incoherent (single-copy) measurements uses $O(d^3/\varepsilon^2)$ copies [Kueng-Rauhut-Terstiege '17], and multiple papers have posed it as an open question to understand whether or not this rate is tight. In this work, we fully resolve this question, by showing that any protocol using incoherent measurements, even if they are chosen adaptively, requires $\Omega(d^3/\varepsilon^2)$ copies, matching the upper bound of [Kueng-Rauhut-Terstiege '17]. We do so by a new proof technique which directly bounds the "tilt" of the posterior distribution after measurements, which yields a surprisingly short proof of our lower bound, and which we believe may be of independent interest.</description>
  </item>

  <item>
    <title>Perturbation Theory and the Sum of Squares</title>
    <link>http://arxiv.org/pdf/2205.12325</link>
    <author>Matthew B. Hastings</author>
    <pubDate>May 26 2022</pubDate>
    <description>The sum-of-squares (SoS) hierarchy is a powerful technique based on semi-definite programming that can be used for both classical and quantum optimization problems. This hierarchy goes under several names; in particular, in quantum chemistry it is called the reduced density matrix (RDM) method. We consider the ability of this hierarchy to reproduce weak coupling perturbation theory for three different kinds of systems: spin (or qubit) systems, bosonic systems (the anharmonic oscillator), and fermionic systems with quartic interactions. For such fermionic systems, we show that degree-$4$ SoS (called $2$-RDM in quantum chemsitry) does not reproduce second order perturbation theory but degree-$6$ SoS ($3$-RDM) does (and we conjecture that it reproduces third order perturbation theory). Indeed, we identify a fragment of degree-$6$ SoS which can do this, which may be useful for practical quantum chemical calculations as it may be possible to implement this fragment with less cost than the full degree-$6$ SoS. Remarkably, this fragment is very similar to one studied by Hastings and O'Donnell for the Sachdev-Ye-Kitaev (SYK) model.</description>
  </item>

  <item>
    <title>Adaptive Online Learning of Quantum States</title>
    <link>http://arxiv.org/pdf/2206.00220</link>
    <author>Xinyi Chen, Elad Hazan, Tongyang Li, Zhou Lu, Xinzhao Wang, Rui Yang</author>
    <pubDate>Jun 02 2022</pubDate>
    <description>In the fundamental problem of shadow tomography, the goal is to efficiently learn an unknown $d$-dimensional quantum state using projective measurements. However, it is rarely the case that the underlying state remains stationary: changes may occur due to measurements, environmental noise, or an underlying Hamiltonian state evolution. In this paper we adopt tools from adaptive online learning to learn a changing state, giving adaptive and dynamic regret bounds for online shadow tomography that are polynomial in the number of qubits and sublinear in the number of measurements. Our analysis utilizes tools from complex matrix analysis to cope with complex numbers, which may be of independent interest in online learning. In addition, we provide numerical experiments that corroborate our theoretical results.</description>
  </item>

  <item>
    <title>Quantum Advantage in Cryptography</title>
    <link>http://arxiv.org/pdf/2206.04078</link>
    <author>Renato Renner, Ramona Wolf</author>
    <pubDate>Jun 10 2022</pubDate>
    <description>Ever since its inception, cryptography has been caught in a vicious circle: Cryptographers keep inventing methods to hide information, and cryptanalysts break them, prompting cryptographers to invent even more sophisticated encryption schemes, and so on. But could it be that quantum information technology breaks this circle? At first sight, it looks as if it just lifts the competition between cryptographers and cryptanalysts to the next level. Indeed, quantum computers will render most of today's public key cryptosystems insecure. Nonetheless, there are good reasons to believe that cryptographers will ultimately prevail over cryptanalysts. Quantum cryptography allows us to build communication schemes whose secrecy relies only on the laws of physics as well as some minimum assumptions about the cryptographic hardware - leaving basically no room for an attack. While we are not yet there, this article provides an overview of the principles and state of the art of quantum cryptography.</description>
  </item>

  <item>
    <title>Improved single-shot decoding of higher dimensional hypergraph product codes</title>
    <link>http://arxiv.org/pdf/2206.03122</link>
    <author>Oscar Higgott, Nikolas P. Breuckmann</author>
    <pubDate>Jun 08 2022</pubDate>
    <description>In this work we study the single-shot performance of higher dimensional hypergraph product codes decoded using belief-propagation and ordered-statistics decoding [Panteleev and Kalachev, 2019]. We find that decoding data qubit and syndrome measurement errors together in a single stage leads to single-shot thresholds that greatly exceed all previously observed single-shot thresholds for these codes. For the 3D toric code and a phenomenological noise model, our results are consistent with a sustainable threshold of 7.1% for $Z$ errors, compared to the threshold of 2.90% previously found using a two-stage decoder [Quintavalle et al., 2021]. For the 4D toric code, for which both $X$ and $Z$ error correction is single-shot, our results are consistent with a sustainable single-shot threshold of 4.3% which is even higher than the threshold of 2.93% for the 2D toric code for the same noise model but using $L$ rounds of stabiliser measurement. We also explore the performance of balanced product and 4D hypergraph product codes which we show lead to a reduction in qubit overhead compared the surface code for phenomenological error rates as high as 1%.</description>
  </item>

  <item>
    <title>Quantum Resources Required to Block-Encode a Matrix of Classical Data</title>
    <link>http://arxiv.org/pdf/2206.03505</link>
    <author>B. David Clader, Alexander M. Dalzell, Nikitas Stamatopoulos, Grant Salton, Mario Berta, William J. Zeng</author>
    <pubDate>Jun 09 2022</pubDate>
    <description>We provide modular circuit-level implementations and resource estimates for several methods of block-encoding a dense $N\times N$ matrix of classical data to precision $\epsilon$; the minimal-depth method achieves a $T$-depth of $\mathcal{O}{(\log (N/\epsilon))},$ while the minimal-count method achieves a $T$-count of $\mathcal{O}{(N\log(1/\epsilon))}$. We examine resource tradeoffs between the different approaches, and we explore implementations of two separate models of quantum random access memory (QRAM). As part of this analysis, we provide a novel state preparation routine with $T$-depth $\mathcal{O}{(\log (N/\epsilon))}$, improving on previous constructions with scaling $\mathcal{O}{(\log^2 (N/\epsilon))}$. Our results go beyond simple query complexity and provide a clear picture into the resource costs when large amounts of classical data are assumed to be accessible to quantum algorithms.</description>
  </item>

  <item>
    <title>Benchmarking Quantum Simulators using Quantum Chaos</title>
    <link>http://arxiv.org/pdf/2205.12211</link>
    <author>Daniel K. Mark, Joonhee Choi, Adam L. Shaw, Manuel Endres, Soonwon Choi</author>
    <pubDate>May 25 2022</pubDate>
    <description>We propose and analyze a sample-efficient protocol to estimate the fidelity between an experimentally prepared state and an ideal target state, applicable to a wide class of analog quantum simulators without advanced sophisticated spatiotemporal control. Our approach utilizes newly discovered universal fluctuations emerging from generic Hamiltonian dynamics, and it does not require any fine-tuned control over state preparation, quantum evolution, or readout capability. It only needs a small number of experimental measurements, achieving near optimal sample complexity: in ideal cases, a percent-level precision is obtained with $\sim 10^3$ measurements independent of system size. Furthermore, the accuracy of our fidelity estimation improves with increasing system size. We numerically demonstrate our protocol for a variety of quantum simulator platforms such as itinerant particles on optical lattices, trapped ions, and Rydberg atoms. We discuss further applications of our method for advanced tasks such as multi-parameter estimation of quantum states and processes.</description>
  </item>

  <item>
    <title>On the Role of Quantum Coherence in Thermodynamics</title>
    <link>http://arxiv.org/pdf/2205.13612</link>
    <author>Gilad Gour</author>
    <pubDate>May 30 2022</pubDate>
    <description>We find necessary and sufficient conditions to determine the inter-convertibility of quantum systems under time-translation covariant evolution, and use it to solve several problems in quantum thermodynamics both in the single-shot and asymptotic regimes. It is well known that the resource theory of quantum athermality is not reversible, but in PRL 111, 250404 (2013) it was claimed that the theory becomes reversible "provided a sublinear amount of coherent superposition over energy levels is available". Here we show that the original proof of this claim is incorrect, and then provide a completely new rigorous proof for the pure-state case. A proof of the same claim for the mixed-state case is still lacking.</description>
  </item>

  <item>
    <title>Correlations in typicality and an affirmative solution to the exact catalytic entropy conjecture</title>
    <link>http://arxiv.org/pdf/2205.08915</link>
    <author>Henrik Wilming</author>
    <pubDate>May 19 2022</pubDate>
    <description>I show that if a finite-dimensional density matrix has strictly smaller von Neumann entropy than a second one of the same dimension (and the rank is not bigger), then sufficiently (but finitely) many tensor-copies of the first density matrix majorize a density matrix whose single-body marginals are all exactly equal to the second density matrix. This implies an affirmative solution of the exact catalytic entropy conjecture (CEC) introduced by Boes et al. [PRL 122, 210402 (2019)]. Both the Lemma and the solution to the CEC transfer to the classical setting of finite-dimensional probability vectors (with permutations of entries instead of unitary transformations for the CEC).</description>
  </item>

  <item>
    <title>The battle of clean and dirty qubits in the era of partial error correction</title>
    <link>http://arxiv.org/pdf/2205.13454</link>
    <author>Daniel Bultrini, Samson Wang, Piotr Czarnik, Max Hunter Gordon, M. Cerezo, Patrick J. Coles, Lukasz Cincio</author>
    <pubDate>May 27 2022</pubDate>
    <description>When error correction becomes possible it will be necessary to dedicate a large number of physical qubits to each logical qubit. Error correction allows for deeper circuits to be run, but each additional physical qubit can potentially contribute an exponential increase in computational space, so there is a trade-off between using qubits for error correction or using them as noisy qubits. In this work we look at the effects of using noisy qubits in conjunction with noiseless qubits (an idealized model for error-corrected qubits), which we call the "clean and dirty" setup. We employ analytical models and numerical simulations to characterize this setup. Numerically we show the appearance of Noise-Induced Barren Plateaus (NIBPs), i.e., an exponential concentration of observables caused by noise, in an Ising model Hamiltonian variational ansatz circuit. We observe this even if only a single qubit is noisy and given a deep enough circuit, suggesting that NIBPs cannot be fully overcome simply by error-correcting a subset of the qubits. On the positive side, we find that for every noiseless qubit in the circuit, there is an exponential suppression in concentration of gradient observables, showing the benefit of partial error correction. Finally, our analytical models corroborate these findings by showing that observables concentrate with a scaling in the exponent related to the ratio of dirty-to-total qubits.</description>
  </item>

  <item>
    <title>Efficient decoding up to a constant fraction of the code length for asymptotically good quantum codes</title>
    <link>http://arxiv.org/pdf/2206.07571</link>
    <author>Anthony Leverrier, Gilles Zémor</author>
    <pubDate>Jun 16 2022</pubDate>
    <description>We introduce and analyse an efficient decoder for the quantum Tanner codes of that can correct adversarial errors of linear weight. Previous decoders for quantum low-density parity-check codes could only handle adversarial errors of weight $O(\sqrt{n \log n})$. We also work on the link between quantum Tanner codes and the Lifted Product codes of Panteleev and Kalachev, and show that our decoder can be adapted to the latter. The decoding algorithm alternates between sequential and parallel procedures and converges in linear time.</description>
  </item>

  <item>
    <title>Composite Quantum Simulations</title>
    <link>http://arxiv.org/pdf/2206.06409</link>
    <author>Matthew Hagan, Nathan Wiebe</author>
    <pubDate>Jun 15 2022</pubDate>
    <description>In this paper we provide a framework for combining multiple quantum simulation methods, such as Trotter-Suzuki formulas and QDrift into a single composite channel that builds upon older coalescing ideas for reducing gate counts. The central idea behind our approach is to use a partitioning scheme that allocates a Hamiltonian term to the Trotter or QDrift part of a channel within the simulation. This allows us to simulate small but numerous terms using QDrift while simulating the larger terms using a high-order Trotter-Suzuki formula. We prove rigorous bounds on the diamond distance between the composite channel and the ideal simulation channel and show under what conditions the cost of implementing the composite channel is asymptotically upper bounded by the methods that comprise it for both probabilistic partitioning of terms and deterministic partitioning. Finally, we discuss strategies for determining partitioning schemes as well as methods for incorporating different simulation methods within the same framework.</description>
  </item>

  <item>
    <title>Provably efficient variational generative modeling of quantum many-body systems via quantum-probabilistic information geometry</title>
    <link>http://arxiv.org/pdf/2206.04663</link>
    <author>Faris M. Sbahi, Antonio J. Martinez, Sahil Patel, Dmitri Saberi, Jae Hyeon Yoo, Geoffrey Roeder, Guillaume Verdon</author>
    <pubDate>Jun 10 2022</pubDate>
    <description>The dual tasks of quantum Hamiltonian learning and quantum Gibbs sampling are relevant to many important problems in physics and chemistry. In the low temperature regime, algorithms for these tasks often suffer from intractabilities, for example from poor sample- or time-complexity. With the aim of addressing such intractabilities, we introduce a generalization of quantum natural gradient descent to parameterized mixed states, as well as provide a robust first-order approximating algorithm, Quantum-Probabilistic Mirror Descent. We prove data sample efficiency for the dual tasks using tools from information geometry and quantum metrology, thus generalizing the seminal result of classical Fisher efficiency to a variational quantum algorithm for the first time. Our approaches extend previously sample-efficient techniques to allow for flexibility in model choice, including to spectrally-decomposed models like Quantum Hamiltonian-Based Models, which may circumvent intractable time complexities. Our first-order algorithm is derived using a novel quantum generalization of the classical mirror descent duality. Both results require a special choice of metric, namely, the Bogoliubov-Kubo-Mori metric. To test our proposed algorithms numerically, we compare their performance to existing baselines on the task of quantum Gibbs sampling for the transverse field Ising model. Finally, we propose an initialization strategy leveraging geometric locality for the modelling of sequences of states such as those arising from quantum-stochastic processes. We demonstrate its effectiveness empirically for both real and imaginary time evolution while defining a broader class of potential applications.</description>
  </item>

  <item>
    <title>Avoiding barren plateaus via transferability of smooth solutions in Hamiltonian Variational Ansatz</title>
    <link>http://arxiv.org/pdf/2206.01982</link>
    <author>Antonio Anna Mele, Glen Bigan Mbeng, Giuseppe Ernesto Santoro, Mario Collura, Pietro Torta</author>
    <pubDate>Jun 07 2022</pubDate>
    <description>A large ongoing research effort focuses on Variational Quantum Algorithms (VQAs), representing leading candidates to achieve computational speed-ups on current quantum devices. The scalability of VQAs to a large number of qubits, beyond the simulation capabilities of classical computers, is still debated. Two major hurdles are the proliferation of low-quality variational local minima, and the exponential vanishing of gradients in the cost function landscape, a phenomenon referred to as barren plateaus. Here we show that by employing iterative search schemes one can effectively prepare the ground state of paradigmatic quantum many-body models, circumventing also the barren plateau phenomenon. This is accomplished by leveraging the transferability to larger system sizes of iterative solutions, displaying an intrinsic smoothness of the variational parameters, a result that does not extend to other solutions found via random-start local optimization. Our scheme could be directly tested on near-term quantum devices, running a refinement optimization in a favorable local landscape with non-vanishing gradients.</description>
  </item>

  <item>
    <title>Optimising shadow tomography with generalised measurements</title>
    <link>http://arxiv.org/pdf/2205.08990</link>
    <author>H. Chau Nguyen, Jan Lennart Bönsel, Jonathan Steinberg, Otfried Gühne</author>
    <pubDate>May 19 2022</pubDate>
    <description>Advances in quantum technology require scalable techniques to efficiently extract information from a quantum system, such as expectation values of observables or its entropy. Traditional tomography is limited to a handful of qubits and shadow tomography has been suggested as a scalable replacement for larger systems. Shadow tomography is conventionally analysed based on outcomes of ideal projective measurements on the system upon application of randomised unitaries. Here, we suggest that shadow tomography can be much more straightforwardly formulated for generalised measurements, or positive operator valued measures. Based on the idea of the least-square estimator, shadow tomography with generalised measurements is both more general and simpler than the traditional formulation with randomisation of unitaries. In particular, this formulation allows us to analyse theoretical aspects of shadow tomography in detail. For example, we provide a detailed study of the implication of symmetries in shadow tomography. Shadow tomography with generalised measurements is also indispensable in realistic implementation of quantum mechanical measurements, when noise is unavoidable. Moreover, we also demonstrate how the optimisation of measurements for shadow tomography tailored toward a particular set of observables can be carried out.</description>
  </item>

  <item>
    <title>Measurement incompatibility vs. Bell non-locality: an approach via tensor norms</title>
    <link>http://arxiv.org/pdf/2205.12668</link>
    <author>Faedi Loulidi, Ion Nechita</author>
    <pubDate>May 26 2022</pubDate>
    <description>Measurement incompatibility and quantum non-locality are two key features of quantum theory. Violations of Bell inequalities require quantum entanglement and incompatibility of the measurements used by the two parties involved in the protocol. We analyze the converse question: for which Bell inequalities is the incompatibility of measurements enough to ensure a quantum violation? We relate the two questions by comparing two tensor norms on the space of dichotomic quantum measurements: one characterizing measurement compatibility and the second one characterizing violations of a given Bell inequality. We provide sufficient conditions for the equivalence of the two notions in terms of the matrix describing the correlation Bell inequality. We show that the CHSH inequality and its variants are the only ones satisfying it.</description>
  </item>

  <item>
    <title>Classically optimized Hamiltonian simulation</title>
    <link>http://arxiv.org/pdf/2205.11427</link>
    <author>Conor Mc Keever, Michael Lubasch</author>
    <pubDate>May 24 2022</pubDate>
    <description>Hamiltonian simulation is a promising application for quantum computers to achieve a quantum advantage. We present classical algorithms based on tensor network methods to optimize quantum circuits for this task. We show that the classically optimized circuits can be orders of magnitude more accurate than Trotter product formulas.</description>
  </item>

  <item>
    <title>Estimating the frame potential of large-scale quantum circuit sampling using tensor networks up to 50 qubits</title>
    <link>http://arxiv.org/pdf/2205.09900</link>
    <author>Minzhao Liu, Junyu Liu, Yuri Alexeev, Liang Jiang</author>
    <pubDate>May 23 2022</pubDate>
    <description>We develop numerical protocols for estimating the frame potential, the 2-norm distance between a given ensemble and the exact Haar randomness, using the \textttQTensor platform. Our tensor-network-based algorithm has polynomial complexity for shallow circuits and is high performing using CPU and GPU parallelism. We apply the above methods to two problems: the Brown-Susskind conjecture, with local and parallel random circuits in terms of the Haar distance and the approximate $k$-design properties of the hardware efficient ansätze in quantum machine learning, which induce the barren plateau problem. We estimate frame potentials with these ensembles up to 50 qubits and $k=5$, examine the Haar distance of the hardware-efficient ansätze, and verify the Brown-Susskind conjecture numerically. Our work shows that large-scale tensor network simulations could provide important hints toward open problems in quantum information science.</description>
  </item>

  <item>
    <title>Mitigating barren plateaus of variational quantum eigensolvers</title>
    <link>http://arxiv.org/pdf/2205.13539</link>
    <author>Xia Liu, Geng Liu, Jiaxin Huang, Xin Wang</author>
    <pubDate>May 27 2022</pubDate>
    <description>Variational quantum algorithms (VQAs) are expected to establish valuable applications on near-term quantum computers. However, recent works have pointed out that the performance of VQAs greatly relies on the capability of the ansatzes and is seriously limited by optimization issues such as barren plateaus (i.e., vanishing gradients). This work proposes the state efficient ansatz (SEA) for accurate quantum dynamics simulations with improved trainability. First, we show that SEA can generate an arbitrary pure state with much fewer parameters than a universal ansatz, making it efficient for tasks like ground state estimation. It also has the flexibility in adjusting the entanglement of the prepared state, which could be applied to further improve the efficiency of simulating weak entanglement. Second, we show that SEA is not a unitary 2-design even if it has universal wavefunction expressibility and thus has great potential to improve the trainability by avoiding the zone of barren plateaus. We further investigate a plethora of examples in ground state estimation and notably obtain significant improvements in the variances of derivatives and the overall optimization behaviors. This result indicates that SEA can mitigate barren plateaus by sacrificing the redundant expressibility for the target problem.</description>
  </item>

  <item>
    <title>Average-case hardness of estimating probabilities of random quantum circuits with a linear scaling in the error exponent</title>
    <link>http://arxiv.org/pdf/2206.05642</link>
    <author>Hari Krovi</author>
    <pubDate>Jun 14 2022</pubDate>
    <description>We consider the hardness of computing additive approximations to output probabilities of random quantum circuits. We consider three random circuit families, namely, Haar random, $p=1$ QAOA, and random IQP circuits. Our results are as follows. For Haar random circuits with $m$ gates, we improve on prior results by showing $\mathsf{coC_=P}$ hardness of average-case additive approximations to an imprecision of $2^{-O(m)}$. Efficient classical simulation of such problems would imply the collapse of the polynomial hierarchy. For constant depth circuits i.e., when $m=O(n)$, this linear scaling in the exponent is within a constant of the scaling required to show hardness of sampling. Prior to our work, such a result was shown only for Boson Sampling in Bouland et al (2021). We also use recent results in polynomial interpolation to show $\mathsf{coC_=P}$ hardness under $\mathsf{BPP}$ reductions rather than $\mathsf{BPP}^{\mathsf{NP}}$ reductions. This improves the results of prior work for Haar random circuits both in terms of the error scaling and the power of reductions. Next, we consider random $p=1$ QAOA and IQP circuits and show that in the average-case, it is $\mathsf{coC_=P}$ hard to approximate the output probability to within an additive error of $2^{-O(n)}$. For $p=1$ QAOA circuits, this work constitutes the first average-case hardness result for the problem of approximating output probabilities for random QAOA circuits, which include Sherrington-Kirkpatrick and Erdös-Renyi graphs. For IQP circuits, a consequence of our results is that approximating the Ising partition function with imaginary couplings to an additive error of $2^{-O(n)}$ is hard even in the average-case, which extends prior work on worst-case hardness of multiplicative approximation to Ising partition functions.</description>
  </item>

</channel>

</rss>
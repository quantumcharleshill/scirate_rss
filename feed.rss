<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>A super-polynomial quantum advantage for combinatorial optimization problems</title>
    <link>http://arxiv.org/pdf/2212.08678</link>
    <author>Niklas Pirnay, Vincent Ulitzsch, Frederik Wilde, Jens Eisert, Jean-Pierre Seifert</author>
    <pubDate>Dec 20 2022</pubDate>
    <description>Combinatorial optimization - a field of research addressing problems that feature strongly in a wealth of practical and industrial contexts - has been identified as one of the core potential fields of applicability of near-term quantum computers. It is still unclear, however, to what extent variational quantum algorithms can actually outperform classical algorithms for this type of problems. In this work, by resorting to computational learning theory and cryptographic notions, we prove that fault-tolerant quantum computers feature a super-polynomial advantage over classical computers in approximating solutions to combinatorial optimization problems. Specifically, building on seminal work of Kearns and Valiant, we construct special instances of the integer programming problem (which in its most general form is NP-complete) that we prove to be hard-to-approximate classically but give an efficient quantum algorithm to approximate the optimal solution of those instances, hence showing a super-polynomial quantum advantage. This result shows that quantum devices have the power to approximate combinatorial optimization solutions beyond the reach of classical efficient algorithms.</description>
  </item>

  <item>
    <title>Unconditional Quantum Advantage for Sampling with Shallow Circuits</title>
    <link>http://arxiv.org/pdf/2301.00995</link>
    <author>Adam Bene Watts, Natalie Parham</author>
    <pubDate>Jan 04 2023</pubDate>
    <description>Recent work by Bravyi, Gosset, and Koenig showed that there exists a search problem that a constant-depth quantum circuit can solve, but that any constant-depth classical circuit with bounded fan-in cannot. They also pose the question: can we achieve a similar proof of separation for an input-independent sampling task? In this paper, we show that the answer to this question is yes. We introduce a distribution $D_{n}$ and give a constant-depth, $n$ qubit, quantum circuit that samples from a distribution close to $D_{n}$ in total variation distance. For any $\delta < 1$ we also prove, unconditionally, that any classical circuit with bounded fan-in gates that takes as input $n + n^\delta$ uniformly random bits and produces output close to $D_{n}$ in total variation distance has depth $\Omega(\log \log n)$. This gives an unconditional proof that constant-depth quantum circuits can sample from distributions which can't be reproduced by constant-depth bounded fan-in classical circuits, even up to additive error. The distribution $D_n$ and classical circuit lower bounds are based on work of Viola, in which he shows a different (but related) distribution cannot be sampled from approximately by constant-depth bounded fan-in classical circuits.</description>
  </item>

  <item>
    <title>Quantum advantage for combinatorial optimization problems, Simplified</title>
    <link>http://arxiv.org/pdf/2212.12572</link>
    <author>Mario Szegedy</author>
    <pubDate>Dec 27 2022</pubDate>
    <description>We observe that fault-tolerant quantum computers have an optimal advantage over classical computers in approximating solutions to many NP optimization problems. This observation however gives nothing in practice.</description>
  </item>

  <item>
    <title>Thrifty shadow estimation: re-using quantum circuits and bounding tails</title>
    <link>http://arxiv.org/pdf/2212.06240</link>
    <author>Jonas Helsen, Michael Walter</author>
    <pubDate>Dec 14 2022</pubDate>
    <description>Randomized shadow estimation is a recent protocol that allows estimating exponentially many expectation values of a quantum state from ``classical shadows'', obtained by applying random quantum circuits and computational basis measurements. In this paper we study the statistical efficiency of this approach in light of near-term quantum computing. In particular, we propose and analyze a more practically-implementable variant of the protocol, thrifty shadow estimation, in which quantum circuits are reused many times instead of having to be freshly generated for each measurement (as in the original protocol). We show that the effect of this reuse strongly depends on the family of quantum circuits that is chosen. In particular, it is maximally effective when sampling Haar random unitaries, and maximally ineffective when sampling Clifford circuits (even though the Clifford group forms a three-design). To interpolate between these two extremes, we provide an efficiently simulable family of quantum circuits inspired by a recent construction of approximate t-designs. Finally we consider tail bounds for shadow estimation and discuss when median-of-means estimation can be replaced with standard mean estimation.</description>
  </item>

  <item>
    <title>Quantum advantage and stability to errors in analogue quantum simulators</title>
    <link>http://arxiv.org/pdf/2212.04924</link>
    <author>Rahul Trivedi, Adrian Franco Rubio, J. Ignacio Cirac</author>
    <pubDate>Dec 12 2022</pubDate>
    <description>Several quantum hardware platforms, while being unable to perform fully fault-tolerant quantum computation, can still be operated as analogue quantum simulators for addressing many-body problems. However, due to the presence of errors, it is not clear to what extent those devices can provide us with an advantage with respect to classical computers. In this work we consider the use of noisy analogue quantum simulators for computing physically relevant properties of many-body systems both in equilibrium and undergoing dynamics. We first formulate a system-size independent notion of stability against extensive errors, which we prove for Gaussian fermion models, as well as for a restricted class of spin systems. Remarkably, for the Gaussian fermion models, our analysis shows the stability of critical (gapless) models at zero temperature which have long-range correlations. Furthermore, we analyze how this stability may lead to a quantum advantage, for the problem of computing the thermodynamic limits of many-body models, in the presence of a constant error rate and without any explicit error correction.</description>
  </item>

  <item>
    <title>Hardware-efficient learning of quantum many-body states</title>
    <link>http://arxiv.org/pdf/2212.06084</link>
    <author>Katherine Van Kirk, Jordan Cotler, Hsin-Yuan Huang, Mikhail D. Lukin</author>
    <pubDate>Dec 13 2022</pubDate>
    <description>Efficient characterization of highly entangled multi-particle systems is an outstanding challenge in quantum science. Recent developments have shown that a modest number of randomized measurements suffices to learn many properties of a quantum many-body system. However, implementing such measurements requires complete control over individual particles, which is unavailable in many experimental platforms. In this work, we present rigorous and efficient algorithms for learning quantum many-body states in systems with any degree of control over individual particles, including when every particle is subject to the same global field and no additional ancilla particles are available. We numerically demonstrate the effectiveness of our algorithms for estimating energy densities in a U(1) lattice gauge theory and classifying topological order using very limited measurement capabilities.</description>
  </item>

  <item>
    <title>Optimal lower bounds for Quantum Learning via Information Theory</title>
    <link>http://arxiv.org/pdf/2301.02227</link>
    <author>Shima Bab Hadiashar, Ashwin Nayak, Pulkit Sinha</author>
    <pubDate>Jan 06 2023</pubDate>
    <description>Although a concept class may be learnt more efficiently using quantum samples as compared with classical samples in certain scenarios, Arunachalam and de Wolf (JMLR, 2018) proved that quantum learners are asymptotically no more efficient than classical ones in the quantum PAC and Agnostic learning models. They established lower bounds on sample complexity via quantum state identification and Fourier analysis. In this paper, we derive optimal lower bounds for quantum sample complexity in both the PAC and agnostic models via an information-theoretic approach. The proofs are arguably simpler, and the same ideas can potentially be used to derive optimal bounds for other problems in quantum learning theory. We then turn to a quantum analogue of the Coupon Collector problem, a classic problem from probability theory also of importance in the study of PAC learning. Arunachalam, Belovs, Childs, Kothari, Rosmanis, and de Wolf (TQC, 2020) characterized the quantum sample complexity of this problem up to constant factors. First, we show that the information-theoretic approach mentioned above provably does not yield the optimal lower bound. As a by-product, we get a natural ensemble of pure states in arbitrarily high dimensions which are not easily (simultaneously) distinguishable, while the ensemble has close to maximal Holevo information. Second, we discover that the information-theoretic approach yields an asymptotically optimal bound for an approximation variant of the problem. Finally, we derive a sharp lower bound for the Quantum Coupon Collector problem, with the exact leading order term, via the Holevo-Curlander bounds on the distinguishability of an ensemble. All the aspects of the Quantum Coupon Collector problem we study rest on properties of the spectrum of the associated Gram matrix, which may be of independent interest.</description>
  </item>

  <item>
    <title>Noisy Stabilizer Formalism</title>
    <link>http://arxiv.org/pdf/2212.08677</link>
    <author>Maria Flors Mor-Ruiz, Wolfgang Dür</author>
    <pubDate>Dec 20 2022</pubDate>
    <description>Despite the exponential overhead to describe general multi-qubit quantum states and processes, efficient methods for certain state families and operations have been developed and utilised. The stabilizer formalism and the Gottesman-Knill theorem, where pure stabilizer or graph states are manipulated by Clifford operations and Pauli measurements, are prominent examples, and these states play a major role in many applications in quantum technologies. Here we develop a noisy stabilizer formalism, i.e., a method that allows one not only to efficiently describe and follow pure states under Clifford operations and Pauli measurements but also Pauli noise processes acting on such stabilizer states, including uncorrelated and correlated dephasing and single- or multi-qubit depolarizing noise. The method scales linearly in the number of qubits of the initial state, but exponentially in the size of the target state. Thus, whenever a noisy stabilizer state is manipulated by means of local Pauli measurements such that a multipartite entangled state of a few qubits is generated, one can efficiently describe the resulting state.</description>
  </item>

  <item>
    <title>Tailoring fusion-based error correction for high thresholds to biased fusion failures</title>
    <link>http://arxiv.org/pdf/2301.00019</link>
    <author>Kaavya Sahay, Jahan Claes, Shruti Puri</author>
    <pubDate>Jan 03 2023</pubDate>
    <description>We introduce fault-tolerant (FT) architectures for error correction with the XZZX cluster state based on performing measurements of two-qubit Pauli operators $Z\otimes Z$ and $X\otimes X$, or fusions, on a collection of few-body entangled resource states. Our construction is tailored to be effective against noise that predominantly causes faulty $X\otimes X$ measurements during fusions. This feature offers practical advantage in linear optical quantum computing with dual-rail photonic qubits, where failed fusions only erase $X\otimes X$ measurement outcomes. By applying our construction to this platform, we find a record high FT threshold to fusion failures exceeding $25\%$ in the experimentally relevant regime of non-zero loss rate per photon, considerably simplifying hardware requirements.</description>
  </item>

  <item>
    <title>High-threshold quantum computing by fusing one-dimensional cluster states</title>
    <link>http://arxiv.org/pdf/2212.06775</link>
    <author>Stefano Paesani, Benjamin J. Brown</author>
    <pubDate>Dec 14 2022</pubDate>
    <description>We propose a measurement-based model for fault-tolerant quantum computation that can be realised with one-dimensional cluster states and fusion measurements only; basic resources that are readily available with scalable photonic hardware. Our simulations demonstrate high thresholds compared with other measurement-based models realized with basic entangled resources and two-qubit fusion measurements. Its high tolerance to noise indicates that our practical construction offers a promising route to scalable quantum computing with quantum emitters and linear-optical elements.</description>
  </item>

  <item>
    <title>Quantum Mass Production Theorems</title>
    <link>http://arxiv.org/pdf/2212.14399</link>
    <author>William Kretschmer</author>
    <pubDate>Jan 02 2023</pubDate>
    <description>We prove that for any $n$-qubit unitary transformation $U$ and for any $r = 2^{o(n / \log n)}$, there exists a quantum circuit to implement $U^{\otimes r}$ with at most $O(4^n)$ gates. This asymptotically equals the number of gates needed to implement just a single copy of a worst-case $U$. We also establish analogous results for quantum states and diagonal unitary transformations. Our techniques are based on the work of Uhlig [Math. Notes 1974], who proved a similar mass production theorem for Boolean functions.</description>
  </item>

  <item>
    <title>Sharp complexity phase transitions generated by entanglement</title>
    <link>http://arxiv.org/pdf/2212.10582</link>
    <author>Soumik Ghosh, Abhinav Deshpande, Dominik Hangleiter, Alexey V. Gorshkov, Bill Fefferman</author>
    <pubDate>Dec 22 2022</pubDate>
    <description>Entanglement is one of the physical properties of quantum systems responsible for the computational hardness of simulating quantum systems. But while the runtime of specific algorithms, notably tensor network algorithms, explicitly depends on the amount of entanglement in the system, it is unknown whether this connection runs deeper and entanglement can also cause inherent, algorithm-independent complexity. In this work, we quantitatively connect the entanglement present in certain quantum systems to the computational complexity of simulating those systems. Moreover, we completely characterize the entanglement and complexity as a function of a system parameter. Specifically, we consider the task of simulating single-qubit measurements of $k$--regular graph states on $n$ qubits. We show that, as the regularity parameter is increased from $1$ to $n-1$, there is a sharp transition from an easy regime with low entanglement to a hard regime with high entanglement at $k=3$, and a transition back to easy and low entanglement at $k=n-3$. As a key technical result, we prove a duality for the simulation complexity of regular graph states between low and high regularity.</description>
  </item>

  <item>
    <title>Simple and high-precision Hamiltonian simulation by compensating Trotter error with linear combination of unitary operations</title>
    <link>http://arxiv.org/pdf/2212.04566</link>
    <author>Pei Zeng, Jinzhao Sun, Liang Jiang, Qi Zhao</author>
    <pubDate>Dec 12 2022</pubDate>
    <description>Trotter and linear-combination-of-unitary (LCU) are two popular Hamiltonian simulation methods. We propose Hamiltonian simulation algorithms using LCU to compensate Trotter error, which enjoy both of their advantages. By adding few gates after the Kth-order Trotter, we realize a better time scaling than 2Kth-order Trotter. Our first algorithm exponentially improves the accuracy scaling of the Kth-order Trotter formula. In the second algorithm, we consider the detailed structure of Hamiltonians and construct LCU for Trotter errors with commutator scaling. Consequently, for lattice Hamiltonians, the algorithm enjoys almost linear system-size dependence and quadratically improves the accuracy of the Kth-order Trotter.</description>
  </item>

  <item>
    <title>Asymptotic Equipartition Theorems in von Neumann algebras</title>
    <link>http://arxiv.org/pdf/2212.14700</link>
    <author>Omar Fawzi, Li Gao, Mizanur Rahaman</author>
    <pubDate>Jan 02 2023</pubDate>
    <description>The Asymptotic Equipartition Property (AEP) in information theory establishes that independent and identically distributed (i.i.d.) states behave in a way that is similar to uniform states. In particular, with appropriate smoothing, for such states both the min and the max relative entropy asymptotically coincide with the relative entropy. In this paper, we generalize several such equipartition properties to states on general von Neumann algebras. First, we show that the smooth max relative entropy of i.i.d. states on a von Neumann algebra has an asymptotic rate given by the quantum relative entropy. In fact, our AEP not only applies to states, but also to quantum channels with appropriate restrictions. In addition, going beyond the i.i.d. assumption, we show that for states that are produced by a sequential process of quantum channels, the smooth max relative entropy can be upper bounded by the sum of appropriate channel relative entropies. Our main technical contributions are to extend to the context of general von Neumann algebras a chain rule for quantum channels, as well as an additivity result for the channel relative entropy with a replacer channel.</description>
  </item>

  <item>
    <title>Fault-tolerant error correction for a universal non-Abelian topological quantum computer at finite temperature</title>
    <link>http://arxiv.org/pdf/2301.00054</link>
    <author>Alexis Schotte, Lander Burgelman, Guanyu Zhu</author>
    <pubDate>Jan 03 2023</pubDate>
    <description>We study fault-tolerant error correction in a quantum memory constructed as a two-dimensional model of Fibonacci anyons on a torus, in the presence of thermal noise represented by pair-creation processes and measurement errors. The correction procedure is based on the cellular automaton decoders originating in the works of Gács and Harrington. Through numerical simulations, we observe that this code behaves fault-tolerantly and that threshold behavior is likely present. Hence, we provide strong evidence for the existence of a fault-tolerant universal non-Abelian topological quantum computer.</description>
  </item>

  <item>
    <title>Approaching the Quantum Singleton Bound with Approximate Error Correction</title>
    <link>http://arxiv.org/pdf/2212.09935</link>
    <author>Thiago Bergamaschi, Louis Golowich, Sam Gunn</author>
    <pubDate>Dec 21 2022</pubDate>
    <description>It is well known that no quantum error correcting code of rate $R$ can correct adversarial errors on more than a $(1-R)/4$ fraction of symbols. But what if we only require our codes to *approximately* recover the message? We construct efficiently-decodable approximate quantum codes against adversarial error rates approaching the quantum Singleton bound of $(1-R)/2$, for any constant rate $R$. Moreover, the size of the alphabet is a constant independent of the message length and the recovery error is exponentially small in the message length. Central to our construction is a notion of quantum list decoding and an implementation involving folded quantum Reed-Solomon codes.</description>
  </item>

  <item>
    <title>Quantum simulation of exact electron dynamics can be more efficient than classical mean-field methods</title>
    <link>http://arxiv.org/pdf/2301.01203</link>
    <author>Ryan Babbush, William J. Huggins, Dominic W. Berry, Shu Fay Ung, Andrew Zhao, David R. Reichman, Hartmut Neven, Andrew D. Baczewski, Joonho Lee</author>
    <pubDate>Jan 04 2023</pubDate>
    <description>Quantum algorithms for simulating electronic ground states are slower than popular classical mean-field algorithms such as Hartree-Fock and density functional theory, but offer higher accuracy. Accordingly, quantum computers have been predominantly regarded as competitors to only the most accurate and costly classical methods for treating electron correlation. However, here we tighten bounds showing that certain first quantized quantum algorithms enable exact time evolution of electronic systems with exponentially less space and polynomially fewer operations in basis set size than conventional real-time time-dependent Hartree-Fock and density functional theory. Although the need to sample observables in the quantum algorithm reduces the speedup, we show that one can estimate all elements of the $k$-particle reduced density matrix with a number of samples scaling only polylogarithmically in basis set size. We also introduce a more efficient quantum algorithm for first quantized mean-field state preparation that is likely cheaper than the cost of time evolution. We conclude that quantum speedup is most pronounced for finite temperature simulations and suggest several practically important electron dynamics problems with potential quantum advantage.</description>
  </item>

  <item>
    <title>Operator relaxation and the optimal depth of classical shadows</title>
    <link>http://arxiv.org/pdf/2212.11963</link>
    <author>Matteo Ippoliti, Yaodong Li, Tibor Rakovszky, Vedika Khemani</author>
    <pubDate>Dec 23 2022</pubDate>
    <description>Classical shadows are a powerful method for learning many properties of quantum states in a sample-efficient manner, by making use of randomized measurements. Here we study the sample complexity of learning the expectation value of Pauli operators via ``shallow shadows'', a recently-proposed version of classical shadows in which the randomization step is effected by a local unitary circuit of variable depth $t$. We show that the state-averaged shadow norm (the quantity controlling the average sample complexity) is expressed in terms of properties of the Heisenberg time evolution of operators under the randomizing (``twirling'') circuit -- namely the evolution of the weight distribution characterizing the number of sites on which an operator acts nontrivially. For spatially-contiguous operators of weight $k$, this entails a competition between two processes: operator spreading (whereby the support of an operator grows over time, increasing its weight) and operator relaxation (whereby the bulk of the operator develops an equilibrium density of identity operators, decreasing its weight). From this simple picture we derive (i) an upper bound on the shadow norm which, for depth $t\sim \log(k)$, guarantees an exponential gain in sample complexity over the $t=0$ protocol in any spatial dimension, and (ii) quantitative results in one dimension within a mean-field approximation, including a universal subleading correction to the optimal depth, found to be in excellent agreement with infinite matrix product state numerical simulations. Our work connects fundamental ideas in quantum many-body dynamics to applications in quantum information science, and paves the way to highly-optimized protocols for learning different properties of quantum states.</description>
  </item>

  <item>
    <title>Low-depth random Clifford circuits for quantum coding against Pauli noise using a tensor-network decoder</title>
    <link>http://arxiv.org/pdf/2212.05071</link>
    <author>Andrew S. Darmawan, Yoshifumi Nakata, Shiro Tamiya, Hayata Yamasaki</author>
    <pubDate>Dec 13 2022</pubDate>
    <description>Recent work [M. J. Gullans et al., Physical Review X, 11(3):031066 (2021)] has shown that quantum error correcting codes defined by random Clifford encoding circuits can achieve a non-zero encoding rate in correcting errors even if the random circuits on $n$ qubits, embedded in one spatial dimension (1D), have a logarithmic depth $d=\mathcal{O}(\log{n})$. However, this was demonstrated only for a simple erasure noise model. In this work, we discover that this desired property indeed holds for the conventional Pauli noise model. Specifically, we numerically demonstrate that the hashing bound, i.e., a rate known to be achieved with $d=\mathcal{O}(n)$-depth random encoding circuits, can be attained even when the circuit depth is restricted to $d=\mathcal{O}(\log n)$ in 1D for depolarizing noise of various strengths. This analysis is made possible with our development of a tensor-network maximum-likelihood decoding algorithm that works efficiently for $\log$-depth encoding circuits in 1D.</description>
  </item>

  <item>
    <title>Non-Exponential Behaviour in Logical Randomized Benchmarking</title>
    <link>http://arxiv.org/pdf/2212.05488</link>
    <author>Athena Ceasura, Pavithran Iyer, Joel J. Wallman, Hakop Pashayan</author>
    <pubDate>Dec 13 2022</pubDate>
    <description>We construct a gate and time-independent noise model that results in the output of a logical randomized benchmarking protocol oscillating rather than decaying exponentially. To illustrate our idea, we first construct an example in standard randomized benchmarking where we assume the existence of ``hidden'' qubits, permitting a choice of representation of the Clifford group that contains multiplicities. We use the multiplicities to, with each gate application, update a hidden memory of the gate history that we use to circumvent theorems which guarantee the output decays exponentially. In our focal setting of logical randomized benchmarking, we show that the presence of machinery associated with the implementation of quantum error correction can facilitate non-exponential decay. Since, in logical randomized benchmarking, the role of the hidden qubits is assigned to the syndrome qubits used in error correction and these are strongly coupled to the logical qubits via a decoder.</description>
  </item>

  <item>
    <title>One-Way Ticket to Las Vegas and the Quantum Adversary</title>
    <link>http://arxiv.org/pdf/2301.02003</link>
    <author>Aleksandrs Belovs, Duyal Yolcu</author>
    <pubDate>Jan 06 2023</pubDate>
    <description>We propose a new definition of quantum Las Vegas query complexity. We show that it is exactly equal to the quantum adversary bound. This is achieved by a new and very simple way of transforming a feasible solution to the adversary optimisation problem into a quantum query algorithm. This allows us to generalise the bound to include unidirectional access, multiple input oracles, and input oracles that are not unitary. As an application, we demonstrate a separation between unidirectional and bidirectional access to an input oracle for a rather natural unitary permutation inversion problem.</description>
  </item>

  <item>
    <title>Algorithmic Shadow Spectroscopy</title>
    <link>http://arxiv.org/pdf/2212.11036</link>
    <author>Hans Hon Sang Chan, Richard Meister, Matthew L. Goh, Bálint Koczor</author>
    <pubDate>Dec 22 2022</pubDate>
    <description>Finding energy differences between eigenstates of a quantum system, which contains key information about its properties, is a central task in many-body physics. Quantum computers promise to perform this task more efficiently than classical hardware; however, extraction of this information remains challenging. Non-trivial protocols for this task require either a substantial increase in circuit complexity (phase estimation) or a large number of circuit repetitions (variational quantum eigensolvers). Here we present shadow spectroscopy, a novel simulator-agnostic quantum algorithm which extracts energy gaps using an extremely low number of circuit repetitions (shots) and no extra resources (ancilla qubits) beyond performing time evolution and measurements. The approach builds on the fundamental feature that every observable property of a quantum system must evolve according to the same harmonic components, whose frequencies can be extracted from classical shadows of time-evolved quantum states. Classical post processing of the large set of resulting time-periodic signals directly reveals Hamiltonian energy differences with Heisenberg-limited precision. While the classical computational complexity is linear, the number of circuit repetitions (quantum resources) required is only logarithmic in the number of analysed observables. Moreover, applying shadow spectroscopy numerically to probe model systems and CH$_2$ excited states verifies that the approach is intuitively easy to use in practice, very robust against gate noise, amiable to a new type of algorithmic-error mitigation technique, and uses orders of magnitude fewer number of shots than typical near-term quantum algorithms -- as low as 10 shots per timestep is sufficient.</description>
  </item>

  <item>
    <title>Grothendieck inequalities characterize converses to the polynomial method</title>
    <link>http://arxiv.org/pdf/2212.08559</link>
    <author>Jop Briët, Francisco Escudero Gutiérrez, Sander Gribling</author>
    <pubDate>Dec 19 2022</pubDate>
    <description>A surprising 'converse to the polynomial method' of Aaronson et al. (CCC'16) shows that any bounded quadratic polynomial can be computed exactly in expectation by a 1-query algorithm up to a universal multiplicative factor related to the famous Grothendieck constant. Here we show that such a result does not generalize to quartic polynomials and 2-query algorithms, even when we allow for additive approximations. We also show that the additive approximation implied by their result is tight for bounded bilinear forms, which gives a new characterization of the Grothendieck constant in terms of 1-query quantum algorithms. Along the way we provide reformulations of the completely bounded norm of a form, and its dual norm.</description>
  </item>

  <item>
    <title>A graph-state based synthesis framework for Clifford isometries</title>
    <link>http://arxiv.org/pdf/2212.06928</link>
    <author>Timothée Goubault de Brugière, Simon Martiel, Christophe Vuillot</author>
    <pubDate>Dec 15 2022</pubDate>
    <description>We tackle the problem of Clifford isometry compilation, i.e, how to synthesize a Clifford isometry into an executable quantum circuit. We propose a simple framework for synthesis that only exploits the elementary properties of the Clifford group and one equation of the symplectic group. We highlight the versatility of our framework by showing that several normal forms of the literature are natural corollaries. We report an improvement of the two-qubit depth necessary for the execution of a Clifford circuit on an LNN architecture. We also apply our framework to the synthesis of graph states and the codiagonalization of Pauli rotations and we improve the 2-qubit count and 2-qubit depth of circuits taken from quantum chemistry experiments.</description>
  </item>

  <item>
    <title>Upper Bounds on the Distillable Randomness of Bipartite Quantum States</title>
    <link>http://arxiv.org/pdf/2212.09073</link>
    <author>Ludovico Lami, Bartosz Regula, Xin Wang, Mark M. Wilde</author>
    <pubDate>Dec 20 2022</pubDate>
    <description>The distillable randomness of a bipartite quantum state is an information-theoretic quantity equal to the largest net rate at which shared randomness can be distilled from the state by means of local operations and classical communication. This quantity has been widely used as a measure of classical correlations, and one version of it is equal to the regularized Holevo information of the ensemble that results from measuring one share of the state. However, due to the regularization, the distillable randomness is difficult to compute in general. To address this problem, we define measures of classical correlations and prove a number of their properties, most importantly that they serve as upper bounds on the distillable randomness of an arbitrary bipartite state. We then further bound these measures from above by some that are efficiently computable by means of semi-definite programming, we evaluate one of them for the example of an isotropic state, and we remark on the relation to quantities previously proposed in the literature.</description>
  </item>

  <item>
    <title>Improved Error Scaling for Trotter Simulations through Extrapolation</title>
    <link>http://arxiv.org/pdf/2212.14144</link>
    <author>Gumaro Rendon, Jacob Watkins, Nathan Wiebe</author>
    <pubDate>Jan 02 2023</pubDate>
    <description>In recent years, Trotter formulas have emerged as a leading approach for simulating quantum dynamics on quantum computers, owing to their ability to exploit locality and commutator structure of the Hamiltonian. However, a major problem facing Trotter formulas is their inability to achieve poly-logarithmic scaling with the error tolerance. We address this problem by providing a well-conditioned extrapolation scheme that takes data from Trotter-Suzuki simulations obtained for specifically chosen Trotter step sizes and estimates the value that would be seen in the limit where the Trotter step size goes to zero. We show this leads, even for the first order Trotter formula, to $\tilde{O}(1/\epsilon)$ scaling for phase estimation and $\tilde{O}(t^2/\epsilon)$ scaling for estimating time-evolved expectation values for simulation time $t$ and error tolerance $\epsilon$. This is better scaling with the error tolerance than the best known un-extrapolated Trotter formulas. Additionally, we provide a new approach for phase estimation that is unbiased and also provide a new approach for estimating the Trotter error on a quantum computer through extrapolation which yields a new way to independently assess the errors in a Trotter simulation.</description>
  </item>

  <item>
    <title>On linear-algebraic notions of expansion</title>
    <link>http://arxiv.org/pdf/2212.13154</link>
    <author>Yinan Li, Youming Qiao, Avi Wigderson, Yuval Wigderson, Chuanqi Zhang</author>
    <pubDate>Dec 27 2022</pubDate>
    <description>A fundamental fact about bounded-degree graph expanders is that three notions of expansion -- vertex expansion, edge expansion, and spectral expansion -- are all equivalent. In this paper, we study to what extent such a statement is true for linear-algebraic notions of expansion. There are two well-studied notions of linear-algebraic expansion, namely dimension expansion (defined in analogy to graph vertex expansion) and quantum expansion (defined in analogy to graph spectral expansion). Lubotzky and Zelmanov proved that the latter implies the former. We prove that the converse is false: there are dimension expanders which are not quantum expanders. Moreover, this asymmetry is explained by the fact that there are two distinct linear-algebraic analogues of graph edge expansion. The first of these is quantum edge expansion, which was introduced by Hastings, and which he proved to be equivalent to quantum expansion. We introduce a new notion, termed dimension edge expansion, which we prove is equivalent to dimension expansion and which is implied by quantum edge expansion. Thus, the separation above is implied by a finer one: dimension edge expansion is strictly weaker than quantum edge expansion. This new notion also leads to a new, more modular proof of the Lubotzky--Zelmanov result that quantum expanders are dimension expanders.</description>
  </item>

  <item>
    <title>General guarantees for randomized benchmarking with random quantum circuits</title>
    <link>http://arxiv.org/pdf/2212.06181</link>
    <author>Markus Heinrich, Martin Kliesch, Ingo Roth</author>
    <pubDate>Dec 14 2022</pubDate>
    <description>In its many variants, randomized benchmarking (RB) is a broadly used technique for assessing the quality of gate implementations on quantum computers. A detailed theoretical understanding and general guarantees exist for the functioning and interpretation of RB protocols if the gates under scrutiny are drawn uniformly at random from a compact group. In contrast, many practically attractive and scalable RB protocols implement random quantum circuits with local gates randomly drawn from some gate-set. Despite their abundance in practice, for those non-uniform RB protocols, general guarantees under experimentally plausible assumptions are missing. In this work, we derive such guarantees for a large class of RB protocols for random circuits that we refer to as filtered RB. Prominent examples include linear cross-entropy benchmarking, character benchmarking, Pauli-noise tomography and variants of simultaneous RB. Building upon recent results for random circuits, we show that many relevant filtered RB schemes can be realized with random quantum circuits in linear depth, and we provide explicit small constants for common instances. We further derive general sample complexity bounds for filtered RB. We show filtered RB to be sample-efficient for several relevant groups, including protocols addressing higher-order cross-talk. Our theory for non-uniform filtered RB is, in principle, flexible enough to design new protocols for non-universal and analog quantum simulators.</description>
  </item>

  <item>
    <title>Measuring out quasi-local integrals of motion from entanglement</title>
    <link>http://arxiv.org/pdf/2301.01787</link>
    <author>B. Lu, C. Bertoni, S. J. Thomson, J. Eisert</author>
    <pubDate>Jan 06 2023</pubDate>
    <description>Quasi-local integrals of motion are a key concept underpinning the modern understanding of many-body localisation, an intriguing phenomenon in which interactions and disorder come together. Despite the existence of several numerical ways to compute them - and astoundingly in the light of the observation that much of the phenomenology of many properties can be derived from them - it is not obvious how to directly measure aspects of them in real quantum simulations; in fact, the smoking gun of their experimental observation is arguably still missing. In this work, we propose a way to extract the real-space properties of such quasi-local integrals of motion based on a spatially-resolved entanglement probe able to distinguish Anderson from many-body localisation from non-equilibrium dynamics. We complement these findings with a new rigorous entanglement bound and compute the relevant quantities using tensor networks. We demonstrate that the entanglement gives rise to a well-defined length scale that can be measured in experiments.</description>
  </item>

  <item>
    <title>Fast Time-Evolution of Matrix-Product States using the QR decomposition</title>
    <link>http://arxiv.org/pdf/2212.09782</link>
    <author>Jakob Unfried, Johannes Hauschild, Frank Pollmann</author>
    <pubDate>Dec 21 2022</pubDate>
    <description>We propose and benchmark a modified time evolution block decimation (TEBD) algorithm that uses a truncation scheme based on the QR decomposition instead of the singular value decomposition (SVD). The modification reduces the scaling with the dimension of the physical Hilbert space $d$ from $d^3$ down to $d^2$. Moreover, the QR decomposition has a lower computational complexity than the SVD and allows for highly efficient implementations on GPU hardware. In a benchmark simulation of a global quench in a quantum clock model, we observe a speedup of up to three orders of magnitude comparing QR and SVD based updates on an A100 GPU.</description>
  </item>

</channel>

</rss>
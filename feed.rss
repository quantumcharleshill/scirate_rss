<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>A super-polynomial quantum advantage for combinatorial optimization problems</title>
    <link>http://arxiv.org/pdf/2212.08678</link>
    <author>Niklas Pirnay, Vincent Ulitzsch, Frederik Wilde, Jens Eisert, Jean-Pierre Seifert</author>
    <pubDate>Dec 20 2022</pubDate>
    <description>Combinatorial optimization - a field of research addressing problems that feature strongly in a wealth of practical and industrial contexts - has been identified as one of the core potential fields of applicability of near-term quantum computers. It is still unclear, however, to what extent variational quantum algorithms can actually outperform classical algorithms for this type of problems. In this work, by resorting to computational learning theory and cryptographic notions, we prove that fault-tolerant quantum computers feature a super-polynomial advantage over classical computers in approximating solutions to combinatorial optimization problems. Specifically, building on seminal work of Kearns and Valiant, we construct special instances of the integer programming problem (which in its most general form is NP-complete) that we prove to be hard-to-approximate classically but give an efficient quantum algorithm to approximate the optimal solution of those instances, hence showing a super-polynomial quantum advantage. This result shows that quantum devices have the power to approximate combinatorial optimization solutions beyond the reach of classical efficient algorithms.</description>
  </item>

  <item>
    <title>Unconditional Quantum Advantage for Sampling with Shallow Circuits</title>
    <link>http://arxiv.org/pdf/2301.00995</link>
    <author>Adam Bene Watts, Natalie Parham</author>
    <pubDate>Jan 04 2023</pubDate>
    <description>Recent work by Bravyi, Gosset, and Koenig showed that there exists a search problem that a constant-depth quantum circuit can solve, but that any constant-depth classical circuit with bounded fan-in cannot. They also pose the question: can we achieve a similar proof of separation for an input-independent sampling task? In this paper, we show that the answer to this question is yes. We introduce a distribution $D_{n}$ and give a constant-depth, $n$ qubit, quantum circuit that samples from a distribution close to $D_{n}$ in total variation distance. For any $\delta < 1$ we also prove, unconditionally, that any classical circuit with bounded fan-in gates that takes as input $n + n^\delta$ uniformly random bits and produces output close to $D_{n}$ in total variation distance has depth $\Omega(\log \log n)$. This gives an unconditional proof that constant-depth quantum circuits can sample from distributions which can't be reproduced by constant-depth bounded fan-in classical circuits, even up to additive error. The distribution $D_n$ and classical circuit lower bounds are based on work of Viola, in which he shows a different (but related) distribution cannot be sampled from approximately by constant-depth bounded fan-in classical circuits.</description>
  </item>

  <item>
    <title>Quantum advantage for combinatorial optimization problems, Simplified</title>
    <link>http://arxiv.org/pdf/2212.12572</link>
    <author>Mario Szegedy</author>
    <pubDate>Dec 27 2022</pubDate>
    <description>We observe that fault-tolerant quantum computers have an optimal advantage over classical computers in approximating solutions to many NP optimization problems. This observation however gives nothing in practice.</description>
  </item>

  <item>
    <title>Thrifty shadow estimation: re-using quantum circuits and bounding tails</title>
    <link>http://arxiv.org/pdf/2212.06240</link>
    <author>Jonas Helsen, Michael Walter</author>
    <pubDate>Dec 14 2022</pubDate>
    <description>Randomized shadow estimation is a recent protocol that allows estimating exponentially many expectation values of a quantum state from ``classical shadows'', obtained by applying random quantum circuits and computational basis measurements. In this paper we study the statistical efficiency of this approach in light of near-term quantum computing. In particular, we propose and analyze a more practically-implementable variant of the protocol, thrifty shadow estimation, in which quantum circuits are reused many times instead of having to be freshly generated for each measurement (as in the original protocol). We show that the effect of this reuse strongly depends on the family of quantum circuits that is chosen. In particular, it is maximally effective when sampling Haar random unitaries, and maximally ineffective when sampling Clifford circuits (even though the Clifford group forms a three-design). To interpolate between these two extremes, we provide an efficiently simulable family of quantum circuits inspired by a recent construction of approximate t-designs. Finally we consider tail bounds for shadow estimation and discuss when median-of-means estimation can be replaced with standard mean estimation.</description>
  </item>

  <item>
    <title>Optimal lower bounds for Quantum Learning via Information Theory</title>
    <link>http://arxiv.org/pdf/2301.02227</link>
    <author>Shima Bab Hadiashar, Ashwin Nayak, Pulkit Sinha</author>
    <pubDate>Jan 06 2023</pubDate>
    <description>Although a concept class may be learnt more efficiently using quantum samples as compared with classical samples in certain scenarios, Arunachalam and de Wolf (JMLR, 2018) proved that quantum learners are asymptotically no more efficient than classical ones in the quantum PAC and Agnostic learning models. They established lower bounds on sample complexity via quantum state identification and Fourier analysis. In this paper, we derive optimal lower bounds for quantum sample complexity in both the PAC and agnostic models via an information-theoretic approach. The proofs are arguably simpler, and the same ideas can potentially be used to derive optimal bounds for other problems in quantum learning theory. We then turn to a quantum analogue of the Coupon Collector problem, a classic problem from probability theory also of importance in the study of PAC learning. Arunachalam, Belovs, Childs, Kothari, Rosmanis, and de Wolf (TQC, 2020) characterized the quantum sample complexity of this problem up to constant factors. First, we show that the information-theoretic approach mentioned above provably does not yield the optimal lower bound. As a by-product, we get a natural ensemble of pure states in arbitrarily high dimensions which are not easily (simultaneously) distinguishable, while the ensemble has close to maximal Holevo information. Second, we discover that the information-theoretic approach yields an asymptotically optimal bound for an approximation variant of the problem. Finally, we derive a sharp lower bound for the Quantum Coupon Collector problem, with the exact leading order term, via the Holevo-Curlander bounds on the distinguishability of an ensemble. All the aspects of the Quantum Coupon Collector problem we study rest on properties of the spectrum of the associated Gram matrix, which may be of independent interest.</description>
  </item>

  <item>
    <title>Noisy Stabilizer Formalism</title>
    <link>http://arxiv.org/pdf/2212.08677</link>
    <author>Maria Flors Mor-Ruiz, Wolfgang DÃ¼r</author>
    <pubDate>Dec 20 2022</pubDate>
    <description>Despite the exponential overhead to describe general multi-qubit quantum states and processes, efficient methods for certain state families and operations have been developed and utilised. The stabilizer formalism and the Gottesman-Knill theorem, where pure stabilizer or graph states are manipulated by Clifford operations and Pauli measurements, are prominent examples, and these states play a major role in many applications in quantum technologies. Here we develop a noisy stabilizer formalism, i.e., a method that allows one not only to efficiently describe and follow pure states under Clifford operations and Pauli measurements but also Pauli noise processes acting on such stabilizer states, including uncorrelated and correlated dephasing and single- or multi-qubit depolarizing noise. The method scales linearly in the number of qubits of the initial state, but exponentially in the size of the target state. Thus, whenever a noisy stabilizer state is manipulated by means of local Pauli measurements such that a multipartite entangled state of a few qubits is generated, one can efficiently describe the resulting state.</description>
  </item>

  <item>
    <title>Tailoring fusion-based error correction for high thresholds to biased fusion failures</title>
    <link>http://arxiv.org/pdf/2301.00019</link>
    <author>Kaavya Sahay, Jahan Claes, Shruti Puri</author>
    <pubDate>Jan 03 2023</pubDate>
    <description>We introduce fault-tolerant (FT) architectures for error correction with the XZZX cluster state based on performing measurements of two-qubit Pauli operators $Z\otimes Z$ and $X\otimes X$, or fusions, on a collection of few-body entangled resource states. Our construction is tailored to be effective against noise that predominantly causes faulty $X\otimes X$ measurements during fusions. This feature offers practical advantage in linear optical quantum computing with dual-rail photonic qubits, where failed fusions only erase $X\otimes X$ measurement outcomes. By applying our construction to this platform, we find a record high FT threshold to fusion failures exceeding $25\%$ in the experimentally relevant regime of non-zero loss rate per photon, considerably simplifying hardware requirements.</description>
  </item>

  <item>
    <title>Quantum Mass Production Theorems</title>
    <link>http://arxiv.org/pdf/2212.14399</link>
    <author>William Kretschmer</author>
    <pubDate>Jan 02 2023</pubDate>
    <description>We prove that for any $n$-qubit unitary transformation $U$ and for any $r = 2^{o(n / \log n)}$, there exists a quantum circuit to implement $U^{\otimes r}$ with at most $O(4^n)$ gates. This asymptotically equals the number of gates needed to implement just a single copy of a worst-case $U$. We also establish analogous results for quantum states and diagonal unitary transformations. Our techniques are based on the work of Uhlig [Math. Notes 1974], who proved a similar mass production theorem for Boolean functions.</description>
  </item>

  <item>
    <title>Sharp complexity phase transitions generated by entanglement</title>
    <link>http://arxiv.org/pdf/2212.10582</link>
    <author>Soumik Ghosh, Abhinav Deshpande, Dominik Hangleiter, Alexey V. Gorshkov, Bill Fefferman</author>
    <pubDate>Dec 22 2022</pubDate>
    <description>Entanglement is one of the physical properties of quantum systems responsible for the computational hardness of simulating quantum systems. But while the runtime of specific algorithms, notably tensor network algorithms, explicitly depends on the amount of entanglement in the system, it is unknown whether this connection runs deeper and entanglement can also cause inherent, algorithm-independent complexity. In this work, we quantitatively connect the entanglement present in certain quantum systems to the computational complexity of simulating those systems. Moreover, we completely characterize the entanglement and complexity as a function of a system parameter. Specifically, we consider the task of simulating single-qubit measurements of $k$--regular graph states on $n$ qubits. We show that, as the regularity parameter is increased from $1$ to $n-1$, there is a sharp transition from an easy regime with low entanglement to a hard regime with high entanglement at $k=3$, and a transition back to easy and low entanglement at $k=n-3$. As a key technical result, we prove a duality for the simulation complexity of regular graph states between low and high regularity.</description>
  </item>

  <item>
    <title>High-threshold quantum computing by fusing one-dimensional cluster states</title>
    <link>http://arxiv.org/pdf/2212.06775</link>
    <author>Stefano Paesani, Benjamin J. Brown</author>
    <pubDate>Dec 14 2022</pubDate>
    <description>We propose a measurement-based model for fault-tolerant quantum computation that can be realised with one-dimensional cluster states and fusion measurements only; basic resources that are readily available with scalable photonic hardware. Our simulations demonstrate high thresholds compared with other measurement-based models realized with basic entangled resources and two-qubit fusion measurements. Its high tolerance to noise indicates that our practical construction offers a promising route to scalable quantum computing with quantum emitters and linear-optical elements.</description>
  </item>

  <item>
    <title>Asymptotic Equipartition Theorems in von Neumann algebras</title>
    <link>http://arxiv.org/pdf/2212.14700</link>
    <author>Omar Fawzi, Li Gao, Mizanur Rahaman</author>
    <pubDate>Jan 02 2023</pubDate>
    <description>The Asymptotic Equipartition Property (AEP) in information theory establishes that independent and identically distributed (i.i.d.) states behave in a way that is similar to uniform states. In particular, with appropriate smoothing, for such states both the min and the max relative entropy asymptotically coincide with the relative entropy. In this paper, we generalize several such equipartition properties to states on general von Neumann algebras. First, we show that the smooth max relative entropy of i.i.d. states on a von Neumann algebra has an asymptotic rate given by the quantum relative entropy. In fact, our AEP not only applies to states, but also to quantum channels with appropriate restrictions. In addition, going beyond the i.i.d. assumption, we show that for states that are produced by a sequential process of quantum channels, the smooth max relative entropy can be upper bounded by the sum of appropriate channel relative entropies. Our main technical contributions are to extend to the context of general von Neumann algebras a chain rule for quantum channels, as well as an additivity result for the channel relative entropy with a replacer channel.</description>
  </item>

  <item>
    <title>Approaching the Quantum Singleton Bound with Approximate Error Correction</title>
    <link>http://arxiv.org/pdf/2212.09935</link>
    <author>Thiago Bergamaschi, Louis Golowich, Sam Gunn</author>
    <pubDate>Dec 21 2022</pubDate>
    <description>It is well known that no quantum error correcting code of rate $R$ can correct adversarial errors on more than a $(1-R)/4$ fraction of symbols. But what if we only require our codes to *approximately* recover the message? We construct efficiently-decodable approximate quantum codes against adversarial error rates approaching the quantum Singleton bound of $(1-R)/2$, for any constant rate $R$. Moreover, the size of the alphabet is a constant independent of the message length and the recovery error is exponentially small in the message length. Central to our construction is a notion of quantum list decoding and an implementation involving folded quantum Reed-Solomon codes.</description>
  </item>

  <item>
    <title>Quantum simulation of exact electron dynamics can be more efficient than classical mean-field methods</title>
    <link>http://arxiv.org/pdf/2301.01203</link>
    <author>Ryan Babbush, William J. Huggins, Dominic W. Berry, Shu Fay Ung, Andrew Zhao, David R. Reichman, Hartmut Neven, Andrew D. Baczewski, Joonho Lee</author>
    <pubDate>Jan 04 2023</pubDate>
    <description>Quantum algorithms for simulating electronic ground states are slower than popular classical mean-field algorithms such as Hartree-Fock and density functional theory, but offer higher accuracy. Accordingly, quantum computers have been predominantly regarded as competitors to only the most accurate and costly classical methods for treating electron correlation. However, here we tighten bounds showing that certain first quantized quantum algorithms enable exact time evolution of electronic systems with exponentially less space and polynomially fewer operations in basis set size than conventional real-time time-dependent Hartree-Fock and density functional theory. Although the need to sample observables in the quantum algorithm reduces the speedup, we show that one can estimate all elements of the $k$-particle reduced density matrix with a number of samples scaling only polylogarithmically in basis set size. We also introduce a more efficient quantum algorithm for first quantized mean-field state preparation that is likely cheaper than the cost of time evolution. We conclude that quantum speedup is most pronounced for finite temperature simulations and suggest several practically important electron dynamics problems with potential quantum advantage.</description>
  </item>

  <item>
    <title>Fault-tolerant error correction for a universal non-Abelian topological quantum computer at finite temperature</title>
    <link>http://arxiv.org/pdf/2301.00054</link>
    <author>Alexis Schotte, Lander Burgelman, Guanyu Zhu</author>
    <pubDate>Jan 03 2023</pubDate>
    <description>We study fault-tolerant error correction in a quantum memory constructed as a two-dimensional model of Fibonacci anyons on a torus, in the presence of thermal noise represented by pair-creation processes and measurement errors. The correction procedure is based on the cellular automaton decoders originating in the works of GÃ¡cs and Harrington. Through numerical simulations, we observe that this code behaves fault-tolerantly and that threshold behavior is likely present. Hence, we provide strong evidence for the existence of a fault-tolerant universal non-Abelian topological quantum computer.</description>
  </item>

  <item>
    <title>Operator relaxation and the optimal depth of classical shadows</title>
    <link>http://arxiv.org/pdf/2212.11963</link>
    <author>Matteo Ippoliti, Yaodong Li, Tibor Rakovszky, Vedika Khemani</author>
    <pubDate>Dec 23 2022</pubDate>
    <description>Classical shadows are a powerful method for learning many properties of quantum states in a sample-efficient manner, by making use of randomized measurements. Here we study the sample complexity of learning the expectation value of Pauli operators via ``shallow shadows'', a recently-proposed version of classical shadows in which the randomization step is effected by a local unitary circuit of variable depth $t$. We show that the state-averaged shadow norm (the quantity controlling the average sample complexity) is expressed in terms of properties of the Heisenberg time evolution of operators under the randomizing (``twirling'') circuit -- namely the evolution of the weight distribution characterizing the number of sites on which an operator acts nontrivially. For spatially-contiguous operators of weight $k$, this entails a competition between two processes: operator spreading (whereby the support of an operator grows over time, increasing its weight) and operator relaxation (whereby the bulk of the operator develops an equilibrium density of identity operators, decreasing its weight). From this simple picture we derive (i) an upper bound on the shadow norm which, for depth $t\sim \log(k)$, guarantees an exponential gain in sample complexity over the $t=0$ protocol in any spatial dimension, and (ii) quantitative results in one dimension within a mean-field approximation, including a universal subleading correction to the optimal depth, found to be in excellent agreement with infinite matrix product state numerical simulations. Our work connects fundamental ideas in quantum many-body dynamics to applications in quantum information science, and paves the way to highly-optimized protocols for learning different properties of quantum states.</description>
  </item>

  <item>
    <title>Graphical quantum Clifford-encoder compilers from the ZX calculus</title>
    <link>http://arxiv.org/pdf/2301.02356</link>
    <author>Andrey Boris Khesin, Jonathan Z. Lu, Peter W. Shor</author>
    <pubDate>Jan 09 2023</pubDate>
    <description>We present a quantum compilation algorithm that maps Clifford encoders, an equivalence class of quantum circuits that arise universally in quantum error correction, into a representation in the ZX calculus. In particular, we develop a canonical form in the ZX calculus and prove canonicity as well as efficient reducibility of any Clifford encoder into the canonical form. The diagrams produced by our compiler explicitly visualize information propagation and entanglement structure of the encoder, revealing properties that may be obscured in the circuit or stabilizer-tableau representation.</description>
  </item>

  <item>
    <title>One-Way Ticket to Las Vegas and the Quantum Adversary</title>
    <link>http://arxiv.org/pdf/2301.02003</link>
    <author>Aleksandrs Belovs, Duyal Yolcu</author>
    <pubDate>Jan 06 2023</pubDate>
    <description>We propose a new definition of quantum Las Vegas query complexity. We show that it is exactly equal to the quantum adversary bound. This is achieved by a new and very simple way of transforming a feasible solution to the adversary optimisation problem into a quantum query algorithm. This allows us to generalise the bound to include unidirectional access, multiple input oracles, and input oracles that are not unitary. As an application, we demonstrate a separation between unidirectional and bidirectional access to an input oracle for a rather natural unitary permutation inversion problem.</description>
  </item>

  <item>
    <title>Guaranteed efficient energy estimation of quantum many-body Hamiltonians using ShadowGrouping</title>
    <link>http://arxiv.org/pdf/2301.03385</link>
    <author>Alexander Gresch, Martin Kliesch</author>
    <pubDate>Jan 10 2023</pubDate>
    <description>Energy estimation in quantum many-body Hamiltonians is a paradigmatic task in various research fields. In particular, efficient energy estimation may be crucial in achieving a quantum advantage for a practically relevant problem. For instance, the measurement effort poses a crucial bottleneck in variational quantum algorithms. We aim to find the optimal strategy with single-qubit measurements that yields the highest provable accuracy given a total measurement budget. As a central tool, we establish new tail bounds for empirical estimators of the energy. They are useful for identifying measurement settings that improve the energy estimate the most. This task constitutes an NP-hard problem. However, we are able to circumvent this bottleneck and use the tail bounds to develop a practical efficient estimation strategy which we call ShadowGrouping. As the name suggests, it combines shadow estimation methods with grouping strategies for Pauli strings. In numerical experiments, we demonstrate that ShadowGrouping outperforms state-of-the-art methods in estimating the electronic ground-state energies of various small molecules, both in provable and effective accuracy benchmarks. Hence, this work provides a promising way, e.g., to tackle the measurement bottleneck of variational quantum algorithms.</description>
  </item>

  <item>
    <title>Algorithmic Shadow Spectroscopy</title>
    <link>http://arxiv.org/pdf/2212.11036</link>
    <author>Hans Hon Sang Chan, Richard Meister, Matthew L. Goh, BÃ¡lint Koczor</author>
    <pubDate>Dec 22 2022</pubDate>
    <description>Finding energy differences between eigenstates of a quantum system, which contains key information about its properties, is a central task in many-body physics. Quantum computers promise to perform this task more efficiently than classical hardware; however, extraction of this information remains challenging. Non-trivial protocols for this task require either a substantial increase in circuit complexity (phase estimation) or a large number of circuit repetitions (variational quantum eigensolvers). Here we present shadow spectroscopy, a novel simulator-agnostic quantum algorithm which extracts energy gaps using an extremely low number of circuit repetitions (shots) and no extra resources (ancilla qubits) beyond performing time evolution and measurements. The approach builds on the fundamental feature that every observable property of a quantum system must evolve according to the same harmonic components, whose frequencies can be extracted from classical shadows of time-evolved quantum states. Classical post processing of the large set of resulting time-periodic signals directly reveals Hamiltonian energy differences with Heisenberg-limited precision. While the classical computational complexity is linear, the number of circuit repetitions (quantum resources) required is only logarithmic in the number of analysed observables. Moreover, applying shadow spectroscopy numerically to probe model systems and CH$_2$ excited states verifies that the approach is intuitively easy to use in practice, very robust against gate noise, amiable to a new type of algorithmic-error mitigation technique, and uses orders of magnitude fewer number of shots than typical near-term quantum algorithms -- as low as 10 shots per timestep is sufficient.</description>
  </item>

  <item>
    <title>A graph-state based synthesis framework for Clifford isometries</title>
    <link>http://arxiv.org/pdf/2212.06928</link>
    <author>TimothÃ©e Goubault de BrugiÃ¨re, Simon Martiel, Christophe Vuillot</author>
    <pubDate>Dec 15 2022</pubDate>
    <description>We tackle the problem of Clifford isometry compilation, i.e, how to synthesize a Clifford isometry into an executable quantum circuit. We propose a simple framework for synthesis that only exploits the elementary properties of the Clifford group and one equation of the symplectic group. We highlight the versatility of our framework by showing that several normal forms of the literature are natural corollaries. We report an improvement of the two-qubit depth necessary for the execution of a Clifford circuit on an LNN architecture. We also apply our framework to the synthesis of graph states and the codiagonalization of Pauli rotations and we improve the 2-qubit count and 2-qubit depth of circuits taken from quantum chemistry experiments.</description>
  </item>

  <item>
    <title>Quantum Speedups for Zero-Sum Games via Improved Dynamic Gibbs Sampling</title>
    <link>http://arxiv.org/pdf/2301.03763</link>
    <author>Adam Bouland, Yosheb Getachew, Yujia Jin, Aaron Sidford, Kevin Tian</author>
    <pubDate>Jan 11 2023</pubDate>
    <description>We give a quantum algorithm for computing an $\epsilon$-approximate Nash equilibrium of a zero-sum game in a $m \times n$ payoff matrix with bounded entries. Given a standard quantum oracle for accessing the payoff matrix our algorithm runs in time $\widetilde{O}(\sqrt{m + n}\cdot \epsilon^{-2.5} + \epsilon^{-3})$ and outputs a classical representation of the $\epsilon$-approximate Nash equilibrium. This improves upon the best prior quantum runtime of $\widetilde{O}(\sqrt{m + n} \cdot \epsilon^{-3})$ obtained by [vAG19] and the classic $\widetilde{O}((m + n) \cdot \epsilon^{-2})$ runtime due to [GK95] whenever $\epsilon = \Omega((m +n)^{-1})$. We obtain this result by designing new quantum data structures for efficiently sampling from a slowly-changing Gibbs distribution.</description>
  </item>

  <item>
    <title>Grothendieck inequalities characterize converses to the polynomial method</title>
    <link>http://arxiv.org/pdf/2212.08559</link>
    <author>Jop BriÃ«t, Francisco Escudero GutiÃ©rrez, Sander Gribling</author>
    <pubDate>Dec 19 2022</pubDate>
    <description>A surprising 'converse to the polynomial method' of Aaronson et al. (CCC'16) shows that any bounded quadratic polynomial can be computed exactly in expectation by a 1-query algorithm up to a universal multiplicative factor related to the famous Grothendieck constant. Here we show that such a result does not generalize to quartic polynomials and 2-query algorithms, even when we allow for additive approximations. We also show that the additive approximation implied by their result is tight for bounded bilinear forms, which gives a new characterization of the Grothendieck constant in terms of 1-query quantum algorithms. Along the way we provide reformulations of the completely bounded norm of a form, and its dual norm.</description>
  </item>

  <item>
    <title>Measuring out quasi-local integrals of motion from entanglement</title>
    <link>http://arxiv.org/pdf/2301.01787</link>
    <author>B. Lu, C. Bertoni, S. J. Thomson, J. Eisert</author>
    <pubDate>Jan 06 2023</pubDate>
    <description>Quasi-local integrals of motion are a key concept underpinning the modern understanding of many-body localisation, an intriguing phenomenon in which interactions and disorder come together. Despite the existence of several numerical ways to compute them - and astoundingly in the light of the observation that much of the phenomenology of many properties can be derived from them - it is not obvious how to directly measure aspects of them in real quantum simulations; in fact, the smoking gun of their experimental observation is arguably still missing. In this work, we propose a way to extract the real-space properties of such quasi-local integrals of motion based on a spatially-resolved entanglement probe able to distinguish Anderson from many-body localisation from non-equilibrium dynamics. We complement these findings with a new rigorous entanglement bound and compute the relevant quantities using tensor networks. We demonstrate that the entanglement gives rise to a well-defined length scale that can be measured in experiments.</description>
  </item>

  <item>
    <title>Upper Bounds on the Distillable Randomness of Bipartite Quantum States</title>
    <link>http://arxiv.org/pdf/2212.09073</link>
    <author>Ludovico Lami, Bartosz Regula, Xin Wang, Mark M. Wilde</author>
    <pubDate>Dec 20 2022</pubDate>
    <description>The distillable randomness of a bipartite quantum state is an information-theoretic quantity equal to the largest net rate at which shared randomness can be distilled from the state by means of local operations and classical communication. This quantity has been widely used as a measure of classical correlations, and one version of it is equal to the regularized Holevo information of the ensemble that results from measuring one share of the state. However, due to the regularization, the distillable randomness is difficult to compute in general. To address this problem, we define measures of classical correlations and prove a number of their properties, most importantly that they serve as upper bounds on the distillable randomness of an arbitrary bipartite state. We then further bound these measures from above by some that are efficiently computable by means of semi-definite programming, we evaluate one of them for the example of an isotropic state, and we remark on the relation to quantities previously proposed in the literature.</description>
  </item>

  <item>
    <title>Hypothesis Testing for Error Mitigation: How to Evaluate Error Mitigation</title>
    <link>http://arxiv.org/pdf/2301.02690</link>
    <author>Abdullah Ash Saki, Amara Katabarwa, Salonik Resch, George Umbrarescu</author>
    <pubDate>Jan 10 2023</pubDate>
    <description>In the noisy intermediate-scale quantum (NISQ) era, quantum error mitigation will be a necessary tool to extract useful performance out of quantum devices. However, there is a big gap between the noise models often assumed by error mitigation techniques and the actual noise on quantum devices. As a consequence, there arises a gap between the theoretical expectations of the techniques and their everyday performance. Cloud users of quantum devices in particular, who often take the devices as they are, feel this gap the most. How should they parametrize their uncertainty in the usefulness of these techniques and be able to make judgement calls between resources required to implement error mitigation and the accuracy required at the algorithmic level? To answer the first question, we introduce hypothesis testing within the framework of quantum error mitigation and for the second question, we propose an inclusive figure of merit that accounts for both resource requirement and mitigation efficiency of an error mitigation implementation. The figure of merit is useful to weigh the trade-offs between the scalability and accuracy of various error mitigation methods. Finally, using the hypothesis testing and the figure of merit, we experimentally evaluate $16$ error mitigation pipelines composed of singular methods such as zero noise extrapolation, randomized compilation, measurement error mitigation, dynamical decoupling, and mitigation with estimation circuits. In total our data involved running $275,640$ circuits on two IBM quantum computers.</description>
  </item>

  <item>
    <title>General guarantees for randomized benchmarking with random quantum circuits</title>
    <link>http://arxiv.org/pdf/2212.06181</link>
    <author>Markus Heinrich, Martin Kliesch, Ingo Roth</author>
    <pubDate>Dec 14 2022</pubDate>
    <description>In its many variants, randomized benchmarking (RB) is a broadly used technique for assessing the quality of gate implementations on quantum computers. A detailed theoretical understanding and general guarantees exist for the functioning and interpretation of RB protocols if the gates under scrutiny are drawn uniformly at random from a compact group. In contrast, many practically attractive and scalable RB protocols implement random quantum circuits with local gates randomly drawn from some gate-set. Despite their abundance in practice, for those non-uniform RB protocols, general guarantees under experimentally plausible assumptions are missing. In this work, we derive such guarantees for a large class of RB protocols for random circuits that we refer to as filtered RB. Prominent examples include linear cross-entropy benchmarking, character benchmarking, Pauli-noise tomography and variants of simultaneous RB. Building upon recent results for random circuits, we show that many relevant filtered RB schemes can be realized with random quantum circuits in linear depth, and we provide explicit small constants for common instances. We further derive general sample complexity bounds for filtered RB. We show filtered RB to be sample-efficient for several relevant groups, including protocols addressing higher-order cross-talk. Our theory for non-uniform filtered RB is, in principle, flexible enough to design new protocols for non-universal and analog quantum simulators.</description>
  </item>

  <item>
    <title>Randomized adaptive quantum state preparation</title>
    <link>http://arxiv.org/pdf/2301.04201</link>
    <author>Alicia B. Magann, Sophia E. Economou, Christian Arenz</author>
    <pubDate>Jan 12 2023</pubDate>
    <description>We develop an adaptive method for quantum state preparation that utilizes randomness as an essential component and that does not require classical optimization. Instead, a cost function is minimized to prepare a desired quantum state through an adaptively constructed quantum circuit, where each adaptive step is informed by feedback from gradient measurements in which the associated tangent space directions are randomized. We provide theoretical arguments and numerical evidence that convergence to the target state can be achieved for almost all initial states. We investigate different randomization procedures and develop lower bounds on the expected cost function change, which allows for drawing connections to barren plateaus and for assessing the applicability of the algorithm to large-scale problems.</description>
  </item>

  <item>
    <title>Improved Error Scaling for Trotter Simulations through Extrapolation</title>
    <link>http://arxiv.org/pdf/2212.14144</link>
    <author>Gumaro Rendon, Jacob Watkins, Nathan Wiebe</author>
    <pubDate>Jan 02 2023</pubDate>
    <description>In recent years, Trotter formulas have emerged as a leading approach for simulating quantum dynamics on quantum computers, owing to their ability to exploit locality and commutator structure of the Hamiltonian. However, a major problem facing Trotter formulas is their inability to achieve poly-logarithmic scaling with the error tolerance. We address this problem by providing a well-conditioned extrapolation scheme that takes data from Trotter-Suzuki simulations obtained for specifically chosen Trotter step sizes and estimates the value that would be seen in the limit where the Trotter step size goes to zero. We show this leads, even for the first order Trotter formula, to $\tilde{O}(1/\epsilon)$ scaling for phase estimation and $\tilde{O}(t^2/\epsilon)$ scaling for estimating time-evolved expectation values for simulation time $t$ and error tolerance $\epsilon$. This is better scaling with the error tolerance than the best known un-extrapolated Trotter formulas. Additionally, we provide a new approach for phase estimation that is unbiased and also provide a new approach for estimating the Trotter error on a quantum computer through extrapolation which yields a new way to independently assess the errors in a Trotter simulation.</description>
  </item>

  <item>
    <title>On linear-algebraic notions of expansion</title>
    <link>http://arxiv.org/pdf/2212.13154</link>
    <author>Yinan Li, Youming Qiao, Avi Wigderson, Yuval Wigderson, Chuanqi Zhang</author>
    <pubDate>Dec 27 2022</pubDate>
    <description>A fundamental fact about bounded-degree graph expanders is that three notions of expansion -- vertex expansion, edge expansion, and spectral expansion -- are all equivalent. In this paper, we study to what extent such a statement is true for linear-algebraic notions of expansion. There are two well-studied notions of linear-algebraic expansion, namely dimension expansion (defined in analogy to graph vertex expansion) and quantum expansion (defined in analogy to graph spectral expansion). Lubotzky and Zelmanov proved that the latter implies the former. We prove that the converse is false: there are dimension expanders which are not quantum expanders. Moreover, this asymmetry is explained by the fact that there are two distinct linear-algebraic analogues of graph edge expansion. The first of these is quantum edge expansion, which was introduced by Hastings, and which he proved to be equivalent to quantum expansion. We introduce a new notion, termed dimension edge expansion, which we prove is equivalent to dimension expansion and which is implied by quantum edge expansion. Thus, the separation above is implied by a finer one: dimension edge expansion is strictly weaker than quantum edge expansion. This new notion also leads to a new, more modular proof of the Lubotzky--Zelmanov result that quantum expanders are dimension expanders.</description>
  </item>

  <item>
    <title>Discrete holography in dual-unitary circuits</title>
    <link>http://arxiv.org/pdf/2301.02825</link>
    <author>Lluis Masanes</author>
    <pubDate>Jan 10 2023</pubDate>
    <description>We introduce a family of dual-unitary circuits in 1+1 dimensions which constitute a discrete analog of conformal field theories. These circuits are quantum cellular automata which are invariant under the joint action of Lorentz and scale transformations. Dual unitaries are four-legged tensors which satisfy the unitarity condition across the time as well as the space direction, a property that makes the model mathematically tractable. Using dual unitaries too, we construct tensor-network states for our 1+1 model, which are interpreted as spatial slices of curved 2+1 discrete geometries, where the metric distance is defined by the entanglement structure of the state, following Ryu-Takayanagi's prescription. The dynamics of the circuit induces a natural dynamics on these geometries, which we study for flat and anti-de Sitter spaces, and in the presence or absence of matter. We observe that the dynamics of spaces with two or more particles differs from that of zero or one, suggesting the presence of black holes. But this contrasts with the fact that the family of models appears to be non-chaotic.</description>
  </item>

</channel>

</rss>
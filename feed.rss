<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>How Much Structure Is Needed for Huge Quantum Speedups?</title>
    <link>http://arxiv.org/pdf/2209.06930</link>
    <author>Scott Aaronson</author>
    <pubDate>Sep 16 2022</pubDate>
    <description>I survey, for a general scientific audience, three decades of research into which sorts of problems admit exponential speedups via quantum computers -- from the classics (like the algorithms of Simon and Shor), to the breakthrough of Yamakawa and Zhandry from April 2022. I discuss both the quantum circuit model, which is what we ultimately care about in practice but where our knowledge is radically incomplete, and the so-called oracle or black-box or query complexity model, where we've managed to achieve a much more thorough understanding that then informs our conjectures about the circuit model. I discuss the strengths and weaknesses of switching attention to sampling tasks, as was done in the recent quantum supremacy experiments. I make some skeptical remarks about widely-repeated claims of exponential quantum speedups for practical machine learning and optimization problems. Through many examples, I try to convey the "law of conservation of weirdness," according to which every problem admitting an exponential quantum speedup must have some unusual property to allow the amplitude to be concentrated on the unknown right answer(s).</description>
  </item>

  <item>
    <title>Shallow shadows: Expectation estimation using low-depth random Clifford circuits</title>
    <link>http://arxiv.org/pdf/2209.12924</link>
    <author>Christian Bertoni, Jonas Haferkamp, Marcel Hinsche, Marios Ioannou, Jens Eisert, Hakop Pashayan</author>
    <pubDate>Sep 28 2022</pubDate>
    <description>We provide practical and powerful schemes for learning many properties of an unknown n-qubit quantum state using a sparing number of copies of the state. Specifically, we present a depth-modulated randomized measurement scheme that interpolates between two known classical shadows schemes based on random Pauli measurements and random Clifford measurements. These can be seen within our scheme as the special cases of zero and infinite depth, respectively. We focus on the regime where depth scales logarithmically in n and provide evidence that this retains the desirable properties of both extremal schemes whilst, in contrast to the random Clifford scheme, also being experimentally feasible. We present methods for two key tasks; estimating expectation values of certain observables from generated classical shadows and, computing upper bounds on the depth-modulated shadow norm, thus providing rigorous guarantees on the accuracy of the output estimates. We consider observables that can be written as a linear combination of poly(n) Paulis and observables that can be written as a low bond dimension matrix product operator. For the former class of observables both tasks are solved efficiently in n. For the latter class, we do not guarantee efficiency but present a method that works in practice; by variationally computing a heralded approximate inverses of a tensor network that can then be used for efficiently executing both these tasks.</description>
  </item>

  <item>
    <title>The Complexity of NISQ</title>
    <link>http://arxiv.org/pdf/2210.07234</link>
    <author>Sitan Chen, Jordan Cotler, Hsin-Yuan Huang, Jerry Li</author>
    <pubDate>Oct 14 2022</pubDate>
    <description>The recent proliferation of NISQ devices has made it imperative to understand their computational power. In this work, we define and study the complexity class $\textsf{NISQ} $, which is intended to encapsulate problems that can be efficiently solved by a classical computer with access to a NISQ device. To model existing devices, we assume the device can (1) noisily initialize all qubits, (2) apply many noisy quantum gates, and (3) perform a noisy measurement on all qubits. We first give evidence that $\textsf{BPP}\subsetneq \textsf{NISQ}\subsetneq \textsf{BQP}$, by demonstrating super-polynomial oracle separations among the three classes, based on modifications of Simon's problem. We then consider the power of $\textsf{NISQ}$ for three well-studied problems. For unstructured search, we prove that $\textsf{NISQ}$ cannot achieve a Grover-like quadratic speedup over $\textsf{BPP}$. For the Bernstein-Vazirani problem, we show that $\textsf{NISQ}$ only needs a number of queries logarithmic in what is required for $\textsf{BPP}$. Finally, for a quantum state learning problem, we prove that $\textsf{NISQ}$ is exponentially weaker than classical computation with access to noiseless constant-depth quantum circuits.</description>
  </item>

  <item>
    <title>Parallel window decoding enables scalable fault tolerant quantum computation</title>
    <link>http://arxiv.org/pdf/2209.08552</link>
    <author>Luka Skoric, Dan E. Browne, Kenton M. Barnes, Neil I. Gillespie, Earl T. Campbell</author>
    <pubDate>Sep 20 2022</pubDate>
    <description>Quantum Error Correction (QEC) continuously generates a stream of syndrome data that contains information about the errors in the system. Useful fault-tolerant quantum computation requires online decoders that are capable of processing this syndrome data at the rate it is received. Otherwise, a data backlog is created that grows exponentially with the $T$-gate depth of the computation. Superconducting quantum devices can perform QEC rounds in sub-1 $\mu$s time, setting a stringent requirement on the speed of the decoders. All current decoder proposals have a maximum code size beyond which the processing of syndromes becomes too slow to keep up with the data acquisition, thereby making the fault-tolerant computation not scalable. Here, we will present a methodology that parallelizes the decoding problem and achieves almost arbitrary syndrome processing speed. Our parallelization requires some classical feedback decisions to be delayed, leading to a slow-down of the logical clock speed. However, the slow-down is now polynomial in code size and so an exponential backlog is averted. Furthermore, using known auto-teleportation gadgets the slow-down can be eliminated altogether in exchange for increased qubit overhead, all polynomially scaling. We demonstrate our parallelization speed-up using a Python implementation, combining it with both union-find and minimum weight perfect matching. Furthermore, we show that the algorithm imposes no noticeable reduction in logical fidelity compared to the original global decoder. Finally, we discuss how the same methodology can be implemented in online hardware decoders.</description>
  </item>

  <item>
    <title>Quantum Error Mitigation</title>
    <link>http://arxiv.org/pdf/2210.00921</link>
    <author>Zhenyu Cai, Ryan Babbush, Simon C. Benjamin, Suguru Endo, William J. Huggins, Ying Li, Jarrod R. McClean, Thomas E. O'Brien</author>
    <pubDate>Oct 04 2022</pubDate>
    <description>For quantum computers to successfully solve real-world problems, it is necessary to tackle the challenge of noise: the errors which occur in elementary physical components due to unwanted or imperfect interactions. The theory of quantum fault tolerance can provide an answer in the long term, but in the coming era of `NISQ' machines we must seek to mitigate errors rather than completely remove them. This review surveys the diverse methods that have been proposed for quantum error mitigation, assesses their in-principle efficacy, and then describes the hardware demonstrations achieved to date. We identify the commonalities and limitations among the methods, noting how mitigation methods can be chosen according to the primary type of noise present, including algorithmic errors. Open problems in the field are identified and we discuss the prospects for realising mitigation-based devices that can deliver quantum advantage with an impact on science and business.</description>
  </item>

  <item>
    <title>The Future of Quantum Computing with Superconducting Qubits</title>
    <link>http://arxiv.org/pdf/2209.06841</link>
    <author>Sergey Bravyi, Oliver Dial, Jay M. Gambetta, Dario Gil, Zaira Nazario</author>
    <pubDate>Sep 16 2022</pubDate>
    <description>For the first time in history, we are seeing a branching point in computing paradigms with the emergence of quantum processing units (QPUs). Extracting the full potential of computation and realizing quantum algorithms with a super-polynomial speedup will most likely require major advances in quantum error correction technology. Meanwhile, achieving a computational advantage in the near term may be possible by combining multiple QPUs through circuit knitting techniques, improving the quality of solutions through error suppression and mitigation, and focusing on heuristic versions of quantum algorithms with asymptotic speedups. For this to happen, the performance of quantum computing hardware needs to improve and software needs to seamlessly integrate quantum and classical processors together to form a new architecture that we are calling quantum-centric supercomputing. Long term, we see hardware that exploits qubit connectivity in higher than 2D topologies to realize more efficient quantum error correcting codes, modular architectures for scaling QPUs and parallelizing workloads, and software that evolves to make the intricacies of the technology invisible to the users and realize the goal of ubiquitous, frictionless quantum computing.</description>
  </item>

  <item>
    <title>Learning many-body Hamiltonians with Heisenberg-limited scaling</title>
    <link>http://arxiv.org/pdf/2210.03030</link>
    <author>Hsin-Yuan Huang, Yu Tong, Di Fang, Yuan Su</author>
    <pubDate>Oct 07 2022</pubDate>
    <description>Learning a many-body Hamiltonian from its dynamics is a fundamental problem in physics. In this work, we propose the first algorithm to achieve the Heisenberg limit for learning an interacting $N$-qubit local Hamiltonian. After a total evolution time of $\mathcal{O}(\epsilon^{-1})$, the proposed algorithm can efficiently estimate any parameter in the $N$-qubit Hamiltonian to $\epsilon$-error with high probability. The proposed algorithm is robust against state preparation and measurement error, does not require eigenstates or thermal states, and only uses $\mathrm{polylog}(\epsilon^{-1})$ experiments. In contrast, the best previous algorithms, such as recent works using gradient-based optimization or polynomial interpolation, require a total evolution time of $\mathcal{O}(\epsilon^{-2})$ and $\mathcal{O}(\epsilon^{-2})$ experiments. Our algorithm uses ideas from quantum simulation to decouple the unknown $N$-qubit Hamiltonian $H$ into noninteracting patches, and learns $H$ using a quantum-enhanced divide-and-conquer approach. We prove a matching lower bound to establish the asymptotic optimality of our algorithm.</description>
  </item>

  <item>
    <title>Thermalization without eigenstate thermalization</title>
    <link>http://arxiv.org/pdf/2209.09826</link>
    <author>Aram W. Harrow, Yichen Huang</author>
    <pubDate>Sep 21 2022</pubDate>
    <description>In an isolated quantum many-body system undergoing unitary evolution, we study the thermalization of a subsystem, treating the rest of the system as a bath. In this setting, the eigenstate thermalization hypothesis (ETH) was proposed to explain thermalization. Consider a nearly integrable Sachdev-Ye-Kitaev model obtained by adding random all-to-all $4$-body interactions as a perturbation to a random free-fermion model. When the subsystem size is larger than the square root of but is still a vanishing fraction of the system size, we prove thermalization if the system is initialized in a random product state, while almost all eigenstates violate the ETH. In this sense, the ETH is not a necessary condition for thermalization.</description>
  </item>

  <item>
    <title>Clique Homology is QMA1-hard</title>
    <link>http://arxiv.org/pdf/2209.11793</link>
    <author>Marcos Crichigno, Tamara Kohler</author>
    <pubDate>Sep 27 2022</pubDate>
    <description>We tackle the long-standing question of the computational complexity of determining homology groups of simplicial complexes, a fundamental task in computational topology, posed by Kaibel and Pfetsch 20 years ago. We show that this decision problem is QMA1-hard. Moreover, we show that a version of the problem satisfying a suitable promise and certain constraints is contained in QMA. This suggests that the seemingly classical problem may in fact be quantum mechanical. In fact, we are able to significantly strengthen this by showing that the problem remains QMA1-hard in the case of clique complexes, a family of simplicial complexes specified by a graph which is relevant to the problem of topological data analysis. The proof combines a number of techniques from Hamiltonian complexity and homological algebra. We discuss potential implications for the problem of quantum advantage in topological data analysis.</description>
  </item>

  <item>
    <title>Quantum algorithm for ground state energy estimation using circuit depth with exponentially improved dependence on precision</title>
    <link>http://arxiv.org/pdf/2209.06811</link>
    <author>Guoming Wang, Daniel Stilck-França, Ruizhe Zhang, Shuchen Zhu, Peter D. Johnson</author>
    <pubDate>Sep 15 2022</pubDate>
    <description>A milestone in the field of quantum computing will be solving problems in quantum chemistry and materials faster than state of the art classical methods. The current understanding is that achieving quantum advantage in this area will require some degree of error correction. While hardware is improving towards this milestone, optimizing quantum algorithms also brings it closer to the present. Existing methods for ground state energy estimation require circuit depths that scale as ${\cal O}(1/\epsilon\cdot \operatorname{polylog}(1/\epsilon))$ to reach accuracy $\epsilon$. In this work, we develop and analyze ground state energy estimation algorithms that use just one auxilliary qubit and for which the circuit depths scale as ${\cal O}(1/\Delta \cdot \operatorname{polylog}(\Delta/\epsilon))$, where $\Delta\geq\epsilon$ is a lower bound on the energy gap of the Hamiltonian. With this $\widetilde{\cal O}(\Delta/\epsilon)$ reduction in circuit depth, relative to recent resource estimates of ground state energy estimation for the industrially-relevant molecules of ethelyne-carbonate and PF$_6^-$, the estimated gate count and circuit depth is reduced by a factor of 43 and 78, respectively. Furthermore, the algorithm can take advantage of larger available circuit depths to reduce the total runtime. By setting $\alpha\in[0,1]$ and using depth proportional to $\epsilon^{-\alpha} \Delta_{\rm true}^{-1+\alpha}$, the resulting total runtime is $\widetilde{{\cal O}}(\epsilon^{-2+\alpha}\Delta_{\rm true}^{1-\alpha})$, where $\Delta_{\rm true}$ is the true energy gap of the Hamiltonian. These features make our algorithm a promising candidate for realizing quantum advantage in the era of early fault-tolerant quantum computing.</description>
  </item>

  <item>
    <title>Scalably learning quantum many-body Hamiltonians from dynamical data</title>
    <link>http://arxiv.org/pdf/2209.14328</link>
    <author>Frederik Wilde, Augustine Kshetrimayum, Ingo Roth, Dominik Hangleiter, Ryan Sweke, Jens Eisert</author>
    <pubDate>Sep 30 2022</pubDate>
    <description>The physics of a closed quantum mechanical system is governed by its Hamiltonian. However, in most practical situations, this Hamiltonian is not precisely known, and ultimately all there is are data obtained from measurements on the system. In this work, we introduce a highly scalable, data-driven approach to learning families of interacting many-body Hamiltonians from dynamical data, by bringing together techniques from gradient-based optimization from machine learning with efficient quantum state representations in terms of tensor networks. Our approach is highly practical, experimentally friendly, and intrinsically scalable to allow for system sizes of above 100 spins. In particular, we demonstrate on synthetic data that the algorithm works even if one is restricted to one simple initial state, a small number of single-qubit observables, and time evolution up to relatively short times. For the concrete example of the one-dimensional Heisenberg model our algorithm exhibits an error constant in the system size and scaling as the inverse square root of the size of the data set.</description>
  </item>

  <item>
    <title>The minimal canonical form of a tensor network</title>
    <link>http://arxiv.org/pdf/2209.14358</link>
    <author>Arturo Acuaviva, Visu Makam, Harold Nieuwboer, David Pérez-García, Friedrich Sittner, Michael Walter, Freek Witteveen</author>
    <pubDate>Sep 30 2022</pubDate>
    <description>Tensor networks have a gauge degree of freedom on the virtual degrees of freedom that are contracted. A canonical form is a choice of fixing this degree of freedom. For matrix product states, choosing a canonical form is a powerful tool, both for theoretical and numerical purposes. On the other hand, for tensor networks in dimension two or greater there is only limited understanding of the gauge symmetry. Here we introduce a new canonical form, the minimal canonical form, which applies to projected entangled pair states (PEPS) in any dimension, and prove a corresponding fundamental theorem. Already for matrix product states this gives a new canonical form, while in higher dimensions it is the first rigorous definition of a canonical form valid for any choice of tensor. We show that two tensors have the same minimal canonical forms if and only if they are gauge equivalent up to taking limits; moreover, this is the case if and only if they give the same quantum state for any geometry. In particular, this implies that the latter problem is decidable - in contrast to the well-known undecidability for PEPS on grids. We also provide rigorous algorithms for computing minimal canonical forms. To achieve this we draw on geometric invariant theory and recent progress in theoretical computer science in non-commutative group optimization.</description>
  </item>

  <item>
    <title>Noise can be helpful for variational quantum algorithms</title>
    <link>http://arxiv.org/pdf/2210.06723</link>
    <author>Junyu Liu, Frederik Wilde, Antonio Anna Mele, Liang Jiang, Jens Eisert</author>
    <pubDate>Oct 14 2022</pubDate>
    <description>Saddle points constitute a crucial challenge for first-order gradient descent algorithms. In notions of classical machine learning, they are avoided for example by means of stochastic gradient descent methods. In this work, we provide evidence that the saddle points problem can be naturally avoided in variational quantum algorithms by exploiting the presence of stochasticity. We prove convergence guarantees of the approach and its practical functioning at hand of examples. We argue that the natural stochasticity of variational algorithms can be beneficial for avoiding strict saddle points, i.e., those saddle points with at least one negative Hessian eigenvalue. This insight that some noise levels could help in this perspective is expected to add a new perspective to notions of near-term variational quantum algorithms.</description>
  </item>

  <item>
    <title>A streamlined quantum algorithm for topological data analysis with exponentially fewer qubits</title>
    <link>http://arxiv.org/pdf/2209.12887</link>
    <author>Sam McArdle, András Gilyén, Mario Berta</author>
    <pubDate>Sep 27 2022</pubDate>
    <description>Topological invariants of a dataset, such as the number of holes that survive from one length scale to another (persistent Betti numbers) can be used to analyse and classify data in machine learning applications. We present an improved quantum algorithm for computing persistent Betti numbers, and provide an end-to-end complexity analysis. Our approach provides large polynomial time improvements, and an exponential space saving, over existing quantum algorithms. Subject to gap dependencies, our algorithm obtains an almost quintic speedup in the number of datapoints over rigorous state-of-the-art classical algorithms for calculating the persistent Betti numbers to constant additive error - the salient task for applications. However, this may be reduced to closer to quadratic when compared against heuristic classical methods and observed scalings. We discuss whether quantum algorithms can achieve an exponential speedup for tasks of practical interest, as claimed previously. We conclude that there is currently no evidence that this is the case.</description>
  </item>

  <item>
    <title>Unitary property testing lower bounds by polynomials</title>
    <link>http://arxiv.org/pdf/2210.05885</link>
    <author>Adrian She, Henry Yuen</author>
    <pubDate>Oct 13 2022</pubDate>
    <description>We study unitary property testing, where a quantum algorithm is given query access to a black-box unitary and has to decide whether it satisfies some property. In addition to containing the standard quantum query complexity model (where the unitary encodes a binary string) as a special case, this model contains "inherently quantum" problems that have no classical analogue. Characterizing the query complexity of these problems requires new algorithmic techniques and lower bound methods. Our main contribution is a generalized polynomial method for unitary property testing problems. By leveraging connections with invariant theory, we apply this method to obtain lower bounds on problems such as determining recurrence times of unitaries, approximating the dimension of a marked subspace, and approximating the entanglement entropy of a marked state. We also present a unitary property testing-based approach towards an oracle separation between $\mathsf{QMA}$ and $\mathsf{QMA(2)}$, a long standing question in quantum complexity theory.</description>
  </item>

  <item>
    <title>Scalable surface code decoders with parallelization in time</title>
    <link>http://arxiv.org/pdf/2209.09219</link>
    <author>Xinyu Tan, Fang Zhang, Rui Chao, Yaoyun Shi, Jianxin Chen</author>
    <pubDate>Sep 20 2022</pubDate>
    <description>Fast classical processing is essential for most quantum fault-tolerance architectures. We introduce a sliding-window decoding scheme that provides fast classical processing for the surface code through parallelism. Our scheme divides the syndromes in spacetime into overlapping windows along the time direction, which can be decoded in parallel with any inner decoder. With this parallelism, our scheme can solve the decoding throughput problem as the code scales up, even if the inner decoder is slow. When using min-weight perfect matching and union-find as the inner decoders, we observe circuit-level thresholds of $0.68\%$ and $0.55\%$, respectively, which are almost identical to $0.70\%$ and $0.55\%$ for the batch decoding.</description>
  </item>

  <item>
    <title>NLTS Hamiltonians from classical LTCs</title>
    <link>http://arxiv.org/pdf/2210.02999</link>
    <author>Zhiyang He, Chinmay Nirkhe</author>
    <pubDate>Oct 07 2022</pubDate>
    <description>We provide a completely self-contained construction of a family of NLTS Hamiltonians [Freedman and Hastings, 2014] based on ideas from [Anshu, Breuckmann, and Nirkhe, 2022], [Cross, He, Natarajan, Szegedy, and Zhu, 2022] and [Eldar and Harrow, 2017]. Crucially, it does not require optimal-parameter quantum LDPC codes and can be built from simple classical LTCs such as the repetition code on an expander graph. Furthermore, it removes the constant-rate requirement from the construction of Anshu, Breuckmann, and Nirkhe.</description>
  </item>

  <item>
    <title>Concatenation Schemes for Topological Fault-tolerant Quantum Error Correction</title>
    <link>http://arxiv.org/pdf/2209.09390</link>
    <author>Zhaoyi Li, Isaac Kim, Patrick Hayden</author>
    <pubDate>Sep 21 2022</pubDate>
    <description>We investigate a family of fault-tolerant quantum error correction schemes based on the concatenation of small error detection or error correction codes with the three-dimensional cluster state. We propose fault-tolerant state preparation and decoding schemes that effectively convert every circuit-level error into an erasure error, leveraging the cluster state's high threshold against such errors. We find a set of codes for which such a conversion is possible, and study their performance against the standard circuit-level depolarizing model. Our best performing scheme, which is based on a concatenation with a classical code, improves the threshold by $16.5\%$ and decreases the spacetime overhead by $32\%$ compared to the scheme without concatenation, with each scheme subject to a physical error rate of $10^{-3}$ and achieving a logical error rate of $10^{-6}$.</description>
  </item>

  <item>
    <title>Circuit depth versus energy in topologically ordered systems</title>
    <link>http://arxiv.org/pdf/2210.06796</link>
    <author>Arkin Tikku, Isaac H. Kim</author>
    <pubDate>Oct 14 2022</pubDate>
    <description>We prove a nontrivial circuit-depth lower bound for preparing a low-energy state of a locally interacting quantum many-body system in two dimensions, assuming the circuit is geometrically local. For preparing any state which has an energy density of at most $\epsilon$ with respect to Kitaev's toric code Hamiltonian on a two dimensional lattice $\Lambda$, we prove a lower bound of $\Omega\left(\min\left(1/\epsilon^{\frac{1-\alpha}{2}}, \sqrt{|\Lambda|}\right)\right)$ for any $\alpha >0$. We discuss two implications. First, our bound implies that the lowest energy density obtainable from a large class of existing variational circuits (e.g., Hamiltonian variational ansatz) cannot, in general, decay exponentially with the circuit depth. Second, if long-range entanglement is present in the ground state, this can lead to a nontrivial circuit-depth lower bound even at nonzero energy density. Unlike previous approaches to prove circuit-depth lower bounds for preparing low energy states, our proof technique does not rely on the ground state to be degenerate.</description>
  </item>

  <item>
    <title>Quantum divide and conquer</title>
    <link>http://arxiv.org/pdf/2210.06419</link>
    <author>Andrew M. Childs, Robin Kothari, Matt Kovacs-Deak, Aarthi Sundaram, Daochen Wang</author>
    <pubDate>Oct 13 2022</pubDate>
    <description>The divide-and-conquer framework, used extensively in classical algorithm design, recursively breaks a problem of size $n$ into smaller subproblems (say, $a$ copies of size $n/b$ each), along with some auxiliary work of cost $C^{\textrm{aux}}(n)$, to give a recurrence relation $$C(n) ≤a \,C(n/b) + C^\textrmaux(n)$$ for the classical complexity $C(n)$. We describe a quantum divide-and-conquer framework that, in certain cases, yields an analogous recurrence relation $$C_Q(n) ≤\sqrta \u2009C_Q(n/b) + O(C^\textrmaux_Q(n))$$ that characterizes the quantum query complexity. We apply this framework to obtain near-optimal quantum query complexities for various string problems, such as (i) recognizing regular languages; (ii) decision versions of String Rotation and String Suffix; and natural parameterized versions of (iii) Longest Increasing Subsequence and (iv) Longest Common Subsequence.</description>
  </item>

  <item>
    <title>Quantifying Quantum Advantage in Topological Data Analysis</title>
    <link>http://arxiv.org/pdf/2209.13581</link>
    <author>Dominic W. Berry, Yuan Su, Casper Gyurik, Robbie King, Joao Basso, Alexander Del Toro Barba, Abhishek Rajput, Nathan Wiebe, Vedran Dunjko, Ryan Babbush</author>
    <pubDate>Sep 28 2022</pubDate>
    <description>Lloyd et al. were first to demonstrate the promise of quantum algorithms for computing Betti numbers in persistent homology (a way of characterizing topological features of data sets). Here, we propose, analyze, and optimize an improved quantum algorithm for topological data analysis (TDA) with reduced scaling, including a method for preparing Dicke states based on inequality testing, a more efficient amplitude estimation algorithm using Kaiser windows, and an optimal implementation of eigenvalue projectors based on Chebyshev polynomials. We compile our approach to a fault-tolerant gate set and estimate constant factors in the Toffoli complexity. Relative to the best classical heuristic algorithms, our analysis reveals that super-quadratic quantum speedups are only possible for this problem when targeting a multiplicative error approximation and the Betti number grows asymptotically. Further, we propose a dequantization of the quantum TDA algorithm that shows that having exponentially large dimension and Betti number are necessary, but insufficient conditions, for super-polynomial advantage. We then introduce and analyze specific problem examples for which super-polynomial advantages may be achieved, and argue that quantum circuits with tens of billions of Toffoli gates can solve some seemingly classically intractable instances.</description>
  </item>

  <item>
    <title>Complexity-Theoretic Limitations on Quantum Algorithms for Topological Data Analysis</title>
    <link>http://arxiv.org/pdf/2209.14286</link>
    <author>Alexander Schmidhuber, Seth Lloyd</author>
    <pubDate>Sep 29 2022</pubDate>
    <description>Quantum algorithms for topological data analysis (TDA) seem to provide an exponential advantage over the best classical approach while remaining immune to dequantization procedures and the data-loading problem. In this paper, we argue that quantum algorithms for TDA run in exponential time for almost all inputs by showing that (under widely believed complexity-theoretic conjectures) the central problem of TDA - estimating Betti numbers - is intractable even for quantum computers. Specifically, we prove that the problem of computing Betti numbers exactly is \#P-hard, while the problem of approximating Betti numbers up to multiplicative error is NP-hard. Moreover, both problems retain their hardness if restricted to the regime where quantum algorithms for TDA perform best. Because quantum computers are not expected to solve \#P-hard or NP-hard problems in subexponential time, our results imply that quantum algorithms for TDA offer only a polynomial advantage. We verify our claim by showing that the seminal quantum algorithm for TDA developed by Lloyd, Garnerone and Zanardi \citeLloydAlgo achieves a quadratic speedup over the best classical approach on average, and a power-of-four speedup in the best case. Finally, we argue that an exponential quantum advantage can be recovered if the data is given as a specification of simplices rather than as a list of vertices and edges -- for example, if we wish to calculate the homology of Facebook from a list of Facebook groups and their members rather than from a list of pairwise interactions between Facebook users.</description>
  </item>

  <item>
    <title>Quantum communication complexity of linear regression</title>
    <link>http://arxiv.org/pdf/2210.01601</link>
    <author>Ashley Montanaro, Changpeng Shao</author>
    <pubDate>Oct 05 2022</pubDate>
    <description>Dequantized algorithms show that quantum computers do not have exponential speedups for many linear algebra problems in terms of time and query complexity. In this work, we show that quantum computers can have exponential speedups in terms of communication complexity for some fundamental linear algebra problems. We mainly focus on solving linear regression and Hamiltonian simulation. In the quantum case, the task is to prepare the quantum state of the result. To allow for a fair comparison, in the classical case the task is to sample from the result. We investigate these two problems in two-party and multiparty models, propose near-optimal quantum protocols and prove quantum/classical lower bounds. In this process, we propose an efficient quantum protocol for quantum singular value transformation, which is a powerful technique for designing quantum algorithms. As a result, for many linear algebra problems where quantum computers lose exponential speedups in terms of time and query complexity, it is possible to have exponential speedups in terms of communication complexity.</description>
  </item>

  <item>
    <title>Universal measurement-based quantum computation in a one-dimensional architecture enabled by dual-unitary circuits</title>
    <link>http://arxiv.org/pdf/2209.06191</link>
    <author>David T. Stephen, Wen Wei Ho, Tzu-Chieh Wei, Robert Raussendorf, Ruben Verresen</author>
    <pubDate>Sep 14 2022</pubDate>
    <description>A powerful tool emerging from the study of many-body quantum dynamics is that of dual-unitary circuits, which are unitary even when read `sideways', i.e., along the spatial direction. Here, we show that this provides the ideal framework to understand and expand on the notion of measurement-based quantum computation (MBQC). In particular, applying a dual-unitary circuit to a many-body state followed by appropriate measurements effectively implements quantum computation in the spatial direction. We argue that this computation can be made deterministic by enforcing a Clifford condition, and is generically universal. Remarkably, all these requirements can already be satisfied by the dynamics of the paradigmatic kicked Ising chain at specific parameter choices. Specifically, after $k$ time-steps, equivalent to a depth-$k$ quantum circuit, we obtain a resource state for universal MBQC on $\sim 3k/4$ encoded logical qubits. This removes the usual requirement of going to two dimensions to achieve universality, thereby reducing the demands imposed on potential experimental platforms. Beyond the practical advantages, we also interpret this evolution as an infinite-order entangler for symmetry-protected topological chains, which gives a vast generalization of the celebrated cluster chain and shows that our protocol is robust to symmetry-respecting deformations.</description>
  </item>

  <item>
    <title>Quantum Depth in the Random Oracle Model</title>
    <link>http://arxiv.org/pdf/2210.06454</link>
    <author>Atul Singh Arora, Andrea Coladangelo, Matthew Coudron, Alexandru Gheorghiu, Uttam Singh, Hendrik Waldner</author>
    <pubDate>Oct 13 2022</pubDate>
    <description>We give a comprehensive characterization of the computational power of shallow quantum circuits combined with classical computation. Specifically, for classes of search problems, we show that the following statements hold, relative to a random oracle: (a) $\mathsf{BPP}^{\mathsf{QNC}^{\mathsf{BPP}}} \neq \mathsf{BQP}$. This refutes Jozsa's conjecture [QIP 05] in the random oracle model. As a result, this gives the first instantiatable separation between the classes by replacing the oracle with a cryptographic hash function, yielding a resolution to one of Aaronson's ten semi-grand challenges in quantum computing. (b) $\mathsf{BPP}^{\mathsf{QNC}} \nsubseteq \mathsf{QNC}^{\mathsf{BPP}}$ and $\mathsf{QNC}^{\mathsf{BPP}} \nsubseteq \mathsf{BPP}^{\mathsf{QNC}}$. This shows that there is a subtle interplay between classical computation and shallow quantum computation. In fact, for the second separation, we establish that, for some problems, the ability to perform adaptive measurements in a single shallow quantum circuit, is more useful than the ability to perform polynomially many shallow quantum circuits without adaptive measurements. (c) There exists a 2-message proof of quantum depth protocol. Such a protocol allows a classical verifier to efficiently certify that a prover must be performing a computation of some minimum quantum depth. Our proof of quantum depth can be instantiated using the recent proof of quantumness construction by Yamakawa and Zhandry [STOC 22].</description>
  </item>

  <item>
    <title>Quantum LDPC Codes for Modular Architectures</title>
    <link>http://arxiv.org/pdf/2209.14329</link>
    <author>Armands Strikis, Lucas Berent</author>
    <pubDate>Sep 30 2022</pubDate>
    <description>In efforts to scale the size of quantum computers, modularity plays a central role across most quantum computing technologies. In the light of fault tolerance, this necessitates designing quantum error-correcting codes that are compatible with the connectivity arising from the architectural layouts. In this paper, we aim to bridge this gap by giving a novel way to view and construct quantum LDPC codes tailored for modular architectures. We demonstrate that if the intra- and inter-modular qubit connectivity can be viewed as corresponding to some classical or quantum LDPC codes, then their hypergraph product code fully respects the architectural connectivity constraints. Finally, we show that relaxed connectivity constraints that allow twists of connections between modules pave a way to construct codes with better parameters.</description>
  </item>

  <item>
    <title>Quantum Locally Testable Code with Exotic Parameters</title>
    <link>http://arxiv.org/pdf/2209.11405</link>
    <author>Andrew Cross, Zhiyang He, Anand Natarajan, Mario Szegedy, Guanyu Zhu</author>
    <pubDate>Sep 26 2022</pubDate>
    <description>In this paper, we present a few simple constructions of quantum locally testable codes that achieve interesting parameters which were previously unknown. We introduce an operation which we give the name check product, and show how this operation gives rise to quantum locally testable codes of constant soundness and linear rate, with varying distance and locality.</description>
  </item>

  <item>
    <title>Quantum theory in finite dimension cannot explain every general process with finite memory</title>
    <link>http://arxiv.org/pdf/2209.11225</link>
    <author>Marco Fanizza, Josep Lumbreras, Andreas Winter</author>
    <pubDate>Sep 23 2022</pubDate>
    <description>Arguably, the largest class of stochastic processes generated by means of a finite memory consists of those that are sequences of observations produced by sequential measurements in a suitable generalized probabilistic theory (GPT). These are constructed from a finite-dimensional memory evolving under a set of possible linear maps, and with probabilities of outcomes determined by linear functions of the memory state. Examples of such models are given by classical hidden Markov processes, where the memory state is a probability distribution, and at each step it evolves according to a non-negative matrix, and hidden quantum Markov processes, where the memory state is a finite dimensional quantum state, and at each step it evolves according to a completely positive map. Here we show that the set of processes admitting a finite-dimensional explanation do not need to be explainable in terms of either classical probability or quantum mechanics. To wit, we exhibit families of processes that have a finite-dimensional explanation, defined manifestly by the dynamics of explicitly given GPT, but that do not admit a quantum, and therefore not even classical, explanation in finite dimension. Furthermore, we present a family of quantum processes on qubits and qutrits that do not admit a classical finite-dimensional realization, which includes examples introduced earlier by Fox, Rubin, Dharmadikari and Nadkarni as functions of infinite dimensional Markov chains, and lower bound the size of the memory of a classical model realizing a noisy version of the qubit processes.</description>
  </item>

  <item>
    <title>Low-Stabilizer-Complexity Quantum States Are Not Pseudorandom</title>
    <link>http://arxiv.org/pdf/2209.14530</link>
    <author>Sabee Grewal, Vishnu Iyer, William Kretschmer, Daniel Liang</author>
    <pubDate>Sep 30 2022</pubDate>
    <description>We show that quantum states with "low stabilizer complexity" can be efficiently distinguished from Haar-random. Specifically, given an $n$-qubit pure state $|\psi\rangle$, we give an efficient algorithm that distinguishes whether $|\psi\rangle$ is (i) Haar-random or (ii) a state with stabilizer fidelity at least $\frac{1}{k}$ (i.e., has fidelity at least $\frac{1}{k}$ with some stabilizer state), promised that one of these is the case. With black-box access to $|\psi\rangle$, our algorithm uses $O\!\left( k^{12} \log(1/\delta)\right)$ copies of $|\psi\rangle$ and $O\!\left(n k^{12} \log(1/\delta)\right)$ time to succeed with probability at least $1-\delta$, and, with access to a state preparation unitary for $|\psi\rangle$ (and its inverse), $O\!\left( k^{3} \log(1/\delta)\right)$ queries and $O\!\left(n k^{3} \log(1/\delta)\right)$ time suffice. As a corollary, we prove that $\omega(\log(n))$ $T$-gates are necessary for any Clifford+$T$ circuit to prepare computationally pseudorandom quantum states, a first-of-its-kind lower bound.</description>
  </item>

  <item>
    <title>Postselected quantum hypothesis testing</title>
    <link>http://arxiv.org/pdf/2209.10550</link>
    <author>Bartosz Regula, Ludovico Lami, Mark M. Wilde</author>
    <pubDate>Sep 23 2022</pubDate>
    <description>We study a variant of quantum hypothesis testing wherein an additional 'inconclusive' measurement outcome is added, allowing one to abstain from attempting to discriminate the hypotheses. The error probabilities are then conditioned on a successful attempt, with inconclusive trials disregarded. We completely characterise this task in both the single-shot and asymptotic regimes, providing exact formulas for the optimal error probabilities. In particular, we prove that the asymptotic error exponent of discriminating any two quantum states $\rho$ and $\sigma$ is given by the Hilbert projective metric $D_{\max}(\rho\|\sigma) + D_{\max}(\sigma \| \rho)$ in asymmetric hypothesis testing, and by the Thompson metric $\max \{ D_{\max}(\rho\|\sigma), D_{\max}(\sigma \| \rho) \}$ in symmetric hypothesis testing. This endows these two quantities with fundamental operational interpretations in quantum state discrimination. Our findings extend to composite hypothesis testing, where we show that the asymmetric error exponent with respect to any convex set of density matrices is given by a regularisation of the Hilbert projective metric. We apply our results also to quantum channels, showing that no advantage is gained by employing adaptive or even more general discrimination schemes over parallel ones, in both the asymmetric and symmetric settings. Our state discrimination results make use of no properties specific to quantum mechanics and are also valid in general probabilistic theories.</description>
  </item>

</channel>

</rss>
<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>The randomized measurement toolbox</title>
    <link>http://arxiv.org/pdf/2203.11374</link>
    <author>Andreas Elben, Steven T. Flammia, Hsin-Yuan Huang, Richard Kueng, John Preskill, Beno√Æt Vermersch, Peter Zoller</author>
    <pubDate>Mar 23 2022</pubDate>
    <description>Increasingly sophisticated programmable quantum simulators and quantum computers are opening unprecedented opportunities for exploring and exploiting the properties of highly entangled complex quantum systems. The complexity of large quantum systems is the source of their power, but also makes them difficult to control precisely or characterize accurately using measured classical data. We review recently developed protocols for probing the properties of complex many-qubit systems using measurement schemes that are practical using today's quantum platforms. In all these protocols, a quantum state is repeatedly prepared and measured in a randomly chosen basis; then a classical computer processes the measurement outcomes to estimate the desired property. The randomization of the measurement procedure has distinct advantages; for example, a single data set can be employed multiple times to pursue a variety of applications, and imperfections in the measurements are mapped to a simplified noise model that can more easily be mitigated. We discuss a range of use cases that have already been realized in quantum devices, including Hamiltonian simulation tasks, probes of quantum chaos, measurements of nonlocal order parameters, and comparison of quantum states produced in distantly separated laboratories. By providing a workable method for translating a complex quantum state into a succinct classical representation that preserves a rich variety of relevant physical properties, the randomized measurement toolbox strengthens our ability to grasp and control the quantum world.</description>
  </item>

  <item>
    <title>Is quantum advantage the right goal for quantum machine learning?</title>
    <link>http://arxiv.org/pdf/2203.01340</link>
    <author>Maria Schuld, Nathan Killoran</author>
    <pubDate>Mar 04 2022</pubDate>
    <description>Machine learning is frequently listed among the most promising applications for quantum computing. This is in fact a curious choice: Today's machine learning algorithms are notoriously powerful in practice, but remain theoretically difficult to study. Quantum computing, in contrast, does not offer practical benchmarks on realistic scales, and theory is the main tool we have to judge whether it could become relevant for a problem. In this perspective we explain why it is so difficult to say something about the practical power of quantum computers for machine learning with the tools we are currently using. We argue that these challenges call for a critical debate on whether quantum advantage and the narrative of "beating" classical machine learning should continue to dominate the literature the way it does, and provide a few examples for alternative research questions.</description>
  </item>

  <item>
    <title>The XP Stabiliser Formalism: a Generalisation of the Pauli Stabiliser Formalism with Arbitrary Phases</title>
    <link>http://arxiv.org/pdf/2203.00103</link>
    <author>Mark A. Webster, Benjamin J. Brown, Stephen D. Bartlett</author>
    <pubDate>Mar 02 2022</pubDate>
    <description>We propose an extension to the Pauli stabiliser formalism that includes fractional $2\pi/N$ rotations around the $Z$ axis for some integer $N$. The resulting generalised stabiliser formalism - denoted the XP stabiliser formalism - allows for a wider range of states and codespaces to be represented. We describe the states which arise in the formalism, and demonstrate an equivalence between XP stabiliser states and 'weighted hypergraph states' - a generalisation of both hypergraph and weighted graph states. Given an arbitrary set of XP operators, we present algorithms for determining the codespace and logical operators for an XP code. Finally, we consider whether measurements of XP operators on XP codes can be classically simulated.</description>
  </item>

  <item>
    <title>Logical shadow tomography: Efficient estimation of error-mitigated observables</title>
    <link>http://arxiv.org/pdf/2203.07263</link>
    <author>Hong-Ye Hu, Ryan LaRose, Yi-Zhuang You, Eleanor Rieffel, Zhihui Wang</author>
    <pubDate>Mar 15 2022</pubDate>
    <description>We introduce a technique to estimate error-mitigated expectation values on noisy quantum computers. Our technique performs shadow tomography on a logical state to produce a memory-efficient classical reconstruction of the noisy density matrix. Using efficient classical post-processing, one can mitigate errors by projecting a general nonlinear function of the noisy density matrix into the codespace. The subspace expansion and virtual distillation can be viewed as special cases of the new framekwork. We show our method is favorable in the quantum and classical resources overhead. Relative to subspace expansion which requires $O\left(2^{N} \right)$ samples to estimate a logical Pauli observable with $[[N, k]]$ error correction code, our technique requires only $O\left(4^{k} \right)$ samples. Relative to virtual distillation, our technique can compute powers of the density matrix without additional copies of quantum states or quantum memory. We present numerical evidence using logical states encoded with up to sixty physical qubits and show fast convergence to error-free expectation values with only $10^5$ samples under 1% depolarizing noise.</description>
  </item>

  <item>
    <title>All quantum measurements are asymptotically equivalent</title>
    <link>http://arxiv.org/pdf/2203.02593</link>
    <author>Noah Linden, Paul Skrzypczyk</author>
    <pubDate>Mar 08 2022</pubDate>
    <description>We consider the problem of reproducing one quantum measurement given the ability to perform another. In particular, given the availability of a -- possibly imperfect -- quantum measurement which can be performed multiple times, we study to what extent it can reproduce the measurement statistics and post-measurement state of a second target measurement, in the most general setting where both the available and target measurements are arbitrary generalised quantum measurements. We show that this general problem in fact reduces to the ability to reproduce the statistics of von Neumann measurements, and that in the asymptotic limit of infinitely many uses of the available measurement, a simple protocol based upon `classical cloning' is able to perfectly achieve this task. This shows that asymptotically all (non-trivial) quantum measurements are equivalent. We also study optimal protocols for a fixed number of uses of the available measurement, and show that better protocols than classical cloning can be found in general. Our protocols show that the average error in reproducing a target measurement drops off exponentially fast, and that one can, for example, rapidly improve imperfect measurements by performing them a small number of times. This includes, but is not limited to, improving both noisy and lossy quantum measurements. Finally, we show that in a setting where we perform multiple measurements in parallel, we can moreover achieve finite-rate measurement reproduction, by using block-coding techniques from classical information theory.</description>
  </item>

  <item>
    <title>Shadow Distillation: Quantum Error Mitigation with Classical Shadows for Near-Term Quantum Processors</title>
    <link>http://arxiv.org/pdf/2203.07309</link>
    <author>Alireza Seif, Ze-Pei Cian, Sisi Zhou, Senrui Chen, Liang Jiang</author>
    <pubDate>Mar 15 2022</pubDate>
    <description>Mitigating errors in quantum information processing devices is especially important in the absence of fault tolerance. An effective method in suppressing state-preparation errors is using multiple copies to distill the ideal component from a noisy quantum state. Here, we use classical shadows and randomized measurements to circumvent the need for coherent access to multiple copies at an exponential cost. We study the scaling of resources using numerical simulations and find that the overhead is still favorable compared to full state tomography. We optimize measurement resources under realistic experimental constraints and apply our method to an experiment preparing Greenberger-Horne-Zeilinger (GHZ) state with trapped ions. In addition to improving stabilizer measurements, the analysis of the improved results reveals the nature of errors affecting the experiment. Hence, our results provide a directly applicable method for mitigating errors in near-term quantum computers.</description>
  </item>

  <item>
    <title>Fragile boundaries of tailored surface codes</title>
    <link>http://arxiv.org/pdf/2203.04948</link>
    <author>Oscar Higgott, Thomas C. Bohdanowicz, Aleksander Kubica, Steven T. Flammia, Earl T. Campbell</author>
    <pubDate>Mar 10 2022</pubDate>
    <description>Biased noise is common in physical qubits, and tailoring a quantum code to the bias by locally modifying stabilizers or changing boundary conditions has been shown to greatly increase error correction thresholds. In this work, we explore the challenges of using a specific tailored code, the XY surface code, for fault-tolerant quantum computation. We introduce an efficient and fault-tolerant decoder, belief-matching, which we show has good performance for biased circuit-level noise. Using this decoder, we find that for moderately biased noise, the XY surface code has a higher threshold and lower overhead than the square CSS surface code, however it performs worse when below threshold than the rectangular CSS surface code. We identify a contributor to the reduced performance that we call fragile boundary errors. These are string-like errors that can occur along spatial or temporal boundaries in planar architectures or during logical state preparation and measurement. While we make partial progress towards mitigating these errors by deforming the boundaries of the XY surface code, our work suggests that fragility could remain a significant obstacle, even for other tailored codes. We expect belief-matching will have other uses, and find that it increases the threshold of the surface code to 0.940(3)% in the presence of circuit-level depolarising noise, compared to 0.817(5)% for a minimum-weight perfect matching decoder.</description>
  </item>

  <item>
    <title>Hierarchies of resources for measurement-based quantum computation</title>
    <link>http://arxiv.org/pdf/2203.09965</link>
    <author>Markus Frembs, Sam Roberts, Earl T. Campbell, Stephen D. Bartlett</author>
    <pubDate>Mar 21 2022</pubDate>
    <description>For certain restricted computational tasks, quantum mechanics provides a provable advantage over any possible classical implementation. Several of these results have been proven using the framework of measurement-based quantum computation (MBQC), where non-locality and more generally contextuality have been identified as necessary resources for certain quantum computations. Here, we consider the computational power of MBQC in more detail by refining its resource requirements, both on the allowed operations and the number of accessible qubits. More precisely, we identify which Boolean functions can be computed in non-adaptive MBQC, with local operations contained within a finite level in the Clifford hierarchy. Moreover, for non-adaptive MBQC restricted to certain subtheories such as stabiliser MBQC, we compute the minimal number of qubits required to compute a given Boolean function. Our results point towards hierarchies of resources that more sharply characterise the power of MBQC beyond the binary of contextuality vs non-contextuality.</description>
  </item>

  <item>
    <title>Quantum Parameterized Complexity</title>
    <link>http://arxiv.org/pdf/2203.08002</link>
    <author>Michael J. Bremner, Zhengfeng Ji, Ryan L. Mann, Luke Mathieson, Mauro E.S. Morales, Alexis T.E. Shaw</author>
    <pubDate>Mar 16 2022</pubDate>
    <description>Parameterized complexity theory was developed in the 1990s to enrich the complexity-theoretic analysis of problems that depend on a range of parameters. In this paper we establish a quantum equivalent of classical parameterized complexity theory, motivated by the need for new tools for the classifications of the complexity of real-world problems. We introduce the quantum analogues of a range of parameterized complexity classes and examine the relationship between these classes, their classical counterparts, and well-studied problems. This framework exposes a rich classification of the complexity of parameterized versions of QMA-hard problems, demonstrating, for example, a clear separation between the Quantum Circuit Satisfiability problem and the Local Hamiltonian problem.</description>
  </item>

  <item>
    <title>Adiabatic paths of Hamiltonians, symmetries of topological order, and automorphism codes</title>
    <link>http://arxiv.org/pdf/2203.11137</link>
    <author>David Aasen, Zhenghan Wang, Matthew B. Hastings</author>
    <pubDate>Mar 22 2022</pubDate>
    <description>The recent "honeycomb code" is a fault-tolerant quantum memory defined by a sequence of checks which implements a nontrivial automorphism of the toric code. We argue that a general framework to understand this code is to consider continuous adiabatic paths of gapped Hamiltonians and we give a conjectured description of the fundamental group and second and third homotopy groups of this space in two spatial dimensions. A single cycle of such a path can implement some automorphism of the topological order of that Hamiltonian. We construct such paths for arbitrary automorphisms of two-dimensional doubled topological order. Then, realizing this in the case of the toric code, we turn this path back into a sequence of checks, constructing an automorphism code closely related to the honeycomb code.</description>
  </item>

  <item>
    <title>Quantum-enhanced Markov chain Monte Carlo</title>
    <link>http://arxiv.org/pdf/2203.12497</link>
    <author>David Layden, Guglielmo Mazzola, Ryan V. Mishmash, Mario Motta, Pawel Wocjan, Jin-Sung Kim, Sarah Sheldon</author>
    <pubDate>Mar 24 2022</pubDate>
    <description>Sampling from complicated probability distributions is a hard computational problem arising in many fields, including statistical physics, optimization, and machine learning. Quantum computers have recently been used to sample from complicated distributions that are hard to sample from classically, but which seldom arise in applications. Here we introduce a quantum algorithm to sample from distributions that pose a bottleneck in several applications, which we implement on a superconducting quantum processor. The algorithm performs Markov chain Monte Carlo (MCMC), a popular iterative sampling technique, to sample from the Boltzmann distribution of classical Ising models. In each step, the quantum processor explores the model in superposition to propose a random move, which is then accepted or rejected by a classical computer and returned to the quantum processor, ensuring convergence to the desired Boltzmann distribution. We find that this quantum algorithm converges in fewer iterations than common classical MCMC alternatives on relevant problem instances, both in simulations and experiments. It therefore opens a new path for quantum computers to solve useful--not merely difficult--problems in the near term.</description>
  </item>

  <item>
    <title>Influence in Completely Bounded Block-multilinear Forms and Classical Simulation of Quantum Algorithms</title>
    <link>http://arxiv.org/pdf/2203.00212</link>
    <author>Nikhil Bansal, Makrand Sinha, Ronald de Wolf</author>
    <pubDate>Mar 02 2022</pubDate>
    <description>The Aaronson-Ambainis conjecture (Theory of Computing '14) says that every low-degree bounded polynomial on the Boolean hypercube has an influential variable. This conjecture, if true, would imply that the acceptance probability of every $d$-query quantum algorithm can be well-approximated almost everywhere (i.e., on almost all inputs) by a $\mathrm{poly}(d)$-query classical algorithm. We prove a special case of the conjecture: in every completely bounded degree-$d$ block-multilinear form with constant variance, there always exists a variable with influence at least $1/\mathrm{poly}(d)$. In a certain sense, such polynomials characterize the acceptance probability of quantum query algorithms, as shown by Arunachalam, Bri√´t and Palazuelos (SICOMP '19). As a corollary we obtain efficient classical almost-everywhere simulation for a particular class of quantum algorithms that includes for instance $k$-fold Forrelation. Our main technical result relies on connections to free probability theory.</description>
  </item>

  <item>
    <title>Good quantum LDPC codes with linear time decoder from lossless expanders</title>
    <link>http://arxiv.org/pdf/2203.03581</link>
    <author>Ting-Chun Lin, Min-Hsiu Hsieh</author>
    <pubDate>Mar 08 2022</pubDate>
    <description>Quantum low-density parity-check (qLDPC) codes are quantum stabilizer codes where each stabilizer acts on a constant number of qubits and each qubit is acted on by a constant number of stabilizers. We study qLDPC codes constructed from balanced products and lossless expanders. We found that assuming the existence of 2-sided lossless expander graphs with free group action, the resulting qLDPC codes have constant rate, linear distance, and linear time decoders.</description>
  </item>

  <item>
    <title>Quantum Algorithms for Testing Hamiltonian Symmetry</title>
    <link>http://arxiv.org/pdf/2203.10017</link>
    <author>Margarite L. LaBorde, Mark M. Wilde</author>
    <pubDate>Mar 21 2022</pubDate>
    <description>Symmetries in a Hamiltonian play an important role in quantum physics because they correspond directly with conserved quantities of the related system. In this paper, we propose quantum algorithms capable of testing whether a Hamiltonian exhibits symmetry with respect to a group. We demonstrate that familiar expressions of Hamiltonian symmetry in quantum mechanics correspond directly with the acceptance probabilities of our algorithms. We execute one of our symmetry-testing algorithms on existing quantum computers for simple examples of both symmetric and asymmetric cases.</description>
  </item>

  <item>
    <title>The quantum low-rank approximation problem</title>
    <link>http://arxiv.org/pdf/2203.00811</link>
    <author>Nic Ezzell, Zo√´ Holmes, Patrick J. Coles</author>
    <pubDate>Mar 03 2022</pubDate>
    <description>We consider a quantum version of the famous low-rank approximation problem. Specifically, we consider the distance $D(\rho,\sigma)$ between two normalized quantum states, $\rho$ and $\sigma$, where the rank of $\sigma$ is constrained to be at most $R$. For both the trace distance and Hilbert-Schmidt distance, we analytically solve for the optimal state $\sigma$ that minimizes this distance. For the Hilbert-Schmidt distance, the unique optimal state is $\sigma = \tau_R +N_R$, where $\tau_R = \Pi_R \rho \Pi_R$ is given by projecting $\rho$ onto its $R$ principal components with projector $\Pi_R$, and $N_R$ is a normalization factor given by $N_R = \frac{1- \text{Tr}(\tau_R)}{R}\Pi_R$. For the trace distance, this state is also optimal but not uniquely optimal, and we provide the full set of states that are optimal. We briefly discuss how our results have application for performing principal component analysis (PCA) via variational optimization on quantum computers.</description>
  </item>

  <item>
    <title>Looped Pipelines Enabling Effective 3D Qubit Lattices in a Strictly 2D Device</title>
    <link>http://arxiv.org/pdf/2203.13123</link>
    <author>Zhenyu Cai, Adam Siegel, Simon Benjamin</author>
    <pubDate>Mar 25 2022</pubDate>
    <description>Many quantum computing platforms are based on a fundamentally two-dimensional physical layout. However, there are advantages (for example in fault-tolerant systems) to having a 3D architecture. Here we explore a concept called looped pipelines which permits one to obtain many of the advantages of a 3D lattice while operating a strictly 2D device. The concept leverages qubit shuttling, a well-established feature in platforms like semiconductor spin qubits and trapped-ion qubits. The looped pipeline architecture has similar hardware requirements to other shuttling approaches, but can process a stack of qubit arrays instead of just one. Simple patterns of intra- and inter-loop interactions allow one to embody diverse schemes from NISQ-era error mitigation through to fault-tolerant codes. For the former, protocols involving multiple states can be implemented with a similar space-time resource as preparing one noisy copy. For the latter, one can realise a far broader variety of code structures; in particular, we consider a stack of 2D codes within which transversal CNOTs are available. We find that this can achieve a cost saving of up to a factor of $\sim 80$ in the space-time overhead for magic state distillation (and a factor of $\sim 200$ with modest additional hardware). Using numerical modelling and experimentally-motivated noise models we verify that the looped pipeline approach provides these benefits without significant reduction in the code's threshold.</description>
  </item>

  <item>
    <title>Shorter quantum circuits</title>
    <link>http://arxiv.org/pdf/2203.10064</link>
    <author>Vadym Kliuchnikov, Kristin Lauter, Romy Minko, Adam Paetznick, Christophe Petit</author>
    <pubDate>Mar 21 2022</pubDate>
    <description>We give a novel procedure for approximating general single-qubit unitaries from a finite universal gate set by reducing the problem to a novel magnitude approximation problem, achieving an immediate improvement in sequence length by a factor of 7/9. Extending the works arXiv:1612.01011 and arXiv:1612.02689, we show that taking probabilistic mixtures of channels to solve fallback (arXiv:1409.3552) and magnitude approximation problems saves factor of two in approximation costs. In particular, over the Clifford+$\sqrt{\mathrm{T}}$ gate set we achieve an average non-Clifford gate count of $0.23\log_2(1/\varepsilon)+2.13$ and T-count $0.56\log_2(1/\varepsilon)+5.3$ with mixed fallback approximations for diamond norm accuracy $\varepsilon$. This paper provides a holistic overview of gate approximation, in addition to these new insights. We give an end-to-end procedure for gate approximation for general gate sets related to some quaternion algebras, providing pedagogical examples using common fault-tolerant gate sets (V, Clifford+T and Clifford+$\sqrt{\mathrm{T}}$). We also provide detailed numerical results for Clifford+T and Clifford+$\sqrt{\mathrm{T}}$ gate sets. In an effort to keep the paper self-contained, we include an overview of the relevant algorithms for integer point enumeration and relative norm equation solving. We provide a number of further applications of the magnitude approximation problems, as well as improved algorithms for exact synthesis, in the Appendices.</description>
  </item>

  <item>
    <title>Quantum algorithms from fluctuation theorems: Thermal-state preparation</title>
    <link>http://arxiv.org/pdf/2203.08882</link>
    <author>Zoe Holmes, Gopikrishnan Muraleedharan, Rolando D. Somma, Yigit Subasi, Burak ≈ûahinoƒülu</author>
    <pubDate>Mar 18 2022</pubDate>
    <description>Fluctuation theorems provide a correspondence between properties of quantum systems in thermal equilibrium and a work distribution arising in a non-equilibrium process that connects two quantum systems with Hamiltonians $H_0$ and $H_1=H_0+V$. Building upon these theorems, we present a quantum algorithm to prepare a purification of the thermal state of $H_1$ at inverse temperature $\beta \ge 0$ starting from a purification of the thermal state of $H_0$. The complexity of the quantum algorithm, given by the number of uses of certain unitaries, is $\tilde {\cal O}(e^{\beta (\Delta \! A- w_l)/2})$, where $\Delta \! A$ is the free-energy difference between $H_1$ and $H_0,$ and $w_l$ is a work cutoff that depends on the properties of the work distribution and the approximation error $\epsilon>0$. If the non-equilibrium process is trivial, this complexity is exponential in $\beta \|V\|$, where $\|V\|$ is the spectral norm of $V$. This represents a significant improvement of prior quantum algorithms that have complexity exponential in $\beta \|H_1\|$ in the regime where $\|V\|\ll \|H_1\|$. The dependence of the complexity in $\epsilon$ varies according to the structure of the quantum systems. It can be exponential in $1/\epsilon$ in general, but we show it to be sublinear in $1/\epsilon$ if $H_0$ and $H_1$ commute, or polynomial in $1/\epsilon$ if $H_0$ and $H_1$ are local spin systems. The possibility of applying a unitary that drives the system out of equilibrium allows one to increase the value of $w_l$ and improve the complexity even further. To this end, we analyze the complexity for preparing the thermal state of the transverse field Ising model using different non-equilibrium unitary processes and see significant complexity improvements.</description>
  </item>

  <item>
    <title>Matching and maximum likelihood decoding of a multi-round subsystem quantum error correction experiment</title>
    <link>http://arxiv.org/pdf/2203.07205</link>
    <author>Neereja Sundaresan, Theodore J. Yoder, Youngseok Kim, Muyuan Li, Edward H. Chen, Grace Harper, Ted Thorbeck, Andrew W. Cross, Antonio D. C√≥rcoles, Maika Takita</author>
    <pubDate>Mar 15 2022</pubDate>
    <description>Quantum error correction offers a promising path for performing quantum computations with low errors. Although a fully fault-tolerant execution of a quantum algorithm remains unrealized, recent experimental developments, along with improvements in control electronics, are enabling increasingly advanced demonstrations of the necessary operations for applying quantum error correction. Here, we perform quantum error correction on superconducting qubits connected in a heavy-hexagon lattice. The full processor can encode a logical qubit with distance three and perform several rounds of fault-tolerant syndrome measurements that allow the correction of any single fault in the circuitry. Furthermore, by using dynamic circuits and classical computation as part of our syndrome extraction protocols, we can exploit real-time feedback to reduce the impact of energy relaxation error in the syndrome and flag qubits. We show that the logical error varies depending on the use of a perfect matching decoder compared to a maximum likelihood decoder. We observe a logical error per syndrome measurement round as low as $\sim0.04$ for the matching decoder and as low as $\sim0.03$ for the maximum likelihood decoder. Our results suggest that more significant improvements to decoders are likely on the horizon as quantum hardware has reached a new stage of development towards fully fault-tolerant operations.</description>
  </item>

  <item>
    <title>Quantifying the barren plateau phenomenon for a model of unstructured variational ans√§tze</title>
    <link>http://arxiv.org/pdf/2203.06174</link>
    <author>John Napp</author>
    <pubDate>Mar 14 2022</pubDate>
    <description>Quantifying the flatness of the objective-function landscape associated with unstructured parameterized quantum circuits is important for understanding the performance of variational algorithms utilizing a "hardware-efficient ansatz", particularly for ensuring that a prohibitively flat landscape -- a so-called "barren plateau" -- is avoided. For a model of such ans√§tze, we relate the typical landscape flatness to a certain family of random walks, enabling us to derive a Monte Carlo algorithm for efficiently, classically estimating the landscape flatness for any architecture. The statistical picture additionally allows us to prove new analytic bounds on the barren plateau phenomenon, and more generally provides novel insights into the phenomenon's dependence on the ansatz depth, architecture, qudit dimension, and Hamiltonian combinatorial and spatial locality. Our analysis utilizes techniques originally developed by Dalzell et al. to study anti-concentration in random circuits.</description>
  </item>

  <item>
    <title>Quantifying Grover speed-ups beyond asymptotic analysis</title>
    <link>http://arxiv.org/pdf/2203.04975</link>
    <author>Chris Cade, Marten Folkertsma, Ido Niesen, Jordi Weggemans</author>
    <pubDate>Mar 11 2022</pubDate>
    <description>The usual method for studying run-times of quantum algorithms is via an asymptotic, worst-case analysis. Whilst useful, such a comparison can often fall short: it is not uncommon for algorithms with a large worst-case run-time to end up performing well on instances of practical interest. To remedy this it is necessary to resort to run-time analyses of a more empirical nature, which for sufficiently small input sizes can be performed on a quantum device or a simulation thereof. For larger input sizes, alternative approaches are required. In this paper we consider an approach that combines classical emulation with rigorous complexity bounds: simulating quantum algorithms by running classical versions of the sub-routines, whilst simultaneously collecting information about what the run-time of the quantum routine would have been if it were run instead. To do this accurately and efficiently for very large input sizes, we describe an estimation procedure that provides provable guarantees on the estimates that it obtains. A nice feature of this approach is that it allows one to compare the performance of quantum and classical algorithms on particular inputs of interest, rather than only on those that allow for an easier mathematical analysis. We apply our method to some simple quantum speedups of classical heuristic algorithms for solving the well-studied MAX-k-SAT optimization problem. To do this we first obtain some rigorous bounds (including all constants) on the expected- and worst-case complexities of two important quantum sub-routines, which improve upon existing results and might be of broader interest: Grover search with an unknown number of marked items, and quantum maximum-finding. Our results suggest that such an approach can provide insightful and meaningful information, in particular when the speedup is of a small polynomial nature.</description>
  </item>

  <item>
    <title>Tailored XZZX codes for biased noise</title>
    <link>http://arxiv.org/pdf/2203.16486</link>
    <author>Qian Xu, Nam Mannucci, Alireza Seif, Aleksander Kubica, Steven T. Flammia, Liang Jiang</author>
    <pubDate>Mar 31 2022</pubDate>
    <description>Quantum error correction (QEC) for generic errors is challenging due to the demanding threshold and resource requirements. Interestingly, when physical noise is biased, we can tailor our QEC schemes to the noise to improve performance. Here we study a family of codes having XZZX-type stabilizer generators, including a set of cyclic codes generalized from the five-qubit code and a set of topological codes that we call generalized toric codes (GTCs). We show that these XZZX codes are highly qubit efficient if tailored to biased noise. To characterize the code performance, we use the notion of effective distance, which generalizes code distance to the case of biased noise and constitutes a proxy for the logical failure rate. We find that the XZZX codes can achieve a favorable resource scaling by this metric under biased noise. We also show that the XZZX codes have remarkably high thresholds that reach what is achievable by random codes, and furthermore they can be efficiently decoded using matching decoders. Finally, by adding only one flag qubit, the XZZX codes can realize fault-tolerant QEC while preserving their large effective distance. In combination, our results show that tailored XZZX codes give a resource-efficient scheme for fault-tolerant QEC against biased noise.</description>
  </item>

  <item>
    <title>Improved Quantum Algorithms for Fidelity Estimation</title>
    <link>http://arxiv.org/pdf/2203.15993</link>
    <author>Andr√°s Gily√©n, Alexander Poremba</author>
    <pubDate>Mar 31 2022</pubDate>
    <description>Fidelity is a fundamental measure for the closeness of two quantum states, which is important both from a theoretical and a practical point of view. Yet, in general, it is difficult to give good estimates of fidelity, especially when one works with mixed states over Hilbert spaces of very high dimension. Although, there has been some progress on fidelity estimation, all prior work either requires a large number of identical copies of the relevant states, or relies on unproven heuristics. In this work, we improve on both of these aspects by developing new and efficient quantum algorithms for fidelity estimation with provable performance guarantees in case at least one of the states is approximately low-rank. Our algorithms use advanced quantum linear algebra techniques, such as the quantum singular value transformation, as well as density matrix exponentiation and quantum spectral sampling. As a complementary result, we prove that fidelity estimation to any non-trivial constant additive accuracy is hard in general, by giving a sample complexity lower bound that depends polynomially on the dimension. Moreover, if circuit descriptions for the relevant states are provided, we show that the task is hard for the complexity class called (honest verifier) quantum statistical zero knowledge via a reduction to a closely related result by Watrous.</description>
  </item>

  <item>
    <title>Memory Compression with Quantum Random-Access Gates</title>
    <link>http://arxiv.org/pdf/2203.05599</link>
    <author>Harry Buhrman, Bruno Loff, Subhasree Patro, Florian Speelman</author>
    <pubDate>Mar 14 2022</pubDate>
    <description>In the classical RAM, we have the following useful property. If we have an algorithm that uses $M$ memory cells throughout its execution, and in addition is sparse, in the sense that, at any point in time, only $m$ out of $M$ cells will be non-zero, then we may "compress" it into another algorithm which uses only $m \log M$ memory and runs in almost the same time. We may do so by simulating the memory using either a hash table, or a self-balancing tree. We show an analogous result for quantum algorithms equipped with quantum random-access gates. If we have a quantum algorithm that runs in time $T$ and uses $M$ qubits, such that the state of the memory, at any time step, is supported on computational-basis vectors of Hamming weight at most $m$, then it can be simulated by another algorithm which uses only $O(m \log M)$ memory, and runs in time $\tilde O(T)$. We show how this theorem can be used, in a black-box way, to simplify the presentation in several papers. Broadly speaking, when there exists a need for a space-efficient history-independent quantum data-structure, it is often possible to construct a space-inefficient, yet sparse, quantum data structure, and then appeal to our main theorem. This results in simpler and shorter arguments.</description>
  </item>

  <item>
    <title>Opportunities and Limitations in Broadband Sensing</title>
    <link>http://arxiv.org/pdf/2203.05520</link>
    <author>Anthony M. Polloreno, Jacob L. Beckey, Joshua Levin, Ariel Shlosberg, James K. Thompson, Michael Foss-Feig, David Hayes, Graeme Smith</author>
    <pubDate>Mar 11 2022</pubDate>
    <description>We consider estimating the magnitude of a monochromatic AC signal that couples to a two-level sensor. For any detection protocol, the precision achieved depends on the signal's frequency and can be quantified by the quantum Fisher information. To study limitations in broadband sensing, we introduce the integrated quantum Fisher information and derive inequality bounds that embody fundamental tradeoffs in any sensing protocol. These inequalities show that sensitivity in one frequency range must come at a cost of reduced sensitivity elsewhere. For many protocols, including those with small phase accumulation and those consisting of $\pi$-pulses, we find the integrated Fisher information scales linearly with $T$. We also find protocols with substantial phase accumulation can have integrated QFI that grows quadratically with $T$, which is optimal. These protocols may allow the very rapid detection of a signal with unknown frequency over a very wide bandwidth.</description>
  </item>

  <item>
    <title>Quantum algorithms for estimating quantum entropies</title>
    <link>http://arxiv.org/pdf/2203.02386</link>
    <author>Youle Wang, Benchi Zhao, Xin Wang</author>
    <pubDate>Mar 07 2022</pubDate>
    <description>The von Neumann and quantum R√©nyi entropies characterize fundamental properties of quantum systems and lead to theoretical and practical applications in many fields. Quantum algorithms for estimating quantum entropies, using a quantum query model that prepares the purification of the input state, have been established in the literature. However, constructing such a model is almost as hard as state tomography. In this paper, we propose quantum algorithms to estimate the von Neumann and quantum $\alpha$-R√©nyi entropies of an $n$-qubit quantum state $\rho$ using independent copies of the input state. We also show how to efficiently construct the quantum circuits for quantum entropy estimation using primitive single/two-qubit gates. We prove that the number of required copies scales polynomially in $1/\epsilon$ and $1/\Lambda$, where $\epsilon$ denotes the additive precision and $\Lambda$ denotes the lower bound on all non-zero eigenvalues. Notably, our method outperforms previous methods in the aspect of practicality since it does not require any quantum query oracles, which are usually necessary for previous methods. Furthermore, we conduct experiments to show the efficacy of our algorithms to single-qubit states and study the noise robustness. We also discuss the applications to some quantum states of practical interest as well as some meaningful tasks such as quantum Gibbs state preparation and entanglement estimation.</description>
  </item>

  <item>
    <title>Quantum circuit compilation and hybrid computation using Pauli-based computation</title>
    <link>http://arxiv.org/pdf/2203.01789</link>
    <author>F.C.R. Peres, Ernesto F. Galv√£o</author>
    <pubDate>Mar 04 2022</pubDate>
    <description>Pauli-based computation (PBC) is driven by a sequence of adaptively chosen, non-destructive measurements of Pauli observables. Any quantum circuit written in terms of the Clifford+$T$ gate set and having $t$ $T$ gates can be compiled into a PBC on $t$ qubits. Here we propose practical ways of implementing PBC as adaptive quantum circuits, and provide code to do the required classical side-processing. Our first scheme reduces the number of quantum gates to $O(t^2)$ (from a previous $O(t^3 / \log t)$ scaling) at the cost of one extra auxiliary qubit, with a possible reduction of the depth to $O(t \log t$), at the cost of $t$ additional auxiliary qubits (second scheme). We compile examples of random and hidden-shift quantum circuits into adaptive PBC circuits. We also simulate hybrid quantum computation, where a classical computer effectively extends the working memory of a small quantum computer by $k$ virtual qubits, at a cost exponential in $k$. Our results demonstrate the practical advantage of PBC techniques for circuit compilation and hybrid computation.</description>
  </item>

  <item>
    <title>A cellular automaton decoder for a noise-bias tailored color code</title>
    <link>http://arxiv.org/pdf/2203.16534</link>
    <author>Jonathan F. San Miguel, Dominic J. Williamson, Benjamin J. Brown</author>
    <pubDate>Mar 31 2022</pubDate>
    <description>Self-correcting quantum memories demonstrate robust properties that can be exploited to improve active quantum error-correction protocols. Here we propose a cellular automaton decoder for a variation of the color code where the bases of the physical qubits are locally rotated, which we call the XYZ color code. The local transformation means our decoder demonstrates key properties of a two-dimensional fractal code if the noise acting on the system is infinitely biased towards dephasing, namely, no string-like logical operators. As such, in the high-bias limit, our local decoder reproduces the behavior of a partially self-correcting memory. At low error rates, our simulations show that the memory time diverges polynomially with system size without intervention from a global decoder, up to some critical system size that grows as the error rate is lowered. Furthermore, although we find that we cannot reproduce partially self-correcting behavior at finite bias, our numerics demonstrate improved memory times at realistic noise biases. Our results therefore motivate the design of tailored cellular automaton decoders that help to reduce the bandwidth demands of global decoding for realistic noise models.</description>
  </item>

  <item>
    <title>Detecting entanglement in quantum many-body systems via permutation moments</title>
    <link>http://arxiv.org/pdf/2203.08391</link>
    <author>Zhenhuan Liu, Yifan Tang, Hao Dai, Pengyu Liu, Shu Chen, Xiongfeng Ma</author>
    <pubDate>Mar 17 2022</pubDate>
    <description>Multipartite entanglement plays an essential role in both quantum information science and many-body physics. Due to the exponentially large dimension and complex geometric structure of the state space, the detection of entanglement in many-body systems is extremely challenging in reality. Conventional means, like entanglement witness and entropy criterion, either highly depend on the prior knowledge of the studied systems or the detection capability is relatively weak. In this work, we propose a framework for designing multipartite entanglement criteria based on permutation moments, which have an effective implementation with either the generalized control-SWAP quantum circuits or the random unitary techniques. These criteria show strong detection capability in the multi-qubit Ising model with a long-range $XY$ Hamiltonian. The quantities associated with these criteria have clear physical meaning and can be used as entanglement quantifiers, with which we show the entanglement scaling transition in a quantum dynamical phase transition. Furthermore, our framework can also be generalized to detect the much more complicated entanglement structure in quantum many-body systems.</description>
  </item>

  <item>
    <title>Improved Quantum Query Upper Bounds Based on Classical Decision Trees</title>
    <link>http://arxiv.org/pdf/2203.02968</link>
    <author>Arjan Cornelissen, Nikhil S. Mande, Subhasree Patro</author>
    <pubDate>Mar 08 2022</pubDate>
    <description>Given a classical query algorithm as a decision tree, when does there exist a quantum query algorithm with a speed-up over the classical one? We provide a general construction based on the structure of the underlying decision tree, and prove that this can give us an up-to-quadratic quantum speed-up. In particular, we obtain a bounded-error quantum query algorithm of cost $O(\sqrt{s})$ to compute a Boolean function (more generally, a relation) that can be computed by a classical (even randomized) decision tree of size $s$. Lin and Lin [ToC'16] and Beigi and Taghavi [Quantum'20] showed results of a similar flavor, and gave upper bounds in terms of a quantity which we call the "guessing complexity" of a decision tree. We identify that the guessing complexity of a decision tree equals its rank, a notion introduced by Ehrenfeucht and Haussler [Inf. Comp.'89] in the context of learning theory. This answers a question posed by Lin and Lin, who asked whether the guessing complexity of a decision tree is related to any complexity-theoretic measure. We also show a polynomial separation between rank and randomized rank for the complete binary AND-OR tree. Beigi and Taghavi constructed span programs and dual adversary solutions for Boolean functions given classical decision trees computing them and an assignment of non-negative weights to its edges. We explore the effect of changing these weights on the resulting span program complexity and objective value of the dual adversary bound, and capture the best possible weighting scheme by an optimization program. We exhibit a solution to this program and argue its optimality from first principles. We also exhibit decision trees for which our bounds are asymptotically stronger than those of Lin and Lin, and Beigi and Taghavi. This answers a question of Beigi and Taghavi, who asked whether different weighting schemes could yield better upper bounds.</description>
  </item>

</channel>

</rss>
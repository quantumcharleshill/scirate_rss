<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>The Early Days of Quantum Computation</title>
    <link>http://arxiv.org/pdf/2208.09964</link>
    <author>Peter W. Shor</author>
    <pubDate>Aug 23 2022</pubDate>
    <description>I recount some of my memories of the early development of quantum computation, including the discovery of the factoring algorithm, of error correcting codes, and of fault tolerance.</description>
  </item>

  <item>
    <title>The Physics of Quantum Information</title>
    <link>http://arxiv.org/pdf/2208.08064</link>
    <author>John Preskill</author>
    <pubDate>Aug 18 2022</pubDate>
    <description>Rapid ongoing progress in quantum information science makes this an apt time for a Solvay Conference focused on The Physics of Quantum Information. Here I review four intertwined themes encompassed by this topic: Quantum computer science, quantum hardware, quantum matter, and quantum gravity. Though the time scale for broad practical impact of quantum computation is still uncertain, in the near future we can expect noteworthy progress toward scalable fault-tolerant quantum computing, and discoveries enabled by programmable quantum simulators. In the longer term, controlling highly complex quantum matter will open the door to profound scientific advances and powerful new technologies.</description>
  </item>

  <item>
    <title>Implementing Fault-tolerant Entangling Gates on the Five-qubit Code and the Color Code</title>
    <link>http://arxiv.org/pdf/2208.01863</link>
    <author>C. Ryan-Anderson, N. C. Brown, M. S. Allman, B. Arkin, G. Asa-Attuah, C. Baldwin, J. Berg, J. G. Bohnet, S. Braxton, N. Burdick, J. P. Campora, A. Chernoguzov, J. Esposito, B. Evans, D. Francois, J. P. Gaebler, T. M. Gatterman, J. Gerber, K. Gilmore, D. Gresh, et al (17)</author>
    <pubDate>Aug 04 2022</pubDate>
    <description>We compare two different implementations of fault-tolerant entangling gates on logical qubits. In one instance, a twelve-qubit trapped-ion quantum computer is used to implement a non-transversal logical CNOT gate between two five qubit codes. The operation is evaluated with varying degrees of fault tolerance, which are provided by including quantum error correction circuit primitives known as flagging and pieceable fault tolerance. In the second instance, a twenty-qubit trapped-ion quantum computer is used to implement a transversal logical CNOT gate on two [[7,1,3]] color codes. The two codes were implemented on different but similar devices, and in both instances, all of the quantum error correction primitives, including the determination of corrections via decoding, are implemented during runtime using a classical compute environment that is tightly integrated with the quantum processor. For different combinations of the primitives, logical state fidelity measurements are made after applying the gate to different input states, providing bounds on the process fidelity. We find the highest fidelity operations with the color code, with the fault-tolerant SPAM operation achieving fidelities of 0.99939(15) and 0.99959(13) when preparing eigenstates of the logical X and Z operators, which is higher than the average physical qubit SPAM fidelities of 0.9968(2) and 0.9970(1) for the physical X and Z bases, respectively. When combined with a logical transversal CNOT gate, we find the color code to perform the sequence--state preparation, CNOT, measure out--with an average fidelity bounded by [0.9957,0.9963]. The logical fidelity bounds are higher than the analogous physical-level fidelity bounds, which we find to be [0.9850,0.9903], reflecting multiple physical noise sources such as SPAM errors for two qubits, several single-qubit gates, a two-qubit gate and some amount of memory error.</description>
  </item>

  <item>
    <title>A mathematical framework for quantum Hamiltonian simulation and duality</title>
    <link>http://arxiv.org/pdf/2208.11941</link>
    <author>Harriet Apel, Toby Cubitt</author>
    <pubDate>Aug 26 2022</pubDate>
    <description>Analogue Hamiltonian simulation is a promising near-term application of quantum computing and has recently been put on a theoretical footing. In Hamiltonian simulation, a physical Hamiltonian is engineered to have identical physics to another - often very different - Hamiltonian. This is qualitatively similar to the notion of duality in physics, whereby two superficially different theories are mathematically equivalent in some precise sense. However, existing characterisations of Hamiltonian simulations are not sufficiently general to extend to all dualities in physics. In particular, they cannot encompass the important cases of strong/weak and high-temperature/low-temperature dualities. In this work, we give three physically motivated axiomatisations of duality, formulated respectively in terms of observables, partition functions and entropies. We prove that these axiomatisations are equivalent, and characterise the mathematical form that any duality satisfying these axioms must take. A building block in one of our results is a strengthening of earlier results on entropy-preserving maps to maps that are entropy-preserving up to an additive constant, which we prove decompose as a direct sum of unitary and anti-unitary components, which may be of independent mathematical interest.</description>
  </item>

  <item>
    <title>Wasserstein Complexity of Quantum Circuits</title>
    <link>http://arxiv.org/pdf/2208.06306</link>
    <author>Lu Li, Kaifeng Bu, Dax Enshan Koh, Arthur Jaffe, Seth Lloyd</author>
    <pubDate>Aug 15 2022</pubDate>
    <description>Given a unitary transformation, what is the size of the smallest quantum circuit that implements it? This quantity, known as the quantum circuit complexity, is a fundamental property of quantum evolutions that has widespread applications in many fields, including quantum computation, quantum field theory, and black hole physics. In this letter, we obtain a new lower bound for the quantum circuit complexity in terms of a novel complexity measure that we propose for quantum circuits, which we call the quantum Wasserstein complexity. Our proposed measure is based on the quantum Wasserstein distance of order one (also called the quantum earth mover's distance), a metric on the space of quantum states. We also prove several fundamental and important properties of our new complexity measure, which stand to be of independent interest. Finally, we show that our new measure also provides a lower bound for the experimental cost of implementing quantum circuits, which implies a quantum limit on converting quantum resources to computational resources. Our results provide novel applications of the quantum Wasserstein distance and pave the way for a deeper understanding of the resources needed to implement a quantum computation.</description>
  </item>

  <item>
    <title>Simulating quantum circuits using efficient tensor network contraction algorithms with subexponential upper bound</title>
    <link>http://arxiv.org/pdf/2208.01498</link>
    <author>Thorsten B. Wahl, Sergii Strelchuk</author>
    <pubDate>Aug 03 2022</pubDate>
    <description>We derive a rigorous upper bound on the classical computation time of finite-ranged tensor network contractions in $d \geq 2$ dimensions. By means of the Sphere Separator Theorem, we are able to take advantage of the structure of quantum circuits to speed up contractions to show that quantum circuits of single-qubit and finite-ranged two-qubit gates can be classically simulated in subexponential time in the number of gates. In many practically relevant cases this beats standard simulation schemes. Moreover, our algorithm leads to speedups of several orders of magnitude over naive contraction schemes for two-dimensional quantum circuits on as little as an $8 \times 8$ lattice. We obtain similarly efficient contraction schemes for Google's Sycamore-type quantum circuits, instantaneous quantum polynomial-time circuits and non-homogeneous (2+1)-dimensional random quantum circuits.</description>
  </item>

  <item>
    <title>Classical shadows of fermions with particle number symmetry</title>
    <link>http://arxiv.org/pdf/2208.08964</link>
    <author>Guang Hao Low</author>
    <pubDate>Aug 19 2022</pubDate>
    <description>We consider classical shadows of fermion wavefunctions with $\eta$ particles occupying $n$ modes. We prove that of all $k$-reduced density matrices may be simultaneously estimated to an average variance of $\epsilon^{2}$ using at most $\binom{\eta}{k}\big(1-\frac{\eta-k}{n}\big)^{k}\frac{1+n}{1+n-k}/\epsilon^{2}$ measurements in random single-particle bases that conserve particle number, and provide an estimator that is computationally efficient. This is a super-exponential improvement over the $\binom{n}{k}\sqrt{\pi k}/\epsilon^{2}$ scaling of prior approaches as $n$ can be arbitrarily larger than $\eta$ in natural problems. Our method, in the worst-case of half-filling, still provides a factor of $4^{k}$ advantage in sample complexity, and also estimates all $\eta$-reduced density matrices, applicable to estimating overlaps with all single Slater determinants, with at most $\frac{4}{3}/\epsilon^{2}$ samples, which is additionally independent of $\eta$.</description>
  </item>

  <item>
    <title>Optimal algorithms for learning quantum phase states</title>
    <link>http://arxiv.org/pdf/2208.07851</link>
    <author>Srinivasan Arunachalam, Sergey Bravyi, Arkopal Dutt, Theodore J. Yoder</author>
    <pubDate>Aug 17 2022</pubDate>
    <description>We analyze the complexity of learning $n$-qubit quantum phase states. A degree-$d$ phase state is defined as a superposition of all $2^n$ basis vectors $x$ with amplitudes proportional to $(-1)^{f(x)}$, where $f$ is a degree-$d$ Boolean polynomial over $n$ variables. We show that the sample complexity of learning an unknown degree-$d$ phase state is $\Theta(n^d)$ if we allow separable measurements and $\Theta(n^{d-1})$ if we allow entangled measurements. Our learning algorithm based on separable measurements has runtime $\textsf{poly}(n)$ (for constant $d$) and is well-suited for near-term demonstrations as it requires only single-qubit measurements in the Pauli $X$ and $Z$ bases. We show similar bounds on the sample complexity for learning generalized phase states with complex-valued amplitudes. We further consider learning phase states when $f$ has sparsity-$s$, degree-$d$ in its $\mathbb{F}_2$ representation (with sample complexity $O(2^d sn)$), $f$ has Fourier-degree-$t$ (with sample complexity $O(2^{2t})$), and learning quadratic phase states with $\varepsilon$-global depolarizing noise (with sample complexity $O(n^{1+\varepsilon})$). These learning algorithms give us a procedure to learn the diagonal unitaries of the Clifford hierarchy and IQP circuits.</description>
  </item>

  <item>
    <title>Mean estimation when you have the source code; or, quantum Monte Carlo methods</title>
    <link>http://arxiv.org/pdf/2208.07544</link>
    <author>Robin Kothari, Ryan O'Donnell</author>
    <pubDate>Aug 17 2022</pubDate>
    <description>Suppose $\boldsymbol{y}$ is a real random variable, and one is given access to ``the code'' that generates it (for example, a randomized or quantum circuit whose output is $\boldsymbol{y}$). We give a quantum procedure that runs the code $O(n)$ times and returns an estimate $\widehat{\boldsymbol{\mu}}$ for $\mu = \mathrm{E}[\boldsymbol{y}]$ that with high probability satisfies $|\widehat{\boldsymbol{\mu}} - \mu| \leq \sigma/n$, where $\sigma = \mathrm{stddev}[\boldsymbol{y}]$. This dependence on $n$ is optimal for quantum algorithms. One may compare with classical algorithms, which can only achieve the quadratically worse $|\widehat{\boldsymbol{\mu}} - \mu| \leq \sigma/\sqrt{n}$. Our method improves upon previous works, which either made additional assumptions about $\boldsymbol{y}$, and/or assumed the algorithm knew an a priori bound on $\sigma$, and/or used additional logarithmic factors beyond $O(n)$. The central subroutine for our result is essentially Grover's algorithm but with complex phases.ally Grover's algorithm but with complex phases.</description>
  </item>

  <item>
    <title>Solving boolean satisfiability problems with the quantum approximate optimization algorithm</title>
    <link>http://arxiv.org/pdf/2208.06909</link>
    <author>Sami Boulebnane, Ashley Montanaro</author>
    <pubDate>Aug 16 2022</pubDate>
    <description>The quantum approximate optimization algorithm (QAOA) is one of the most prominent proposed applications for near-term quantum computing. Here we study the ability of QAOA to solve hard constraint satisfaction problems, as opposed to optimization problems. We focus on the fundamental boolean satisfiability problem, in the form of random $k$-SAT. We develop analytic bounds on the average success probability of QAOA over random boolean formulae at the satisfiability threshold, as the number of variables $n$ goes to infinity. The bounds hold for fixed parameters and when $k$ is a power of 2. We complement these theoretical results with numerical results on the performance of QAOA for small $n$, showing that these match the limiting theoretical bounds closely. We then use these results to compare QAOA with leading classical solvers. In the case of random 8-SAT, we find that for around 14 ansatz layers, QAOA matches the scaling performance of the highest-performance classical solver we tested, WalkSATlm. For larger numbers of layers, QAOA outperforms WalkSATlm, with an ultimate level of advantage that is still to be determined. Our methods provide a framework for analysing the performance of QAOA for hard constraint satisfaction problems and finding further speedups over classical algorithms.</description>
  </item>

  <item>
    <title>Erasure qubits: Overcoming the $T_1$ limit in superconducting circuits</title>
    <link>http://arxiv.org/pdf/2208.05461</link>
    <author>Aleksander Kubica, Arbel Haim, Yotam Vaknin, Fernando Brandão, Alex Retzker</author>
    <pubDate>Aug 11 2022</pubDate>
    <description>The amplitude damping time, $T_1$, has long stood as the major factor limiting quantum fidelity in superconducting circuits, prompting concerted efforts in the material science and design of qubits aimed at increasing $T_1$. In contrast, the dephasing time, $T_{\phi}$, can usually be extended above $T_1$ (via, e.g., dynamical decoupling), to the point where it does not limit fidelity. In this article we propose a scheme for overcoming the conventional $T_1$ limit on fidelity by designing qubits in a way that amplitude damping errors can be detected and converted into erasure errors. Compared to standard qubit implementations our scheme improves the performance of fault-tolerant protocols, as numerically demonstrated by the circuit-noise simulations of the surface code. We describe two simple qubit implementations with superconducting circuits and discuss procedures for detecting amplitude damping errors, performing entangling gates, and extending $T_\phi$. Our results suggest that engineering efforts should focus on improving $T_\phi$ and the quality of quantum coherent control, as they effectively become the limiting factor on the performance of fault-tolerant protocols.</description>
  </item>

  <item>
    <title>Universal sample lower bounds for quantum error mitigation</title>
    <link>http://arxiv.org/pdf/2208.09178</link>
    <author>Ryuji Takagi, Hiroyasu Tajima, Mile Gu</author>
    <pubDate>Aug 22 2022</pubDate>
    <description>Although numerous quantum error-mitigation protocols have been proposed as means to suppress noise effects on intermediate-scale quantum devices, their general potential and limitations have still been elusive. In particular, to understand the ultimate feasibility of quantum error mitigation, it is crucial to characterize the fundamental sampling cost -- how many times an arbitrary mitigation protocol must run a noisy quantum device. Here, we establish universal lower bounds on the sampling cost for quantum error mitigation to achieve the desired accuracy with high probability. Our bounds apply to general mitigation protocols, including the ones involving nonlinear postprocessing. We further show that the number of samples required for a wide class of protocols to mitigate errors in layered circuits must grow exponentially with the circuit depth for various noise models, revealing the fundamental obstacles in showing useful applications of noisy near-term quantum devices.</description>
  </item>

  <item>
    <title>Inevitability of knowing less than nothing</title>
    <link>http://arxiv.org/pdf/2208.14424</link>
    <author>Gilad Gour, Mark M. Wilde, Sarah Brandsen, Isabelle Jianing Geng</author>
    <pubDate>Aug 31 2022</pubDate>
    <description>A colloquial interpretation of entropy is that it is the knowledge gained upon learning the outcome of a random experiment. Conditional entropy is then interpreted as the knowledge gained upon learning the outcome of one random experiment after learning the outcome of another, possibly statistically dependent, random experiment. In the classical world, entropy and conditional entropy take only non-negative values, consistent with the intuition that one has regarding the aforementioned interpretations. However, for certain entangled states, one obtains negative values when evaluating commonly accepted and information-theoretically justified formulas for the quantum conditional entropy, leading to the confounding conclusion that one can know less than nothing in the quantum world. Here, we introduce a physically motivated framework for defining quantum conditional entropy, based on two simple postulates inspired by the second law of thermodynamics (non-decrease of entropy) and extensivity of entropy, and we argue that all plausible definitions of quantum conditional entropy should respect these two postulates. We then prove that all plausible quantum conditional entropies take on negative values for certain entangled states, so that it is inevitable that one can know less than nothing in the quantum world. All of our arguments are based on constructions of physical processes that respect the first postulate, the one inspired by the second law of thermodynamics.</description>
  </item>

  <item>
    <title>Is there evidence for exponential quantum advantage in quantum chemistry?</title>
    <link>http://arxiv.org/pdf/2208.02199</link>
    <author>Seunghoon Lee, Joonho Lee, Huanchen Zhai, Yu Tong, Alexander M. Dalzell, Ashutosh Kumar, Phillip Helms, Johnnie Gray, Zhi-Hao Cui, Wenyuan Liu, Michael Kastoryano, Ryan Babbush, John Preskill, David R. Reichman, Earl T. Campbell, Edward F. Valeev, Lin Lin, Garnet Kin-Lic Chan</author>
    <pubDate>Aug 04 2022</pubDate>
    <description>The idea to use quantum mechanical devices to simulate other quantum systems is commonly ascribed to Feynman. Since the original suggestion, concrete proposals have appeared for simulating molecular and materials chemistry through quantum computation, as a potential "killer application". Indications of potential exponential quantum advantage in artificial tasks have increased interest in this application, thus, it is critical to understand the basis for potential exponential quantum advantage in quantum chemistry. Here we gather the evidence for this case in the most common task in quantum chemistry, namely, ground-state energy estimation. We conclude that evidence for such an advantage across chemical space has yet to be found. While quantum computers may still prove useful for quantum chemistry, it may be prudent to assume exponential speedups are not generically available for this problem.</description>
  </item>

  <item>
    <title>Universal cost bound of quantum error mitigation based on quantum estimation theory</title>
    <link>http://arxiv.org/pdf/2208.09385</link>
    <author>Kento Tsubouchi, Takahiro Sagawa, Nobuyuki Yoshioka</author>
    <pubDate>Aug 22 2022</pubDate>
    <description>Quantum error mitigation is an art to combat noise in quantum computers that are not fully fault tolerant. While a wide variety of techniques has been proposed with surging number of experimental applications, little is known concerning the unified understanding on their fundamental aspects. In this paper, we perform a theoretical analysis on the cost of quantum error mitigation using the quantum estimation theory. The applicability of quantum estimation theory is extended so that we can analyze the quantum Fisher information of layered noisy quantum circuits equipped with a wide range of quantum error mitigation methods. By showing that the quantum Fisher information decays exponentially with the circuit depth, we derive for a general class of Markovian noise that unbiased estimation of an observable encounters an exponential growth in the lower bound on the measurement cost, or more precisely the required number of copies of noisy quantum state. As two practical and illustrative examples, we discuss the case when the noise channel is solely the global or local depolarizing noise. We explicitly express the lower bound in terms of their noise rates, and further find that we can asymptotically saturate the bound by a simple mitigation technique for the global depolarizing noise. Our results not only reveal the physical limitations of quantum error mitigation, but may also provide a new criteria for performance evaluation of quantum error mitigation techniques.</description>
  </item>

  <item>
    <title>Exponential concentration and untrainability in quantum kernel methods</title>
    <link>http://arxiv.org/pdf/2208.11060</link>
    <author>Supanut Thanasilp, Samson Wang, M. Cerezo, Zoë Holmes</author>
    <pubDate>Aug 24 2022</pubDate>
    <description>Kernel methods in Quantum Machine Learning (QML) have recently gained significant attention as a potential candidate for achieving a quantum advantage in data analysis. Among other attractive properties, when training a kernel-based model one is guaranteed to find the optimal model's parameters due to the convexity of the training landscape. However, this is based on the assumption that the quantum kernel can be efficiently obtained from a quantum hardware. In this work we study the trainability of quantum kernels from the perspective of the resources needed to accurately estimate kernel values. We show that, under certain conditions, values of quantum kernels over different input data can be exponentially concentrated (in the number of qubits) towards some fixed value, leading to an exponential scaling of the number of measurements required for successful training. We identify four sources that can lead to concentration including: the expressibility of data embedding, global measurements, entanglement and noise. For each source, an associated concentration bound of quantum kernels is analytically derived. Lastly, we show that when dealing with classical data, training a parametrized data embedding with a kernel alignment method is also susceptible to exponential concentration. Our results are verified through numerical simulations for several QML tasks. Altogether, we provide guidelines indicating that certain features should be avoided to ensure the efficient evaluation and the trainability of quantum kernel methods.</description>
  </item>

  <item>
    <title>Correcting non-independent and non-identically distributed errors with surface codes</title>
    <link>http://arxiv.org/pdf/2208.02191</link>
    <author>Konstantin Tiurev, Peter-Jan H. S. Derks, Joschka Roffe, Jens Eisert, Jan-Michael Reiner</author>
    <pubDate>Aug 04 2022</pubDate>
    <description>A common approach to studying the performance of quantum error correcting codes is to assume independent and identically distributed single-qubit errors. However, realistic errors in experimental multi-qubit devices are typically neither independent nor identical across qubits. In this work, we develop and investigate the properties of topological surface codes tailored to a known noise channel by locally adapted Clifford conjugations. We show that the surface code locally tailored to non-uniform single-qubit noise in conjunction with a scalable matching decoder yields improved error thresholds and exponentially suppressed sub-threshold failure rates when compared to the Calderbank-Shor-Steane surface code. Furthermore, we study the behaviour of the tailored surface code under local two-qubit noise and show the role that code degeneracy plays in correcting such noise. The proposed methods do not require additional overhead in terms of the number of qubits and use a standard matching decoder, hence come at no extra cost compared to the standard surface-code error correction.</description>
  </item>

  <item>
    <title>A parallel decoder for good quantum LDPC codes</title>
    <link>http://arxiv.org/pdf/2208.05537</link>
    <author>Anthony Leverrier, Gilles Zémor</author>
    <pubDate>Aug 12 2022</pubDate>
    <description>We introduce a parallel decoding algorithm for recently discovered families of asymptotically good quantum low-density parity-check codes. This algorithm provably corrects arbitrary errors of weight linear in the code length, with a logarithmic number of steps. This decoder applies directly to the family of quantum Tanner codes, and serves as a subroutine for expander lifted product codes. Along the way, we exploit recently established bounds on the robustness of random tensor codes to give a tight bound on the minimum distance of quantum Tanner codes.</description>
  </item>

  <item>
    <title>A local pre-decoder to reduce the bandwidth and latency of quantum error correction</title>
    <link>http://arxiv.org/pdf/2208.04660</link>
    <author>Samuel C. Smith, Benjamin J. Brown, Stephen D. Bartlett</author>
    <pubDate>Aug 10 2022</pubDate>
    <description>A fault-tolerant quantum computer will be supported by a classical decoding system interfacing with quantum hardware to perform quantum error correction. It is important that the decoder can keep pace with the quantum clock speed, within the limitations on communication that are imposed by the physical architecture. To this end we propose a local `pre-decoder', which makes greedy corrections to reduce the amount of syndrome data sent to a standard matching decoder. We study these classical overheads for the surface code under a phenomenological phase-flip noise model with imperfect measurements. We find substantial improvements in the runtime of the global decoder and the communication bandwidth by using the pre-decoder. For instance, to achieve a logical failure probability of $f = 10^{-15}$ using qubits with physical error rate $p = 10^{-3}$ and a distance $d=22$ code, we find that the bandwidth cost is reduced by a factor of $1000$, and the time taken by a matching decoder is sped up by a factor of $200$. To achieve this target failure probability, the pre-decoding approach requires a $50\%$ increase in the qubit count compared with the optimal decoder.</description>
  </item>

  <item>
    <title>Extendibility of Werner States</title>
    <link>http://arxiv.org/pdf/2208.13743</link>
    <author>Dávid Jakab, Adrián Solymos, Zoltán Zimborás</author>
    <pubDate>Aug 30 2022</pubDate>
    <description>We investigate the two-sided symmetric extendibility problem of Werner states. The interplay of the unitary symmetry of these states and the inherent bipartite permutation symmetry of the extendibility scenario allows us to map this problem into the ground state problem of a highly symmetric spin-model Hamiltonian. We solve this ground state problem analytically by utilizing the representation theory of SU(d), in particular a result related to the dominance order of Young diagrams in Littlewood-Richarson decompositions. As a result, we obtain necessary and sufficient conditions for the extendibility of Werner states for arbitrary extension size and local dimension. Interestingly, the range of extendible states has a non-trivial trade-off between the extension sizes on the two sides. We compare our result with the two-sided extendibility problem of isotropic states, where there is no such trade-off.</description>
  </item>

  <item>
    <title>Synergy Between Quantum Circuits and Tensor Networks: Short-cutting the Race to Practical Quantum Advantage</title>
    <link>http://arxiv.org/pdf/2208.13673</link>
    <author>Manuel S. Rudolph, Jacob Miller, Jing Chen, Atithi Acharya, Alejandro Perdomo-Ortiz</author>
    <pubDate>Aug 30 2022</pubDate>
    <description>While recent breakthroughs have proven the ability of noisy intermediate-scale quantum (NISQ) devices to achieve quantum advantage in classically-intractable sampling tasks, the use of these devices for solving more practically relevant computational problems remains a challenge. Proposals for attaining practical quantum advantage typically involve parametrized quantum circuits (PQCs), whose parameters can be optimized to find solutions to diverse problems throughout quantum simulation and machine learning. However, training PQCs for real-world problems remains a significant practical challenge, largely due to the phenomenon of barren plateaus in the optimization landscapes of randomly-initialized quantum circuits. In this work, we introduce a scalable procedure for harnessing classical computing resources to determine task-specific initializations of PQCs, which we show significantly improves the trainability and performance of PQCs on a variety of problems. Given a specific optimization task, this method first utilizes tensor network (TN) simulations to identify a promising quantum state, which is then converted into gate parameters of a PQC by means of a high-performance decomposition procedure. We show that this task-specific initialization avoids barren plateaus, and effectively translates increases in classical resources to enhanced performance and speed in training quantum circuits. By demonstrating a means of boosting limited quantum resources using classical computers, our approach illustrates the promise of this synergy between quantum and quantum-inspired models in quantum computing, and opens up new avenues to harness the power of modern quantum hardware for realizing practical quantum advantage.</description>
  </item>

  <item>
    <title>Fundamental Limitation on the Detectability of Entanglement</title>
    <link>http://arxiv.org/pdf/2208.02518</link>
    <author>Pengyu Liu, Zhenhuan Liu, Shu Chen, Xiongfeng Ma</author>
    <pubDate>Aug 05 2022</pubDate>
    <description>Entanglement detection is essential in quantum information science and quantum many-body physics. It has been proved that entanglement exists almost surely for a random quantum state, while the realizations of effective entanglement criteria usually consume exponential resources, and efficient criteria often perform poorly without prior knowledge. This fact implies a fundamental limitation might exist in the detectability of entanglement. In this work, we formalize this limitation as a fundamental trade-off between the efficiency and effectiveness of entanglement criteria via a systematic method to theoretically evaluate the detection capability of entanglement criteria. For a system coupled to an environment, we prove that any entanglement criterion needs exponentially many observables to detect the entanglement effectively when restricted to single-copy operations. Otherwise, the detection capability of the criterion will decay double-exponentially. Furthermore, if multi-copy joint measurements are allowed, the effectiveness of entanglement detection can be exponentially improved, which implies a quantum advantage in entanglement detection problems.</description>
  </item>

  <item>
    <title>Resource theory of quantum scrambling</title>
    <link>http://arxiv.org/pdf/2208.10477</link>
    <author>Roy J. Garcia, Kaifeng Bu, Arthur Jaffe</author>
    <pubDate>Aug 23 2022</pubDate>
    <description>Quantum scrambling refers to the spread of local quantum information into the many degrees of freedom of a quantum system. In this work, we introduce a resource theory of scrambling which incorporates two mechanisms, "entanglement scrambling" and "magic scrambling". We introduce two resource monotones called the Pauli growth and the OTOC (out-of-time-ordered correlator) magic for these two mechanisms, respectively. Moreover, we show that OTOC fluctuations are bounded by the OTOC magic. This proves that small OTOC fluctuations are an indication of magic in Google's recent experiment (Science 374, 1479 (2021)). We also show that both resource monotones can be used to bound the decoding fidelity in the Hayden-Preskill protocol. These applications provide an operational interpretation of the resource monotones defined in this work.</description>
  </item>

  <item>
    <title>Techniques for combining fast local decoders with global decoders under circuit-level noise</title>
    <link>http://arxiv.org/pdf/2208.01178</link>
    <author>Christopher Chamberland, Luis Goncalves, Prasahnt Sivarajah, Eric Peterson, Sebastian Grimberg</author>
    <pubDate>Aug 03 2022</pubDate>
    <description>Implementing algorithms on a fault-tolerant quantum computer will require fast decoding throughput and latency times to prevent an exponential increase in buffer times between the applications of gates. In this work we begin by quantifying these requirements. We then introduce the construction of local neural network (NN) decoders using three-dimensional convolutions. These local decoders are adapted to circuit-level noise and can be applied to surface code volumes of arbitrary size. Their application removes errors arising from a certain number of faults, which serves to substantially reduce the syndrome density. Remaining errors can then be corrected by a global decoder, such as Blossom or Union Find, with their implementation significantly accelerated due to the reduced syndrome density. However, in the circuit-level setting, the corrections applied by the local decoder introduce many vertical pairs of highlighted vertices. To obtain a low syndrome density in the presence of vertical pairs, we consider a strategy of performing a syndrome collapse which removes many vertical pairs and reduces the size of the decoding graph used by the global decoder. We also consider a strategy of performing a vertical cleanup, which consists of removing all local vertical pairs prior to implementing the global decoder. Lastly, we estimate the cost of implementing our local decoders on Field Programmable Gate Arrays (FPGAs).</description>
  </item>

  <item>
    <title>On establishing learning separations between classical and quantum machine learning with classical data</title>
    <link>http://arxiv.org/pdf/2208.06339</link>
    <author>Casper Gyurik, Vedran Dunjko</author>
    <pubDate>Aug 15 2022</pubDate>
    <description>Despite years of effort, the quantum machine learning community has only been able to show quantum learning advantages for certain contrived cryptography-inspired datasets in the case of classical data. In this note, we discuss the challenges of finding learning problems that quantum learning algorithms can learn much faster than any classical learning algorithm, and we study how to identify such learning problems. Specifically, we reflect on the main concepts in computational learning theory pertaining to this question, and we discuss how subtle changes in definitions can mean conceptually significantly different tasks, which can either lead to a separation or no separation at all. Moreover, we study existing learning problems with a provable quantum speedup to distill sets of more general and sufficient conditions (i.e., ``checklists'') for a learning problem to exhibit a separation between classical and quantum learners. These checklists are intended to streamline one's approach to proving quantum speedups for learning problems, or to elucidate bottlenecks. Finally, to illustrate its application, we analyze examples of potential separations (i.e., when the learning problem is build from computational separations, or when the data comes from a quantum experiment) through the lens of our approach.</description>
  </item>

  <item>
    <title>Duality theory for Clifford tensor powers</title>
    <link>http://arxiv.org/pdf/2208.01688</link>
    <author>Felipe Montealegre-Mora, David Gross</author>
    <pubDate>Aug 04 2022</pubDate>
    <description>The representation theory of the Clifford group is playing an increasingly prominent role in quantum information theory, including in such diverse use cases as the construction of protocols for quantum system certification, quantum simulation, and quantum cryptography. In these applications, the tensor powers of the defining representation seem particularly important. The representation theory of these tensor powers is understood in two regimes. 1. For odd qudits in the case where the power t is not larger than the number of systems n: Here, a duality theory between the Clifford group and certain discrete orthogonal groups can be used to make fairly explicit statements about the occurring irreps (this theory is related to Howe duality and the eta-correspondence). 2. For qubits: Tensor powers up to t=4 have been analyzed on a case-by-case basis. In this paper, we provide a unified framework for the duality approach that also covers qubit systems. To this end, we translate the notion of rank of symplectic representations to representations of the qubit Clifford group, and generalize the eta correspondence between symplectic and orthogonal groups to a correspondence between the Clifford and certain orthogonal-stochastic groups. As a sample application, we provide a protocol to efficiently implement the complex conjugate of a black-box Clifford unitary evolution.</description>
  </item>

  <item>
    <title>Alternating Layered Variational Quantum Circuits Can Be Classically Optimized Efficiently Using Classical Shadows</title>
    <link>http://arxiv.org/pdf/2208.11623</link>
    <author>Afrad Basheer, Yuan Feng, Christopher Ferrie, Sanjiang Li</author>
    <pubDate>Aug 25 2022</pubDate>
    <description>Variational quantum algorithms (VQAs) are the quantum analog of classical neural networks (NNs). A VQA consists of a parameterized quantum circuit (PQC) which is composed of multiple layers of ansatzes (simpler PQCs, which are an analogy of NN layers) that differ only in selections of parameters. Previous work has identified the alternating layered ansatz as potentially a new standard ansatz in near-term quantum computing. Indeed, shallow alternating layered VQAs are easy to implement and have been shown to be both trainable and expressive. In this work, we introduce a training algorithm with an exponential reduction in training cost of such VQAs. Moreover, our algorithm uses classical shadows of quantum input data, and can hence be run on a classical computer with rigorous performance guarantees. We demonstrate 2--3 orders of magnitude improvement in the training cost using our algorithm for the example problems of finding state preparation circuits and the quantum autoencoder.</description>
  </item>

  <item>
    <title>Multidimensional Quantum Walks, with Application to $k$-Distinctness</title>
    <link>http://arxiv.org/pdf/2208.13492</link>
    <author>Stacey Jeffery, Sebastian Zur</author>
    <pubDate>Aug 30 2022</pubDate>
    <description>While the quantum query complexity of $k$-distinctness is known to be $O\left(n^{3/4-1/4(2^k-1)}\right)$ for any constant $k \geq 4$, the best previous upper bound on the time complexity was $\widetilde{O}\left(n^{1-1/k}\right)$. We give a new upper bound of $\widetilde{O}\left(n^{3/4-1/4(2^k-1)}\right)$ on the time complexity, matching the query complexity up to polylogarithmic factors. In order to achieve this upper bound, we give a new technique for designing quantum walk search algorithms, which is an extension of the electric network framework. We also show how to solve the welded trees problem in $O(n)$ queries and $O(n^2)$ time using this new technique, showing that the new quantum walk framework can achieve exponential speedups.</description>
  </item>

  <item>
    <title>Putting paradoxes to work: contextuality in measurement-based quantum computation</title>
    <link>http://arxiv.org/pdf/2208.06624</link>
    <author>Robert Raussendorf</author>
    <pubDate>Aug 16 2022</pubDate>
    <description>We describe a joint cohomological framework for measurement-based quantum computation (MBQC) and the corresponding contextuality proofs. The central object in this framework is an element in the second cohomology group of the chain complex describing a given MBQC. It contains the function computed, up to gauge equivalence, and at the same time is a contextuality witness. The present cohomological description only applies to temporally flat MBQCs, and we outline an approach for extending it to the temporally ordered case.</description>
  </item>

  <item>
    <title>Information-theoretic Hardness of Out-of-time-order Correlators</title>
    <link>http://arxiv.org/pdf/2208.02256</link>
    <author>Jordan Cotler, Thomas Schuster, Masoud Mohseni</author>
    <pubDate>Aug 05 2022</pubDate>
    <description>We establish that there are properties of quantum many-body dynamics which are efficiently learnable if we are given access to out-of-time-order correlators (OTOCs), but which require exponentially many operations in the system size if we can only measure time-ordered correlators. This implies that any experimental protocol which reconstructs OTOCs solely from time-ordered correlators must be, in certain cases, exponentially inefficient. Our proofs leverage and generalize recent techniques in quantum learning theory. Along the way, we elucidate a general definition of time-ordered versus out-of-time-order experimental measurement protocols, which can be considered as classes of adaptive quantum learning algorithms. Moreover, our results provide a theoretical foundation for novel applications of OTOCs in quantum simulations.</description>
  </item>

</channel>

</rss>
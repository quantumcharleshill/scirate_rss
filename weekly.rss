<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>Towards near-term quantum simulation of materials</title>
    <link>http://arxiv.org/pdf/2205.15256</link>
    <author>Laura Clinton, Toby Cubitt, Brian Flynn, Filippo Maria Gambetta, Joel Klassen, Ashley Montanaro, Stephen Piddock, Raul A. Santos, Evan Sheridan</author>
    <pubDate>May 31 2022</pubDate>
    <description>Simulation of materials is one of the most promising applications of quantum computers. On near-term hardware the crucial constraint on these simulations is circuit depth. Many quantum simulation algorithms rely on a layer of unitary evolutions generated by each term in a Hamiltonian. This appears in time-dynamics as a single Trotter step, and in variational quantum eigensolvers under the Hamiltonian variational ansatz as a single ansatz layer. We present a new quantum algorithm design for materials modelling where the depth of a layer is independent of the system size. This design takes advantage of the locality of materials in the Wannier basis and employs a tailored fermionic encoding that preserves locality. We analyse the circuit costs of this approach and present a compiler that transforms density functional theory data into quantum circuit instructions -- connecting the physics of the material to the simulation circuit. The compiler automatically optimises circuits at multiple levels, from the base gate level to optimisations derived from the physics of the specific target material. We present numerical results for materials spanning a wide structural and technological range. Our results demonstrate a reduction of many orders of magnitude in circuit depth over standard prior methods that do not consider the structure of the Hamiltonian. For example our results improve resource requirements for Strontium Vanadate (SrVO$_3$) from 864 to 180 qubits for a $3\times3\times3$ lattice, and the circuit depth of a single Trotter or variational layer from $7.5\times 10^8$ to depth $730$. Although this is still beyond current hardware, our results show that materials simulation may be feasible on quantum computers without necessarily requiring scalable, fault-tolerant quantum computers, provided quantum algorithm design incorporates understanding of the materials and applications.</description>
  </item>

  <item>
    <title>Perturbation Theory and the Sum of Squares</title>
    <link>http://arxiv.org/pdf/2205.12325</link>
    <author>Matthew B. Hastings</author>
    <pubDate>May 26 2022</pubDate>
    <description>The sum-of-squares (SoS) hierarchy is a powerful technique based on semi-definite programming that can be used for both classical and quantum optimization problems. This hierarchy goes under several names; in particular, in quantum chemistry it is called the reduced density matrix (RDM) method. We consider the ability of this hierarchy to reproduce weak coupling perturbation theory for three different kinds of systems: spin (or qubit) systems, bosonic systems (the anharmonic oscillator), and fermionic systems with quartic interactions. For such fermionic systems, we show that degree-$4$ SoS (called $2$-RDM in quantum chemsitry) does not reproduce second order perturbation theory but degree-$6$ SoS ($3$-RDM) does (and we conjecture that it reproduces third order perturbation theory). Indeed, we identify a fragment of degree-$6$ SoS which can do this, which may be useful for practical quantum chemical calculations as it may be possible to implement this fragment with less cost than the full degree-$6$ SoS. Remarkably, this fragment is very similar to one studied by Hastings and O'Donnell for the Sachdev-Ye-Kitaev (SYK) model.</description>
  </item>

  <item>
    <title>The battle of clean and dirty qubits in the era of partial error correction</title>
    <link>http://arxiv.org/pdf/2205.13454</link>
    <author>Daniel Bultrini, Samson Wang, Piotr Czarnik, Max Hunter Gordon, M. Cerezo, Patrick J. Coles, Lukasz Cincio</author>
    <pubDate>May 27 2022</pubDate>
    <description>When error correction becomes possible it will be necessary to dedicate a large number of physical qubits to each logical qubit. Error correction allows for deeper circuits to be run, but each additional physical qubit can potentially contribute an exponential increase in computational space, so there is a trade-off between using qubits for error correction or using them as noisy qubits. In this work we look at the effects of using noisy qubits in conjunction with noiseless qubits (an idealized model for error-corrected qubits), which we call the "clean and dirty" setup. We employ analytical models and numerical simulations to characterize this setup. Numerically we show the appearance of Noise-Induced Barren Plateaus (NIBPs), i.e., an exponential concentration of observables caused by noise, in an Ising model Hamiltonian variational ansatz circuit. We observe this even if only a single qubit is noisy and given a deep enough circuit, suggesting that NIBPs cannot be fully overcome simply by error-correcting a subset of the qubits. On the positive side, we find that for every noiseless qubit in the circuit, there is an exponential suppression in concentration of gradient observables, showing the benefit of partial error correction. Finally, our analytical models corroborate these findings by showing that observables concentrate with a scaling in the exponent related to the ratio of dirty-to-total qubits.</description>
  </item>

  <item>
    <title>On the Role of Quantum Coherence in Thermodynamics</title>
    <link>http://arxiv.org/pdf/2205.13612</link>
    <author>Gilad Gour</author>
    <pubDate>May 30 2022</pubDate>
    <description>We find necessary and sufficient conditions to determine the inter-convertibility of quantum systems under time-translation covariant evolution, and use it to solve several problems in quantum thermodynamics both in the single-shot and asymptotic regimes. It is well known that the resource theory of quantum athermality is not reversible, but in PRL 111, 250404 (2013) it was claimed that the theory becomes reversible "provided a sublinear amount of coherent superposition over energy levels is available". Here we show that the original proof of this claim is incorrect, and then provide a completely new rigorous proof for the pure-state case. A proof of the same claim for the mixed-state case is still lacking.</description>
  </item>

  <item>
    <title>Measurement incompatibility vs. Bell non-locality: an approach via tensor norms</title>
    <link>http://arxiv.org/pdf/2205.12668</link>
    <author>Faedi Loulidi, Ion Nechita</author>
    <pubDate>May 26 2022</pubDate>
    <description>Measurement incompatibility and quantum non-locality are two key features of quantum theory. Violations of Bell inequalities require quantum entanglement and incompatibility of the measurements used by the two parties involved in the protocol. We analyze the converse question: for which Bell inequalities is the incompatibility of measurements enough to ensure a quantum violation? We relate the two questions by comparing two tensor norms on the space of dichotomic quantum measurements: one characterizing measurement compatibility and the second one characterizing violations of a given Bell inequality. We provide sufficient conditions for the equivalence of the two notions in terms of the matrix describing the correlation Bell inequality. We show that the CHSH inequality and its variants are the only ones satisfying it.</description>
  </item>

  <item>
    <title>Mitigating barren plateaus of variational quantum eigensolvers</title>
    <link>http://arxiv.org/pdf/2205.13539</link>
    <author>Xia Liu, Geng Liu, Jiaxin Huang, Xin Wang</author>
    <pubDate>May 27 2022</pubDate>
    <description>Variational quantum algorithms (VQAs) are expected to establish valuable applications on near-term quantum computers. However, recent works have pointed out that the performance of VQAs greatly relies on the capability of the ansatzes and is seriously limited by optimization issues such as barren plateaus (i.e., vanishing gradients). This work proposes the state efficient ansatz (SEA) for accurate quantum dynamics simulations with improved trainability. First, we show that SEA can generate an arbitrary pure state with much fewer parameters than a universal ansatz, making it efficient for tasks like ground state estimation. It also has the flexibility in adjusting the entanglement of the prepared state, which could be applied to further improve the efficiency of simulating weak entanglement. Second, we show that SEA is not a unitary 2-design even if it has universal wavefunction expressibility and thus has great potential to improve the trainability by avoiding the zone of barren plateaus. We further investigate a plethora of examples in ground state estimation and notably obtain significant improvements in the variances of derivatives and the overall optimization behaviors. This result indicates that SEA can mitigate barren plateaus by sacrificing the redundant expressibility for the target problem.</description>
  </item>

  <item>
    <title>Simulation Complexity of Many-Body Localized Systems</title>
    <link>http://arxiv.org/pdf/2205.12967</link>
    <author>Adam Ehrenberg, Abhinav Deshpande, Christopher L. Baldwin, Dmitry A. Abanin, Alexey V. Gorshkov</author>
    <pubDate>May 27 2022</pubDate>
    <description>We use complexity theory to rigorously investigate the difficulty of classically simulating evolution under many-body localized (MBL) Hamiltonians. Using the defining feature that MBL systems have a complete set of quasilocal integrals of motion (LIOMs), we demonstrate a transition in the classical complexity of simulating such systems as a function of evolution time. On one side, we construct a quasipolynomial-time tensor-network-inspired algorithm for strong simulation of 1D MBL systems (i.e., calculating the expectation value of arbitrary products of local observables) evolved for any time polynomial in the system size. On the other side, we prove that even weak simulation, i.e. sampling, becomes formally hard after an exponentially long evolution time, assuming widely believed conjectures in complexity theory. Finally, using the consequences of our classical simulation results, we also show that the quantum circuit complexity for MBL systems is sublinear in evolution time. This result is a counterpart to a recent proof that the complexity of random quantum circuits grows linearly in time.</description>
  </item>

  <item>
    <title>A Convergence Theory for Over-parameterized Variational Quantum Eigensolvers</title>
    <link>http://arxiv.org/pdf/2205.12481</link>
    <author>Xuchen You, Shouvanik Chakrabarti, Xiaodi Wu</author>
    <pubDate>May 26 2022</pubDate>
    <description>The Variational Quantum Eigensolver (VQE) is a promising candidate for quantum applications on near-term Noisy Intermediate-Scale Quantum (NISQ) computers. Despite a lot of empirical studies and recent progress in theoretical understanding of VQE's optimization landscape, the convergence for optimizing VQE is far less understood. We provide the first rigorous analysis of the convergence of VQEs in the over-parameterization regime. By connecting the training dynamics with the Riemannian Gradient Flow on the unit-sphere, we establish a threshold on the sufficient number of parameters for efficient convergence, which depends polynomially on the system dimension and the spectral ratio, a property of the problem Hamiltonian, and could be resilient to gradient noise to some extent. We further illustrate that this overparameterization threshold could be vastly reduced for specific VQE instances by establishing an ansatz-dependent threshold paralleling our main result. We showcase that our ansatz-dependent threshold could serve as a proxy of the trainability of different VQE ansatzes without performing empirical experiments, which hence leads to a principled way of evaluating ansatz design. Finally, we conclude with a comprehensive empirical study that supports our theoretical findings.</description>
  </item>

  <item>
    <title>Only Classical Parametrised States have Optimal Measurements</title>
    <link>http://arxiv.org/pdf/2205.14142</link>
    <author>Wilfred Salmon, Sergii Strelchuk, David Arvidsson-Shukur</author>
    <pubDate>May 30 2022</pubDate>
    <description>Measurements of quantum states form a key component in quantum-information processing. It is therefore an important task to compare measurements and furthermore decide if a measurement strategy is optimal. We introduce a framework that allows one to conclusively establish if a measurement is optimal. Our method relies on the fundamental property of expected errors of estimators, known as risk, and it does not involve optimisation over entropic quantities. The framework applies to finite sample sizes and lack of prior knowledge, as well as to the asymptotic and Bayesian settings. We prove a no-go theorem that shows that only classical states admit optimal measurements. We further consider the less restrictive notion of an approximately optimal measurement and give sufficient conditions for such measurements to exist. Finally, we generalise the notion of when an estimator is inadmissible (i.e. strictly worse than an alternative), and provide two sufficient conditions for a measurement to be inadmissible.</description>
  </item>

  <item>
    <title>Characterizing and mitigating coherent errors in a trapped ion quantum processor using hidden inverses</title>
    <link>http://arxiv.org/pdf/2205.14225</link>
    <author>Swarnadeep Majumder, Christopher G. Yale, Titus D. Morris, Daniel S. Lobser, Ashlyn D. Burch, Matthew N. H. Chow, Melissa C. Revelle, Susan M. Clark, Raphael C. Pooser</author>
    <pubDate>May 31 2022</pubDate>
    <description>Quantum computing testbeds exhibit high-fidelity quantum control over small collections of qubits, enabling performance of precise, repeatable operations followed by measurements. Currently, these noisy intermediate-scale devices can support a sufficient number of sequential operations prior to decoherence such that small algorithms can be performed reliably. While the results of these algorithms are imperfect, these imperfections can help bootstrap quantum computer testbed development. Demonstrations of these small algorithms over the past few years, coupled with the idea that imperfect algorithm performance can be caused by several dominant noise sources in the quantum processor, which can be measured and calibrated during algorithm execution or in post-processing, has led to the use of noise mitigation to improve typical computational results. Conversely, small benchmark algorithms coupled with noise mitigation can help diagnose the nature of the noise, whether systematic or purely random. Here, we outline the use of coherent noise mitigation techniques as a characterization tool in trapped-ion testbeds. We perform model-fitting of the noisy data to determine the noise source based on realistic physics focused noise models and demonstrate that systematic noise amplification coupled with error mitigation schemes provides useful data for noise model deduction. Further, in order to connect lower level noise model details with application specific performance of near term algorithms, we experimentally construct the loss landscape of a variational algorithm under various injected noise sources coupled with error mitigation techniques. This type of connection enables application-aware hardware codesign, in which the most important noise sources in specific applications, like quantum chemistry, become foci of improvement in subsequent hardware generations.</description>
  </item>

</channel>

</rss>
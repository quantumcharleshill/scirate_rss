<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>Improved Hardness Results for the Guided Local Hamiltonian Problem</title>
    <link>http://arxiv.org/pdf/2207.10250</link>
    <author>Sevag Gharibian, Ryu Hayakawa, François Le Gall, Tomoyuki Morimae</author>
    <pubDate>Jul 22 2022</pubDate>
    <description>Estimating the ground state energy of a local Hamiltonian is a central problem in quantum chemistry. In order to further investigate its complexity and the potential of quantum algorithms for quantum chemistry, Gharibian and Le Gall (STOC 2022) recently introduced the guided local Hamiltonian problem (GLH), which is a variant of the local Hamiltonian problem where an approximation of a ground state is given as an additional input. Gharibian and Le Gall showed quantum advantage (more precisely, BQP-completeness) for GLH with $6$-local Hamiltonians when the guiding vector has overlap (inverse-polynomially) close to 1/2 with a ground state. In this paper, we optimally improve both the locality and the overlap parameters: we show that this quantum advantage (BQP-completeness) persists even with 2-local Hamiltonians, and even when the guiding vector has overlap (inverse-polynomially) close to 1 with a ground state. Moreover, we show that the quantum advantage also holds for 2-local physically motivated Hamiltonians on a 2D square lattice. This makes a further step towards establishing practical quantum advantage in quantum chemistry.</description>
  </item>

  <item>
    <title>Complexity of the Guided Local Hamiltonian Problem: Improved Parameters and Extension to Excited States</title>
    <link>http://arxiv.org/pdf/2207.10097</link>
    <author>Chris Cade, Marten Folkertsma, Jordi Weggemans</author>
    <pubDate>Jul 22 2022</pubDate>
    <description>Recently it was shown that the so-called guided local Hamiltonian problem -- estimating the smallest eigenvalue of a $k$-local Hamiltonian when provided with a description of a quantum state ('guiding state') that is guaranteed to have substantial overlap with the true groundstate -- is BQP-complete for $k \geq 6$ when the required precision is inverse polynomial in the system size $n$, and remains hard even when the overlap of the guiding state with the groundstate is close to a constant $\left(\frac12 - \Omega\left(\frac{1}{\mathop{poly}(n)}\right)\right)$. We improve upon this result in three ways: by showing that it remains BQP-complete when i) the Hamiltonian is 2-local, ii) the overlap between the guiding state and target eigenstate is as large as $1 - \Omega\left(\frac{1}{\mathop{poly}(n)}\right)$, and iii) when one is interested in estimating energies of excited states, rather than just the groundstate. Interestingly, iii) is only made possible by first showing that ii) holds.</description>
  </item>

  <item>
    <title>Emergent Quantum Mechanics at the Boundary of a Local Classical Lattice Model</title>
    <link>http://arxiv.org/pdf/2207.09465</link>
    <author>Kevin Slagle, John Preskill</author>
    <pubDate>Jul 21 2022</pubDate>
    <description>We formulate a conceptually new model in which quantum mechanics emerges from classical mechanics. Given a local Hamiltonian $H$ acting on $n$ qubits, we define a local classical model with an additional spatial dimension whose boundary dynamics is described by Schrodinger's equation and $H$. The bulk consists of a lattice of classical bits that propagate towards the boundary through a circuit of stochastic matrices. The bits reaching the boundary are governed by a probability distribution whose deviation from the uniform distribution can be interpreted as the quantum-mechanical wavefunction. Bell nonlocality is achieved because information can move through the bulk much faster than the boundary speed of light. We analytically estimate how much the model deviates from quantum mechanics, and we validate these estimates using computer simulations.</description>
  </item>

  <item>
    <title>Time-Efficient Constant-Space-Overhead Fault-Tolerant Quantum Computation</title>
    <link>http://arxiv.org/pdf/2207.08826</link>
    <author>Hayata Yamasaki, Masato Koashi</author>
    <pubDate>Jul 20 2022</pubDate>
    <description>Scalable realization of quantum computation to attain substantial speedups over classical computation requires fault tolerance. Conventionally, fault-tolerant quantum computation (FTQC) demands excessive space overhead of physical qubits per logical qubit. A more recent protocol to achieve constant-space-overhead FTQC using quantum low-density parity-check (LDPC) codes thus attracts considerable attention but suffers from another drawback: it incurs polynomially long time overhead. We construct an alternative avenue of FTQC to achieve constant space overhead and only quasi-polylogarithmic time overhead simultaneously via techniques for using concatenations of different quantum Hamming codes rather than quantum LDPC codes. Our protocol achieves FTQC even if a decoder has nonzero runtime, unlike the existing constant-space-overhead protocol. These results establish a foundation for realizing FTQC within feasibly bounded space overhead yet negligibly tiny slowdown.</description>
  </item>

  <item>
    <title>The Gauge Theory of Measurement-Based Quantum Computation</title>
    <link>http://arxiv.org/pdf/2207.10098</link>
    <author>Gabriel Wong, Robert Raussendorf, Bartlomiej Czech</author>
    <pubDate>Jul 22 2022</pubDate>
    <description>Measurement-Based Quantum Computation (MBQC) is a model of quantum computation, which uses local measurements instead of unitary gates. Here we explain that the MBQC procedure has a fundamental basis in an underlying gauge theory. This perspective provides a theoretical foundation for global aspects of MBQC. The gauge symmetry reflects the freedom of formulating the same MBQC computation in different local reference frames. The main identifications between MBQC and gauge theory concepts are: (i) the computational output of MBQC is a holonomy of the gauge field, (ii) the adaption of measurement basis that remedies the inherent randomness of quantum measurements is effected by gauge transformations. The gauge theory of MBQC also plays a role in characterizing the entanglement structure of symmetry-protected topologically (SPT) ordered states, which are resources for MBQC. Our framework situates MBQC in a broader context of condensed matter and high energy theory.</description>
  </item>

  <item>
    <title>Preparing Many Copies of a Quantum State in the Black-Box Model</title>
    <link>http://arxiv.org/pdf/2207.11014</link>
    <author>Yassine Hamoudi</author>
    <pubDate>Jul 25 2022</pubDate>
    <description>We describe a simple quantum algorithm for preparing $K$ copies of an $N$-dimensional quantum state whose amplitudes are given by a quantum oracle. Our result extends a previous work of Grover, who showed how to prepare one copy in time $O(\sqrt{N})$. In comparison with the naive $O(K\sqrt{N})$ solution obtained by repeating this procedure~$K$ times, our algorithm achieves the optimal running time of $\theta(\sqrt{KN})$. Our technique uses a refinement of the quantum rejection sampling method employed by Grover. As a direct application, we obtain a similar speed-up for obtaining $K$ independent samples from a distribution whose probability vector is given by a quantum oracle.</description>
  </item>

  <item>
    <title>Classical models are a better explanation of the Jiuzhang Gaussian Boson Samplers than their targeted squeezed light models</title>
    <link>http://arxiv.org/pdf/2207.10058</link>
    <author>Javier Martínez-Cifuentes, K. M. Fonseca-Romero, Nicolás Quesada</author>
    <pubDate>Jul 21 2022</pubDate>
    <description>Recently, Zhong et al. [Science 370, 1460 (2020), Phys. Rev. Lett. 127, 180502 (2021)] performed landmark Gaussian boson sampling experiments with up to 144 modes using threshold detectors. The authors claim to have achieved quantum computational advantage with the implementation of these experiments, named Jiuzhang 1.0 and Jiuzhang 2.0. Their experimental results are validated against several classical hypotheses and adversaries using tests such as the comparison of statistical correlations between modes, Bayesian hypothesis testing and the Heavy Output Generation test. In this work we propose an alternative classical hypothesis for the validation of these experiments. We use the probability distribution of mixtures of coherent states sent into a lossy interferometer; these input mixed states, which we term squashed states, have vacuum fluctuations in one quadrature and excess fluctuations in the other. We find that for configurations in the large photon number density regime, the comparison of statistical correlations does not tell apart the ground truth of the experiment (namely, the probability distribution of two-mode squeezed states sent into a lossy interferometer) from our alternative hypothesis. Moreover, the Bayesian test indicates that our alternative hypothesis is a more likely explanation of the experimental data than the ground truth. Our results indicate that a classical explanation of the experiments of Zhong et al., lacking any quantum features, has not been ruled out.</description>
  </item>

  <item>
    <title>Achievable error exponents of data compression with quantum side information and communication over symmetric classical-quantum channels</title>
    <link>http://arxiv.org/pdf/2207.08899</link>
    <author>Joseph M. Renes</author>
    <pubDate>Jul 20 2022</pubDate>
    <description>A fundamental quantity of interest in Shannon theory, classical or quantum, is the optimal error exponent of a given channel W and rate R: the constant E(W,R) which governs the exponential decay of decoding error when using ever larger codes of fixed rate R to communicate over ever more (memoryless) instances of a given channel W. Here I show that a bound by Hayashi [CMP 333, 335 (2015)] for an analogous quantity in privacy amplification implies a lower bound on the error exponent of communication over symmetric classical-quantum channels. The resulting bound matches Dalai's [IEEE TIT 59, 8027 (2013)] sphere-packing upper bound for rates above a critical value, and reproduces the well-known classical result for symmetric channels. The argument proceeds by first relating the error exponent of privacy amplification to that of compression of classical information with quantum side information, which gives a lower bound that matches the sphere-packing upper bound of Cheng et al. [IEEE TIT 67, 902 (2021)]. In turn, the polynomial prefactors to the sphere-packing bound found by Cheng et al. may be translated to the privacy amplification problem, sharpening a recent result by Li, Yao, and Hayashi [arXiv:2111.01075 [quant-ph]], at least for linear randomness extractors.</description>
  </item>

  <item>
    <title>A Faster Quantum Algorithm for Semidefinite Programming via Robust IPM Framework</title>
    <link>http://arxiv.org/pdf/2207.11154</link>
    <author>Baihe Huang, Shunhua Jiang, Zhao Song, Runzhou Tao, Ruizhe Zhang</author>
    <pubDate>Jul 25 2022</pubDate>
    <description>This paper studies a fundamental problem in convex optimization, which is to solve semidefinite programming (SDP) with high accuracy. This paper follows from existing robust SDP-based interior point method analysis due to [Huang, Jiang, Song, Tao and Zhang, FOCS 2022]. While, the previous work only provides an efficient implementation in the classical setting. This work provides a novel quantum implementation. We give a quantum second-order algorithm with high-accuracy in both the optimality and the feasibility of its output, and its running time depending on $\log(1/\epsilon)$ on well-conditioned instances. Due to the limitation of quantum itself or first-order method, all the existing quantum SDP solvers either have polynomial error dependence or low-accuracy in the feasibility.</description>
  </item>

  <item>
    <title>Matching Triangles and Triangle Collection: Hardness based on a Weak Quantum Conjecture</title>
    <link>http://arxiv.org/pdf/2207.11068</link>
    <author>Andris Ambainis, Harry Buhrman, Koen Leijnse, Subhasree Patro, Florian Speelman</author>
    <pubDate>Jul 25 2022</pubDate>
    <description>Classically, for many computational problems one can conclude time lower bounds conditioned on the hardness of one or more of key problems: k-SAT, 3SUM and APSP. More recently, similar results have been derived in the quantum setting conditioned on the hardness of k-SAT and 3SUM. This is done using fine-grained reductions, where the approach is to (1) select a key problem $X$ that, for some function $T$, is conjectured to not be solvable by any $O(T(n)^{1-\epsilon})$ time algorithm for any constant $\epsilon > 0$ (in a fixed model of computation), and (2) reduce $X$ in a fine-grained way to these computational problems, thus giving (mostly) tight conditional time lower bounds for them. Interestingly, for Delta-Matching Triangles and Triangle Collection, classical hardness results have been derived conditioned on hardness of all three mentioned key problems. More precisely, it is proven that an $n^{3-\epsilon}$ time classical algorithm for either of these two graph problems would imply faster classical algorithms for k-SAT, 3SUM and APSP, which makes Delta-Matching Triangles and Triangle Collection worthwhile to study. In this paper, we show that an $n^{1.5-\epsilon}$ time quantum algorithm for either of these two graph problems would imply faster quantum algorithms for k-SAT, 3SUM, and APSP. We first formulate a quantum hardness conjecture for APSP and then present quantum reductions from k-SAT, 3SUM, and APSP to Delta-Matching Triangles and Triangle Collection. Additionally, based on the quantum APSP conjecture, we are also able to prove quantum lower bounds for a matrix problem and many graph problems. The matching upper bounds follow trivially for most of them, except for Delta-Matching Triangles and Triangle Collection for which we present quantum algorithms that require careful use of data structures and Ambainis' variable time search.</description>
  </item>

</channel>

</rss>
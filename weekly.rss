<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>Is quantum advantage the right goal for quantum machine learning?</title>
    <link>http://arxiv.org/pdf/2203.01340</link>
    <author>Maria Schuld, Nathan Killoran</author>
    <pubDate>Mar 04 2022</pubDate>
    <description>Machine learning is frequently listed among the most promising applications for quantum computing. This is in fact a curious choice: Today's machine learning algorithms are notoriously powerful in practice, but remain theoretically difficult to study. Quantum computing, in contrast, does not offer practical benchmarks on realistic scales, and theory is the main tool we have to judge whether it could become relevant for a problem. In this perspective we explain why it is so difficult to say something about the practical power of quantum computers for machine learning with the tools we are currently using. We argue that these challenges call for a critical debate on whether quantum advantage and the narrative of "beating" classical machine learning should continue to dominate the literature the way it does, and provide a few examples for alternative research questions.</description>
  </item>

  <item>
    <title>All quantum measurements are asymptotically equivalent</title>
    <link>http://arxiv.org/pdf/2203.02593</link>
    <author>Noah Linden, Paul Skrzypczyk</author>
    <pubDate>Mar 08 2022</pubDate>
    <description>We consider the problem of reproducing one quantum measurement given the ability to perform another. In particular, given the availability of a -- possibly imperfect -- quantum measurement which can be performed multiple times, we study to what extent it can reproduce the measurement statistics and post-measurement state of a second target measurement, in the most general setting where both the available and target measurements are arbitrary generalised quantum measurements. We show that this general problem in fact reduces to the ability to reproduce the statistics of von Neumann measurements, and that in the asymptotic limit of infinitely many uses of the available measurement, a simple protocol based upon `classical cloning' is able to perfectly achieve this task. This shows that asymptotically all (non-trivial) quantum measurements are equivalent. We also study optimal protocols for a fixed number of uses of the available measurement, and show that better protocols than classical cloning can be found in general. Our protocols show that the average error in reproducing a target measurement drops off exponentially fast, and that one can, for example, rapidly improve imperfect measurements by performing them a small number of times. This includes, but is not limited to, improving both noisy and lossy quantum measurements. Finally, we show that in a setting where we perform multiple measurements in parallel, we can moreover achieve finite-rate measurement reproduction, by using block-coding techniques from classical information theory.</description>
  </item>

  <item>
    <title>Good quantum LDPC codes with linear time decoder from lossless expanders</title>
    <link>http://arxiv.org/pdf/2203.03581</link>
    <author>Ting-Chun Lin, Min-Hsiu Hsieh</author>
    <pubDate>Mar 08 2022</pubDate>
    <description>Quantum low-density parity-check (qLDPC) codes are quantum stabilizer codes where each stabilizer acts on a constant number of qubits and each qubit is acted on by a constant number of stabilizers. We study qLDPC codes constructed from balanced products and lossless expanders. We found that assuming the existence of 2-sided lossless expander graphs with free group action, the resulting qLDPC codes have constant rate, linear distance, and linear time decoders.</description>
  </item>

  <item>
    <title>Quantum circuit compilation and hybrid computation using Pauli-based computation</title>
    <link>http://arxiv.org/pdf/2203.01789</link>
    <author>F.C.R. Peres, Ernesto F. Galvão</author>
    <pubDate>Mar 04 2022</pubDate>
    <description>Pauli-based computation (PBC) is driven by a sequence of adaptively chosen, non-destructive measurements of Pauli observables. Any quantum circuit written in terms of the Clifford+$T$ gate set and having $t$ $T$ gates can be compiled into a PBC on $t$ qubits. Here we propose practical ways of implementing PBC as adaptive quantum circuits, and provide code to do the required classical side-processing. Our first scheme reduces the number of quantum gates to $O(t^2)$ (from a previous $O(t^3 / \log t)$ scaling) at the cost of one extra auxiliary qubit, with a possible reduction of the depth to $O(t \log t$), at the cost of $t$ additional auxiliary qubits (second scheme). We compile examples of random and hidden-shift quantum circuits into adaptive PBC circuits. We also simulate hybrid quantum computation, where a classical computer effectively extends the working memory of a small quantum computer by $k$ virtual qubits, at a cost exponential in $k$. Our results demonstrate the practical advantage of PBC techniques for circuit compilation and hybrid computation.</description>
  </item>

  <item>
    <title>Quantum algorithms for estimating quantum entropies</title>
    <link>http://arxiv.org/pdf/2203.02386</link>
    <author>Youle Wang, Benchi Zhao, Xin Wang</author>
    <pubDate>Mar 07 2022</pubDate>
    <description>The von Neumann and quantum Rényi entropies characterize fundamental properties of quantum systems and lead to theoretical and practical applications in many fields. Quantum algorithms for estimating quantum entropies, using a quantum query model that prepares the purification of the input state, have been established in the literature. However, constructing such a model is almost as hard as state tomography. In this paper, we propose quantum algorithms to estimate the von Neumann and quantum $\alpha$-Rényi entropies of an $n$-qubit quantum state $\rho$ using independent copies of the input state. We also show how to efficiently construct the quantum circuits for quantum entropy estimation using primitive single/two-qubit gates. We prove that the number of required copies scales polynomially in $1/\epsilon$ and $1/\Lambda$, where $\epsilon$ denotes the additive precision and $\Lambda$ denotes the lower bound on all non-zero eigenvalues. Notably, our method outperforms previous methods in the aspect of practicality since it does not require any quantum query oracles, which are usually necessary for previous methods. Furthermore, we conduct experiments to show the efficacy of our algorithms to single-qubit states and study the noise robustness. We also discuss the applications to some quantum states of practical interest as well as some meaningful tasks such as quantum Gibbs state preparation and entanglement estimation.</description>
  </item>

  <item>
    <title>Improved Quantum Query Upper Bounds Based on Classical Decision Trees</title>
    <link>http://arxiv.org/pdf/2203.02968</link>
    <author>Arjan Cornelissen, Nikhil S. Mande, Subhasree Patro</author>
    <pubDate>Mar 08 2022</pubDate>
    <description>Given a classical query algorithm as a decision tree, when does there exist a quantum query algorithm with a speed-up over the classical one? We provide a general construction based on the structure of the underlying decision tree, and prove that this can give us an up-to-quadratic quantum speed-up. In particular, we obtain a bounded-error quantum query algorithm of cost $O(\sqrt{s})$ to compute a Boolean function (more generally, a relation) that can be computed by a classical (even randomized) decision tree of size $s$. Lin and Lin [ToC'16] and Beigi and Taghavi [Quantum'20] showed results of a similar flavor, and gave upper bounds in terms of a quantity which we call the "guessing complexity" of a decision tree. We identify that the guessing complexity of a decision tree equals its rank, a notion introduced by Ehrenfeucht and Haussler [Inf. Comp.'89] in the context of learning theory. This answers a question posed by Lin and Lin, who asked whether the guessing complexity of a decision tree is related to any complexity-theoretic measure. We also show a polynomial separation between rank and randomized rank for the complete binary AND-OR tree. Beigi and Taghavi constructed span programs and dual adversary solutions for Boolean functions given classical decision trees computing them and an assignment of non-negative weights to its edges. We explore the effect of changing these weights on the resulting span program complexity and objective value of the dual adversary bound, and capture the best possible weighting scheme by an optimization program. We exhibit a solution to this program and argue its optimality from first principles. We also exhibit decision trees for which our bounds are asymptotically stronger than those of Lin and Lin, and Beigi and Taghavi. This answers a question of Beigi and Taghavi, who asked whether different weighting schemes could yield better upper bounds.</description>
  </item>

  <item>
    <title>Semidefinite programming lower bounds on the squashed entanglement</title>
    <link>http://arxiv.org/pdf/2203.03394</link>
    <author>Hamza Fawzi, Omar Fawzi</author>
    <pubDate>Mar 08 2022</pubDate>
    <description>The squashed entanglement is a widely used entanglement measure that has many desirable properties. However, as it is based on an optimization over extensions of arbitrary dimension, one drawback of this measure is the lack of good algorithms to compute it. Here, we introduce a hierarchy of semidefinite programming lower bounds on the squashed entanglement.</description>
  </item>

  <item>
    <title>Quantum Proofs of Deletion for Learning with Errors</title>
    <link>http://arxiv.org/pdf/2203.01610</link>
    <author>Alexander Poremba</author>
    <pubDate>Mar 04 2022</pubDate>
    <description>Quantum information has the property that measurement is an inherently destructive process. This feature is most apparent in the principle of complementarity, which states that mutually incompatible observables cannot be measured at the same time. Recent work by Broadbent and Islam (TCC 2020) builds on this aspect of quantum mechanics to realize a cryptographic notion called certified deletion. While this remarkable notion enables a classical verifier to be convinced that a (private-key) quantum ciphertext has been deleted by an untrusted party, it offers no additional layer of functionality. In this work, we augment the proof-of-deletion paradigm with fully homomorphic encryption (FHE). This results in a new and powerful cryptographic notion called fully homomorphic encryption with certified deletion -- an interactive protocol which enables an untrusted quantum server to compute on encrypted data and, if requested, to simultaneously prove data deletion to a client. Our main technical ingredient is an interactive protocol by which a quantum prover can convince a classical verifier that a sample from the Learning with Errors (LWE) distribution in the form of a quantum state was deleted. We introduce an encoding based on Gaussian coset states which is highly generic and suggests that essentially any LWE-based cryptographic primitive admits a classically-verifiable quantum proof of deletion. As an application of our protocol, we construct a Dual-Regev public-key encryption scheme with certified deletion, which we then extend towards a (leveled) FHE scheme of the same type. Our construction achieves indistinguishable ciphertexts in the semi-honest adversarial model, even if the secret key is later revealed after deletion has taken place.</description>
  </item>

  <item>
    <title>Quantum computation with cat qubits</title>
    <link>http://arxiv.org/pdf/2203.03222</link>
    <author>Jérémie Guillaud, Joachim Cohen, Mazyar Mirrahimi</author>
    <pubDate>Mar 08 2022</pubDate>
    <description>These are the lecture notes from the 2019 Les Houches Summer School on "Quantum Information Machines". After a brief introduction to quantum error correction and bosonic codes, we focus on the case of cat qubits stabilized by a nonlinear multi-photon driven dissipation process. We argue that such a system can be seen as a self-correcting qubit where bit-flip errors are robustly and exponentially suppressed. Next, we provide some experimental directions to engineer such a multi-photon driven dissipation process with superconducting circuits. Finally, we analyze various logical gates that can be implemented without re-introducing bit-flip errors. This set of bias-preserving gates pave the way towards a hardware-efficient and fault-tolerant quantum processor.</description>
  </item>

  <item>
    <title>Differential Privacy Amplification in Quantum and Quantum-inspired Algorithms</title>
    <link>http://arxiv.org/pdf/2203.03604</link>
    <author>Armando Angrisani, Mina Doosti, Elham Kashefi</author>
    <pubDate>Mar 08 2022</pubDate>
    <description>Differential privacy provides a theoretical framework for processing a dataset about $n$ users, in a way that the output reveals a minimal information about any single user. Such notion of privacy is usually ensured by noise-adding mechanisms and amplified by several processes, including subsampling, shuffling, iteration, mixing and diffusion. In this work, we provide privacy amplification bounds for quantum and quantum-inspired algorithms. In particular, we show for the first time, that algorithms running on quantum encoding of a classical dataset or the outcomes of quantum-inspired classical sampling, amplify differential privacy. Moreover, we prove that a quantum version of differential privacy is amplified by the composition of quantum channels, provided that they satisfy some mixing conditions.</description>
  </item>

</channel>

</rss>
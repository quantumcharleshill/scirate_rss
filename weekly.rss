<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>The Early Days of Quantum Computation</title>
    <link>http://arxiv.org/pdf/2208.09964</link>
    <author>Peter W. Shor</author>
    <pubDate>Aug 23 2022</pubDate>
    <description>I recount some of my memories of the early development of quantum computation, including the discovery of the factoring algorithm, of error correcting codes, and of fault tolerance.</description>
  </item>

  <item>
    <title>Classical shadows of fermions with particle number symmetry</title>
    <link>http://arxiv.org/pdf/2208.08964</link>
    <author>Guang Hao Low</author>
    <pubDate>Aug 19 2022</pubDate>
    <description>We consider classical shadows of fermion wavefunctions with $\eta$ particles occupying $n$ modes. We prove that of all $k$-reduced density matrices may be simultaneously estimated to an average variance of $\epsilon^{2}$ using at most $\binom{\eta}{k}\big(1-\frac{\eta-k}{n}\big)^{k}\frac{1+n}{1+n-k}/\epsilon^{2}$ measurements in random single-particle bases that conserve particle number, and provide an estimator that is computationally efficient. This is a super-exponential improvement over the $\binom{n}{k}\sqrt{\pi k}/\epsilon^{2}$ scaling of prior approaches as $n$ can be arbitrarily larger than $\eta$ in natural problems. Our method, in the worst-case of half-filling, still provides a factor of $4^{k}$ advantage in sample complexity, and also estimates all $\eta$-reduced density matrices, applicable to estimating overlaps with all single Slater determinants, with at most $\frac{4}{3}/\epsilon^{2}$ samples, which is additionally independent of $\eta$.</description>
  </item>

  <item>
    <title>Universal sample lower bounds for quantum error mitigation</title>
    <link>http://arxiv.org/pdf/2208.09178</link>
    <author>Ryuji Takagi, Hiroyasu Tajima, Mile Gu</author>
    <pubDate>Aug 22 2022</pubDate>
    <description>Although numerous quantum error-mitigation protocols have been proposed as means to suppress noise effects on intermediate-scale quantum devices, their general potential and limitations have still been elusive. In particular, to understand the ultimate feasibility of quantum error mitigation, it is crucial to characterize the fundamental sampling cost -- how many times an arbitrary mitigation protocol must run a noisy quantum device. Here, we establish universal lower bounds on the sampling cost for quantum error mitigation to achieve the desired accuracy with high probability. Our bounds apply to general mitigation protocols, including the ones involving nonlinear postprocessing. We further show that the number of samples required for a wide class of protocols to mitigate errors in layered circuits must grow exponentially with the circuit depth for various noise models, revealing the fundamental obstacles in showing useful applications of noisy near-term quantum devices.</description>
  </item>

  <item>
    <title>Universal cost bound of quantum error mitigation based on quantum estimation theory</title>
    <link>http://arxiv.org/pdf/2208.09385</link>
    <author>Kento Tsubouchi, Takahiro Sagawa, Nobuyuki Yoshioka</author>
    <pubDate>Aug 22 2022</pubDate>
    <description>Quantum error mitigation is an art to combat noise in quantum computers that are not fully fault tolerant. While a wide variety of techniques has been proposed with surging number of experimental applications, little is known concerning the unified understanding on their fundamental aspects. In this paper, we perform a theoretical analysis on the cost of quantum error mitigation using the quantum estimation theory. The applicability of quantum estimation theory is extended so that we can analyze the quantum Fisher information of layered noisy quantum circuits equipped with a wide range of quantum error mitigation methods. By showing that the quantum Fisher information decays exponentially with the circuit depth, we derive for a general class of Markovian noise that unbiased estimation of an observable encounters an exponential growth in the lower bound on the measurement cost, or more precisely the required number of copies of noisy quantum state. As two practical and illustrative examples, we discuss the case when the noise channel is solely the global or local depolarizing noise. We explicitly express the lower bound in terms of their noise rates, and further find that we can asymptotically saturate the bound by a simple mitigation technique for the global depolarizing noise. Our results not only reveal the physical limitations of quantum error mitigation, but may also provide a new criteria for performance evaluation of quantum error mitigation techniques.</description>
  </item>

  <item>
    <title>Resource theory of quantum scrambling</title>
    <link>http://arxiv.org/pdf/2208.10477</link>
    <author>Roy J. Garcia, Kaifeng Bu, Arthur Jaffe</author>
    <pubDate>Aug 23 2022</pubDate>
    <description>Quantum scrambling refers to the spread of local quantum information into the many degrees of freedom of a quantum system. In this work, we introduce a resource theory of scrambling which incorporates two mechanisms, "entanglement scrambling" and "magic scrambling". We introduce two resource monotones called the Pauli growth and the OTOC (out-of-time-ordered correlator) magic for these two mechanisms, respectively. Moreover, we show that OTOC fluctuations are bounded by the OTOC magic. This proves that small OTOC fluctuations are an indication of magic in Google's recent experiment (Science 374, 1479 (2021)). We also show that both resource monotones can be used to bound the decoding fidelity in the Hayden-Preskill protocol. These applications provide an operational interpretation of the resource monotones defined in this work.</description>
  </item>

  <item>
    <title>Exponential concentration and untrainability in quantum kernel methods</title>
    <link>http://arxiv.org/pdf/2208.11060</link>
    <author>Supanut Thanasilp, Samson Wang, M. Cerezo, Zoë Holmes</author>
    <pubDate>Aug 24 2022</pubDate>
    <description>Kernel methods in Quantum Machine Learning (QML) have recently gained significant attention as a potential candidate for achieving a quantum advantage in data analysis. Among other attractive properties, when training a kernel-based model one is guaranteed to find the optimal model's parameters due to the convexity of the training landscape. However, this is based on the assumption that the quantum kernel can be efficiently obtained from a quantum hardware. In this work we study the trainability of quantum kernels from the perspective of the resources needed to accurately estimate kernel values. We show that, under certain conditions, values of quantum kernels over different input data can be exponentially concentrated (in the number of qubits) towards some fixed value, leading to an exponential scaling of the number of measurements required for successful training. We identify four sources that can lead to concentration including: the expressibility of data embedding, global measurements, entanglement and noise. For each source, an associated concentration bound of quantum kernels is analytically derived. Lastly, we show that when dealing with classical data, training a parametrized data embedding with a kernel alignment method is also susceptible to exponential concentration. Our results are verified through numerical simulations for several QML tasks. Altogether, we provide guidelines indicating that certain features should be avoided to ensure the efficient evaluation and the trainability of quantum kernel methods.</description>
  </item>

  <item>
    <title>Long-distance transmon coupler with CZ gate fidelity above $99.8\%$</title>
    <link>http://arxiv.org/pdf/2208.09460</link>
    <author>Fabian Marxer, Antti Vepsäläinen, Shan W. Jolin, Jani Tuorila, Alessandro Landra, Caspar Ockeloen-Korppi, Wei Liu, Olli Ahonen, Adrian Auer, Lucien Belzane, Ville Bergholm, Chun Fai Chan, Kok Wai Chan, Tuukka Hiltunen, Juho Hotari, Eric Hyyppä, Joni Ikonen, David Janzso, Miikka Koistinen, Janne Kotilahti, et al (19)</author>
    <pubDate>Aug 22 2022</pubDate>
    <description>Tunable coupling of superconducting qubits has been widely studied due to its importance for isolated gate operations in scalable quantum processor architectures. Here, we demonstrate a tunable qubit-qubit coupler based on a floating transmon device which allows us to place qubits at least 2 mm apart from each other while maintaining over 50 MHz coupling between the coupler and the qubits. In the introduced tunable-coupler design, both the qubit-qubit and the qubit-coupler couplings are mediated by two waveguides instead of relying on direct capacitive couplings between the components, reducing the impact of the qubit-qubit distance on the couplings. This leaves space for each qubit to have an individual readout resonator and a Purcell filter needed for fast high-fidelity readout. In addition, the large qubit-qubit distance reduces unwanted non-nearest neighbor coupling and allows multiple control lines to cross over the structure with minimal crosstalk. Using the proposed flexible and scalable architecture, we demonstrate a controlled-$Z$ gate with $(99.81 \pm 0.02)\%$ fidelity.</description>
  </item>

  <item>
    <title>Efficient algorithms for quantum information bottleneck</title>
    <link>http://arxiv.org/pdf/2208.10342</link>
    <author>Masahito Hayashi, Yuxiang Yang</author>
    <pubDate>Aug 23 2022</pubDate>
    <description>The ability to extract relevant information is critical to learning. An ingenious approach as such is the information bottleneck, an optimisation problem whose solution corresponds to a faithful and memory-efficient representation of relevant information from a large system. The advent of the age of quantum computing calls for efficient methods that work on information regarding quantum systems. Here we address this by proposing a new and general algorithm for the quantum generalisation of information bottleneck. Our algorithm excels in the speed and the definiteness of convergence compared with prior results. It also works for a much broader range of problems, including the quantum extension of deterministic information bottleneck, an important variant of the original information bottleneck problem. Notably, we discover that a quantum system can achieve strictly better performance than a classical system of the same size regarding quantum information bottleneck, providing new vision on justifying the advantage of quantum machine learning.</description>
  </item>

  <item>
    <title>Have your QEC and Bandwidth too!: A lightweight cryogenic decoder for common / trivial errors, and efficient bandwidth + execution management otherwise</title>
    <link>http://arxiv.org/pdf/2208.08547</link>
    <author>Gokul Subramanian Ravi, Jonathan M. Baker, Arash Fayyazi, Sophia Fuhui Lin, Ali Javadi-Abhari, Massoud Pedram, Frederic T. Chong</author>
    <pubDate>Aug 19 2022</pubDate>
    <description>The overheads of classical decoding for quantum error correction grow rapidly with the number of logical qubits and their correction code distance. Decoding at room temperature is bottle-necked by refrigerator I/O bandwidth while cryogenic on-chip decoding is limited by area/power/thermal budget. To overcome these overheads, we are motivated by the observation that in the common case (over 90% of the time), error signatures are fairly trivial with high redundancy / sparsity, since the error correction codes are over-provisioned to be able to correct for uncommon worst-case complex scenarios (to ensure substantially low logical error rates). If suitably exploited, these trivial signatures can be decoded and corrected with insignificant overhead, thereby alleviating the bottlenecks described above, while still handling the worst-case complex signatures by state-of-the-art means. Our proposal, targeting Surface Codes, consists of: 1) A lightweight decoder for decoding and correcting trivial common-case errors, designed for the cryogenic domain. The decoder is implemented for SFQ logic. 2) A statistical confidence-based technique for off-chip decoding bandwidth allocation, to efficiently handle rare complex decodes which are not covered by the on-chip decoder. 3) A method for stalling circuit execution, for the worst-case scenarios in which the provisioned off-chip bandwidth is insufficient to complete all requested off-chip decodes. In all, our proposal enables 70-99+% off-chip bandwidth elimination across a range of logical and physical error rates, without significantly sacrificing the accuracy of state-of-the-art off-chip decoding. By doing so, it achieves 10-10000x bandwidth reduction over prior off-chip bandwidth reduction techniques. Furthermore, it achieves a 15-37x resource overhead reduction compared to prior on-chip-only decoding.</description>
  </item>

  <item>
    <title>Solvable model of deep thermalization with distinct design times</title>
    <link>http://arxiv.org/pdf/2208.10542</link>
    <author>Matteo Ippoliti, Wen Wei Ho</author>
    <pubDate>Aug 24 2022</pubDate>
    <description>We study the emergence over time of a universal, uniform distribution of quantum states on a finite subsystem, induced by projectively measuring the rest of the system. Dubbed deep thermalization, this phenomenon represents a form of equilibration in quantum many-body systems stronger than regular thermalization, which only constrains the ensemble-averaged values of observables. While there exist quantum circuit models of dynamics in one dimension where this phenomenon can be shown to arise exactly, these are special in that deep thermalization occurs at precisely the same time as regular thermalization. Here, we present an exactly-solvable model of chaotic dynamics where the two processes can be shown to occur over different time scales. The model is composed of a finite subsystem coupled to an infinite random-matrix bath through a small constriction, and highlights the role of locality and imperfect thermalization in constraining the formation of such universal wavefunction distributions. We test our analytical predictions against exact numerical simulations, finding excellent agreement.</description>
  </item>

</channel>

</rss>
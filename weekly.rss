<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>Towards near-term quantum simulation of materials</title>
    <link>http://arxiv.org/pdf/2205.15256</link>
    <author>Laura Clinton, Toby Cubitt, Brian Flynn, Filippo Maria Gambetta, Joel Klassen, Ashley Montanaro, Stephen Piddock, Raul A. Santos, Evan Sheridan</author>
    <pubDate>May 31 2022</pubDate>
    <description>Simulation of materials is one of the most promising applications of quantum computers. On near-term hardware the crucial constraint on these simulations is circuit depth. Many quantum simulation algorithms rely on a layer of unitary evolutions generated by each term in a Hamiltonian. This appears in time-dynamics as a single Trotter step, and in variational quantum eigensolvers under the Hamiltonian variational ansatz as a single ansatz layer. We present a new quantum algorithm design for materials modelling where the depth of a layer is independent of the system size. This design takes advantage of the locality of materials in the Wannier basis and employs a tailored fermionic encoding that preserves locality. We analyse the circuit costs of this approach and present a compiler that transforms density functional theory data into quantum circuit instructions -- connecting the physics of the material to the simulation circuit. The compiler automatically optimises circuits at multiple levels, from the base gate level to optimisations derived from the physics of the specific target material. We present numerical results for materials spanning a wide structural and technological range. Our results demonstrate a reduction of many orders of magnitude in circuit depth over standard prior methods that do not consider the structure of the Hamiltonian. For example our results improve resource requirements for Strontium Vanadate (SrVO$_3$) from 864 to 180 qubits for a $3\times3\times3$ lattice, and the circuit depth of a single Trotter or variational layer from $7.5\times 10^8$ to depth $730$. Although this is still beyond current hardware, our results show that materials simulation may be feasible on quantum computers without necessarily requiring scalable, fault-tolerant quantum computers, provided quantum algorithm design incorporates understanding of the materials and applications.</description>
  </item>

  <item>
    <title>The battle of clean and dirty qubits in the era of partial error correction</title>
    <link>http://arxiv.org/pdf/2205.13454</link>
    <author>Daniel Bultrini, Samson Wang, Piotr Czarnik, Max Hunter Gordon, M. Cerezo, Patrick J. Coles, Lukasz Cincio</author>
    <pubDate>May 27 2022</pubDate>
    <description>When error correction becomes possible it will be necessary to dedicate a large number of physical qubits to each logical qubit. Error correction allows for deeper circuits to be run, but each additional physical qubit can potentially contribute an exponential increase in computational space, so there is a trade-off between using qubits for error correction or using them as noisy qubits. In this work we look at the effects of using noisy qubits in conjunction with noiseless qubits (an idealized model for error-corrected qubits), which we call the "clean and dirty" setup. We employ analytical models and numerical simulations to characterize this setup. Numerically we show the appearance of Noise-Induced Barren Plateaus (NIBPs), i.e., an exponential concentration of observables caused by noise, in an Ising model Hamiltonian variational ansatz circuit. We observe this even if only a single qubit is noisy and given a deep enough circuit, suggesting that NIBPs cannot be fully overcome simply by error-correcting a subset of the qubits. On the positive side, we find that for every noiseless qubit in the circuit, there is an exponential suppression in concentration of gradient observables, showing the benefit of partial error correction. Finally, our analytical models corroborate these findings by showing that observables concentrate with a scaling in the exponent related to the ratio of dirty-to-total qubits.</description>
  </item>

  <item>
    <title>On the Role of Quantum Coherence in Thermodynamics</title>
    <link>http://arxiv.org/pdf/2205.13612</link>
    <author>Gilad Gour</author>
    <pubDate>May 30 2022</pubDate>
    <description>We find necessary and sufficient conditions to determine the inter-convertibility of quantum systems under time-translation covariant evolution, and use it to solve several problems in quantum thermodynamics both in the single-shot and asymptotic regimes. It is well known that the resource theory of quantum athermality is not reversible, but in PRL 111, 250404 (2013) it was claimed that the theory becomes reversible "provided a sublinear amount of coherent superposition over energy levels is available". Here we show that the original proof of this claim is incorrect, and then provide a completely new rigorous proof for the pure-state case. A proof of the same claim for the mixed-state case is still lacking.</description>
  </item>

  <item>
    <title>Mitigating barren plateaus of variational quantum eigensolvers</title>
    <link>http://arxiv.org/pdf/2205.13539</link>
    <author>Xia Liu, Geng Liu, Jiaxin Huang, Xin Wang</author>
    <pubDate>May 27 2022</pubDate>
    <description>Variational quantum algorithms (VQAs) are expected to establish valuable applications on near-term quantum computers. However, recent works have pointed out that the performance of VQAs greatly relies on the capability of the ansatzes and is seriously limited by optimization issues such as barren plateaus (i.e., vanishing gradients). This work proposes the state efficient ansatz (SEA) for accurate quantum dynamics simulations with improved trainability. First, we show that SEA can generate an arbitrary pure state with much fewer parameters than a universal ansatz, making it efficient for tasks like ground state estimation. It also has the flexibility in adjusting the entanglement of the prepared state, which could be applied to further improve the efficiency of simulating weak entanglement. Second, we show that SEA is not a unitary 2-design even if it has universal wavefunction expressibility and thus has great potential to improve the trainability by avoiding the zone of barren plateaus. We further investigate a plethora of examples in ground state estimation and notably obtain significant improvements in the variances of derivatives and the overall optimization behaviors. This result indicates that SEA can mitigate barren plateaus by sacrificing the redundant expressibility for the target problem.</description>
  </item>

  <item>
    <title>Simulation Complexity of Many-Body Localized Systems</title>
    <link>http://arxiv.org/pdf/2205.12967</link>
    <author>Adam Ehrenberg, Abhinav Deshpande, Christopher L. Baldwin, Dmitry A. Abanin, Alexey V. Gorshkov</author>
    <pubDate>May 27 2022</pubDate>
    <description>We use complexity theory to rigorously investigate the difficulty of classically simulating evolution under many-body localized (MBL) Hamiltonians. Using the defining feature that MBL systems have a complete set of quasilocal integrals of motion (LIOMs), we demonstrate a transition in the classical complexity of simulating such systems as a function of evolution time. On one side, we construct a quasipolynomial-time tensor-network-inspired algorithm for strong simulation of 1D MBL systems (i.e., calculating the expectation value of arbitrary products of local observables) evolved for any time polynomial in the system size. On the other side, we prove that even weak simulation, i.e. sampling, becomes formally hard after an exponentially long evolution time, assuming widely believed conjectures in complexity theory. Finally, using the consequences of our classical simulation results, we also show that the quantum circuit complexity for MBL systems is sublinear in evolution time. This result is a counterpart to a recent proof that the complexity of random quantum circuits grows linearly in time.</description>
  </item>

  <item>
    <title>Only Classical Parametrised States have Optimal Measurements</title>
    <link>http://arxiv.org/pdf/2205.14142</link>
    <author>Wilfred Salmon, Sergii Strelchuk, David Arvidsson-Shukur</author>
    <pubDate>May 30 2022</pubDate>
    <description>Measurements of quantum states form a key component in quantum-information processing. It is therefore an important task to compare measurements and furthermore decide if a measurement strategy is optimal. We introduce a framework that allows one to conclusively establish if a measurement is optimal. Our method relies on the fundamental property of expected errors of estimators, known as risk, and it does not involve optimisation over entropic quantities. The framework applies to finite sample sizes and lack of prior knowledge, as well as to the asymptotic and Bayesian settings. We prove a no-go theorem that shows that only classical states admit optimal measurements. We further consider the less restrictive notion of an approximately optimal measurement and give sufficient conditions for such measurements to exist. Finally, we generalise the notion of when an estimator is inadmissible (i.e. strictly worse than an alternative), and provide two sufficient conditions for a measurement to be inadmissible.</description>
  </item>

  <item>
    <title>Characterizing and mitigating coherent errors in a trapped ion quantum processor using hidden inverses</title>
    <link>http://arxiv.org/pdf/2205.14225</link>
    <author>Swarnadeep Majumder, Christopher G. Yale, Titus D. Morris, Daniel S. Lobser, Ashlyn D. Burch, Matthew N. H. Chow, Melissa C. Revelle, Susan M. Clark, Raphael C. Pooser</author>
    <pubDate>May 31 2022</pubDate>
    <description>Quantum computing testbeds exhibit high-fidelity quantum control over small collections of qubits, enabling performance of precise, repeatable operations followed by measurements. Currently, these noisy intermediate-scale devices can support a sufficient number of sequential operations prior to decoherence such that small algorithms can be performed reliably. While the results of these algorithms are imperfect, these imperfections can help bootstrap quantum computer testbed development. Demonstrations of these small algorithms over the past few years, coupled with the idea that imperfect algorithm performance can be caused by several dominant noise sources in the quantum processor, which can be measured and calibrated during algorithm execution or in post-processing, has led to the use of noise mitigation to improve typical computational results. Conversely, small benchmark algorithms coupled with noise mitigation can help diagnose the nature of the noise, whether systematic or purely random. Here, we outline the use of coherent noise mitigation techniques as a characterization tool in trapped-ion testbeds. We perform model-fitting of the noisy data to determine the noise source based on realistic physics focused noise models and demonstrate that systematic noise amplification coupled with error mitigation schemes provides useful data for noise model deduction. Further, in order to connect lower level noise model details with application specific performance of near term algorithms, we experimentally construct the loss landscape of a variational algorithm under various injected noise sources coupled with error mitigation techniques. This type of connection enables application-aware hardware codesign, in which the most important noise sources in specific applications, like quantum chemistry, become foci of improvement in subsequent hardware generations.</description>
  </item>

  <item>
    <title>Quantum error correction in a time-dependent transverse field Ising model</title>
    <link>http://arxiv.org/pdf/2205.12998</link>
    <author>Yifan Hong, Jeremy T. Young, Adam M. Kaufman, Andrew Lucas</author>
    <pubDate>May 27 2022</pubDate>
    <description>We describe a simple quantum error correcting code built out of a time-dependent transverse field Ising model. The code is similar to a repetition code, but has two advantages: an $N$-qubit code can be implemented with a finite-depth spatially local unitary circuit, and it can subsequently protect against both $X$ and $Z$ errors if $N\ge 10$ is even. We propose an implementation of this code with 10 ultracold Rydberg atoms in optical tweezers, along with further generalizations of the code.</description>
  </item>

  <item>
    <title>Quantum-assisted Monte Carlo algorithms for fermions</title>
    <link>http://arxiv.org/pdf/2205.14903</link>
    <author>Xiaosi Xu, Ying Li</author>
    <pubDate>May 31 2022</pubDate>
    <description>Quantum computing is a promising way to systematically solve the longstanding computational problem, the ground state of a many-body fermion system. Many efforts have been made to realise certain forms of quantum advantage in this problem, for instance, the development of variational quantum algorithms. A recent work by Huggins et al. reports a novel candidate, i.e. a quantum-classical hybrid Monte Carlo algorithm with a reduced bias in comparison to its fully-classical counterpart. In this paper, we propose a family of scalable quantum-assisted Monte Carlo algorithms where the quantum computer is used at its minimal cost and still can reduce the bias. By incorporating a Bayesian inference approach, we can achieve this quantum-facilitated bias reduction with a much smaller quantum-computing cost than taking empirical mean in amplitude estimation. Besides, we show that the hybrid Monte Carlo framework is a general way to suppress errors in the ground state obtained from classical algorithms. Our work provides a Monte Carlo toolkit for achieving quantum-enhanced calculation of fermion systems on near-term quantum devices.</description>
  </item>

  <item>
    <title>Approaching optimal entangling collective measurements on quantum computing platforms</title>
    <link>http://arxiv.org/pdf/2205.15358</link>
    <author>Lorcan O. Conlon, Tobias Vogl, Christian D. Marciniak, Ivan Pogorelov, Simon K. Yung, Falk Eilenberger, Dominic W. Berry, Fabiana S. Santana, Rainer Blatt, Thomas Monz, Ping Koy Lam, Syed M. Assad</author>
    <pubDate>Jun 01 2022</pubDate>
    <description>Entanglement is one of the most intriguing features of quantum mechanics and holds great promise for enhancing metrology and communications. Much of the focus of quantum metrology to date has been on generating highly entangled quantum states which offer better sensitivity, per resource, than can be achieved classically [1-3]. However, to reach the ultimate limits in multi-parameter quantum metrology and quantum information processing tasks, collective measurements, which generate entanglement between multiple copies of the quantum state, are necessary [4-6]. There is presently no known method for implementing arbitrary, optimal collective measurements on more than two copies of the quantum state. Here we experimentally demonstrate theoretically optimal single-copy (separable) and two-copy (entangled) collective measurements for simultaneously estimating two non-commuting qubit rotations. This allows us to draw fundamental insights about the interpretation of the uncertainty principle. We implement our optimal measurements on superconducting, trapped-ion and photonic systems, providing an indication of how future quantum-enhanced sensing networks may look. This work offers a pathway to extracting the maximal advantage of quantum mechanics for information processing tasks [7, 8].</description>
  </item>

</channel>

</rss>
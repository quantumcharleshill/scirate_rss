<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>Logical shadow tomography: Efficient estimation of error-mitigated observables</title>
    <link>http://arxiv.org/pdf/2203.07263</link>
    <author>Hong-Ye Hu, Ryan LaRose, Yi-Zhuang You, Eleanor Rieffel, Zhihui Wang</author>
    <pubDate>Mar 15 2022</pubDate>
    <description>We introduce a technique to estimate error-mitigated expectation values on noisy quantum computers. Our technique performs shadow tomography on a logical state to produce a memory-efficient classical reconstruction of the noisy density matrix. Using efficient classical post-processing, one can mitigate errors by projecting a general nonlinear function of the noisy density matrix into the codespace. The subspace expansion and virtual distillation can be viewed as special cases of the new framekwork. We show our method is favorable in the quantum and classical resources overhead. Relative to subspace expansion which requires $O\left(2^{N} \right)$ samples to estimate a logical Pauli observable with $[[N, k]]$ error correction code, our technique requires only $O\left(4^{k} \right)$ samples. Relative to virtual distillation, our technique can compute powers of the density matrix without additional copies of quantum states or quantum memory. We present numerical evidence using logical states encoded with up to sixty physical qubits and show fast convergence to error-free expectation values with only $10^5$ samples under 1% depolarizing noise.</description>
  </item>

  <item>
    <title>Shadow Distillation: Quantum Error Mitigation with Classical Shadows for Near-Term Quantum Processors</title>
    <link>http://arxiv.org/pdf/2203.07309</link>
    <author>Alireza Seif, Ze-Pei Cian, Sisi Zhou, Senrui Chen, Liang Jiang</author>
    <pubDate>Mar 15 2022</pubDate>
    <description>Mitigating errors in quantum information processing devices is especially important in the absence of fault tolerance. An effective method in suppressing state-preparation errors is using multiple copies to distill the ideal component from a noisy quantum state. Here, we use classical shadows and randomized measurements to circumvent the need for coherent access to multiple copies at an exponential cost. We study the scaling of resources using numerical simulations and find that the overhead is still favorable compared to full state tomography. We optimize measurement resources under realistic experimental constraints and apply our method to an experiment preparing Greenberger-Horne-Zeilinger (GHZ) state with trapped ions. In addition to improving stabilizer measurements, the analysis of the improved results reveals the nature of errors affecting the experiment. Hence, our results provide a directly applicable method for mitigating errors in near-term quantum computers.</description>
  </item>

  <item>
    <title>Quantum Parameterized Complexity</title>
    <link>http://arxiv.org/pdf/2203.08002</link>
    <author>Michael J. Bremner, Zhengfeng Ji, Ryan L. Mann, Luke Mathieson, Mauro E.S. Morales, Alexis T.E. Shaw</author>
    <pubDate>Mar 16 2022</pubDate>
    <description>Parameterized complexity theory was developed in the 1990s to enrich the complexity-theoretic analysis of problems that depend on a range of parameters. In this paper we establish a quantum equivalent of classical parameterized complexity theory, motivated by the need for new tools for the classifications of the complexity of real-world problems. We introduce the quantum analogues of a range of parameterized complexity classes and examine the relationship between these classes, their classical counterparts, and well-studied problems. This framework exposes a rich classification of the complexity of parameterized versions of QMA-hard problems, demonstrating, for example, a clear separation between the Quantum Circuit Satisfiability problem and the Local Hamiltonian problem.</description>
  </item>

  <item>
    <title>Matching and maximum likelihood decoding of a multi-round subsystem quantum error correction experiment</title>
    <link>http://arxiv.org/pdf/2203.07205</link>
    <author>Neereja Sundaresan, Theodore J. Yoder, Youngseok Kim, Muyuan Li, Edward H. Chen, Grace Harper, Ted Thorbeck, Andrew W. Cross, Antonio D. Córcoles, Maika Takita</author>
    <pubDate>Mar 15 2022</pubDate>
    <description>Quantum error correction offers a promising path for performing quantum computations with low errors. Although a fully fault-tolerant execution of a quantum algorithm remains unrealized, recent experimental developments, along with improvements in control electronics, are enabling increasingly advanced demonstrations of the necessary operations for applying quantum error correction. Here, we perform quantum error correction on superconducting qubits connected in a heavy-hexagon lattice. The full processor can encode a logical qubit with distance three and perform several rounds of fault-tolerant syndrome measurements that allow the correction of any single fault in the circuitry. Furthermore, by using dynamic circuits and classical computation as part of our syndrome extraction protocols, we can exploit real-time feedback to reduce the impact of energy relaxation error in the syndrome and flag qubits. We show that the logical error varies depending on the use of a perfect matching decoder compared to a maximum likelihood decoder. We observe a logical error per syndrome measurement round as low as $\sim0.04$ for the matching decoder and as low as $\sim0.03$ for the maximum likelihood decoder. Our results suggest that more significant improvements to decoders are likely on the horizon as quantum hardware has reached a new stage of development towards fully fault-tolerant operations.</description>
  </item>

  <item>
    <title>Quantifying the barren plateau phenomenon for a model of unstructured variational ansätze</title>
    <link>http://arxiv.org/pdf/2203.06174</link>
    <author>John Napp</author>
    <pubDate>Mar 14 2022</pubDate>
    <description>Quantifying the flatness of the objective-function landscape associated with unstructured parameterized quantum circuits is important for understanding the performance of variational algorithms utilizing a "hardware-efficient ansatz", particularly for ensuring that a prohibitively flat landscape -- a so-called "barren plateau" -- is avoided. For a model of such ansätze, we relate the typical landscape flatness to a certain family of random walks, enabling us to derive a Monte Carlo algorithm for efficiently, classically estimating the landscape flatness for any architecture. The statistical picture additionally allows us to prove new analytic bounds on the barren plateau phenomenon, and more generally provides novel insights into the phenomenon's dependence on the ansatz depth, architecture, qudit dimension, and Hamiltonian combinatorial and spatial locality. Our analysis utilizes techniques originally developed by Dalzell et al. to study anti-concentration in random circuits.</description>
  </item>

  <item>
    <title>Detecting entanglement in quantum many-body systems via permutation moments</title>
    <link>http://arxiv.org/pdf/2203.08391</link>
    <author>Zhenhuan Liu, Yifan Tang, Hao Dai, Pengyu Liu, Shu Chen, Xiongfeng Ma</author>
    <pubDate>Mar 17 2022</pubDate>
    <description>Multipartite entanglement plays an essential role in both quantum information science and many-body physics. Due to the exponentially large dimension and complex geometric structure of the state space, the detection of entanglement in many-body systems is extremely challenging in reality. Conventional means, like entanglement witness and entropy criterion, either highly depend on the prior knowledge of the studied systems or the detection capability is relatively weak. In this work, we propose a framework for designing multipartite entanglement criteria based on permutation moments, which have an effective implementation with either the generalized control-SWAP quantum circuits or the random unitary techniques. These criteria show strong detection capability in the multi-qubit Ising model with a long-range $XY$ Hamiltonian. The quantities associated with these criteria have clear physical meaning and can be used as entanglement quantifiers, with which we show the entanglement scaling transition in a quantum dynamical phase transition. Furthermore, our framework can also be generalized to detect the much more complicated entanglement structure in quantum many-body systems.</description>
  </item>

  <item>
    <title>Memory Compression with Quantum Random-Access Gates</title>
    <link>http://arxiv.org/pdf/2203.05599</link>
    <author>Harry Buhrman, Bruno Loff, Subhasree Patro, Florian Speelman</author>
    <pubDate>Mar 14 2022</pubDate>
    <description>In the classical RAM, we have the following useful property. If we have an algorithm that uses $M$ memory cells throughout its execution, and in addition is sparse, in the sense that, at any point in time, only $m$ out of $M$ cells will be non-zero, then we may "compress" it into another algorithm which uses only $m \log M$ memory and runs in almost the same time. We may do so by simulating the memory using either a hash table, or a self-balancing tree. We show an analogous result for quantum algorithms equipped with quantum random-access gates. If we have a quantum algorithm that runs in time $T$ and uses $M$ qubits, such that the state of the memory, at any time step, is supported on computational-basis vectors of Hamming weight at most $m$, then it can be simulated by another algorithm which uses only $O(m \log M)$ memory, and runs in time $\tilde O(T)$. We show how this theorem can be used, in a black-box way, to simplify the presentation in several papers. Broadly speaking, when there exists a need for a space-efficient history-independent quantum data-structure, it is often possible to construct a space-inefficient, yet sparse, quantum data structure, and then appeal to our main theorem. This results in simpler and shorter arguments.</description>
  </item>

  <item>
    <title>Towards experimental classical verification of quantum computation</title>
    <link>http://arxiv.org/pdf/2203.07395</link>
    <author>Roman Stricker, Jose Carrasco, Martin Ringbauer, Lukas Postler, Michael Meth, Claire Edmunds, Philipp Schindler, Rainer Blatt, Peter Zoller, Barbara Kraus, Thomas Monz</author>
    <pubDate>Mar 16 2022</pubDate>
    <description>With today's quantum processors venturing into regimes beyond the capabilities of classical devices [1-3], we face the challenge to verify that these devices perform as intended, even when we cannot check their results on classical computers [4,5]. In a recent breakthrough in computer science [6-8], a protocol was developed that allows the verification of the output of a computation performed by an untrusted quantum device based only on classical resources. Here, we follow these ideas, and demonstrate in a first, proof-of-principle experiment a verification protocol using only classical means on a small trapped-ion quantum processor. We contrast this to verification protocols, which require trust and detailed hardware knowledge, as in gate-level benchmarking [9], or additional quantum resources in case we do not have access to or trust in the device to be tested [5]. While our experimental demonstration uses a simplified version [10] of Mahadev's protocol [6] we demonstrate the necessary steps for verifying fully untrusted devices. A scaled-up version of our protocol will allow for classical verification, requiring no hardware access or detailed knowledge of the tested device. Its security relies on post-quantum secure trapdoor functions within an interactive proof [11]. The conceptually straightforward, but technologically challenging scaled-up version of the interactive proofs, considered here, can be used for a variety of additional tasks such as verifying quantum advantage [8], generating [12] and certifying quantum randomness [7], or composable remote state preparation [13].</description>
  </item>

  <item>
    <title>Quantum algorithms from fluctuation theorems: Thermal-state preparation</title>
    <link>http://arxiv.org/pdf/2203.08882</link>
    <author>Zoe Holmes, Gopikrishnan Muraleedharan, Rolando D. Somma, Yigit Subasi, Burak Şahinoğlu</author>
    <pubDate>Mar 18 2022</pubDate>
    <description>Fluctuation theorems provide a correspondence between properties of quantum systems in thermal equilibrium and a work distribution arising in a non-equilibrium process that connects two quantum systems with Hamiltonians $H_0$ and $H_1=H_0+V$. Building upon these theorems, we present a quantum algorithm to prepare a purification of the thermal state of $H_1$ at inverse temperature $\beta \ge 0$ starting from a purification of the thermal state of $H_0$. The complexity of the quantum algorithm, given by the number of uses of certain unitaries, is $\tilde {\cal O}(e^{\beta (\Delta \! A- w_l)/2})$, where $\Delta \! A$ is the free-energy difference between $H_1$ and $H_0,$ and $w_l$ is a work cutoff that depends on the properties of the work distribution and the approximation error $\epsilon>0$. If the non-equilibrium process is trivial, this complexity is exponential in $\beta \|V\|$, where $\|V\|$ is the spectral norm of $V$. This represents a significant improvement of prior quantum algorithms that have complexity exponential in $\beta \|H_1\|$ in the regime where $\|V\|\ll \|H_1\|$. The dependence of the complexity in $\epsilon$ varies according to the structure of the quantum systems. It can be exponential in $1/\epsilon$ in general, but we show it to be sublinear in $1/\epsilon$ if $H_0$ and $H_1$ commute, or polynomial in $1/\epsilon$ if $H_0$ and $H_1$ are local spin systems. The possibility of applying a unitary that drives the system out of equilibrium allows one to increase the value of $w_l$ and improve the complexity even further. To this end, we analyze the complexity for preparing the thermal state of the transverse field Ising model using different non-equilibrium unitary processes and see significant complexity improvements.</description>
  </item>

  <item>
    <title>A trace inequality of Ando, Hiai and Okubo and a monotonicity property of the Golden-Thompson inequality</title>
    <link>http://arxiv.org/pdf/2203.06136</link>
    <author>Eric A. Carlen, Elliott H. Lieb</author>
    <pubDate>Mar 14 2022</pubDate>
    <description>The Golden-Thompson trace inequality which states that $Tr\, e^{H+K} \leq Tr\, e^H e^K$ has proved to be very useful in quantum statistical mechanics. Golden used it to show that the classical free energy is less than the quantum one. Here we make this G-T inequality more explicit by proving that for some operators, notably the operators of interest in quantum mechanics, $H=\Delta$ or $H= -\sqrt{-\Delta +m}$ and $K=$ potential, $Tr\, e^{H+(1-u)K}e^{uK}$ is a monotone increasing function of the parameter $u$ for $0\leq u \leq 1$. Our proof utilizes an inequality of Ando, Hiai and Okubo (AHO): $Tr\, X^sY^tX^{1-s}Y^{1-t} \leq Tr\, XY$ for positive operators X,Y and for $\tfrac{1}{2} \leq s,\,t \leq 1 $ and $s+t \leq \tfrac{3}{2}$. The obvious conjecture that this inequality should hold up to $s+t\leq 1$, was proved false by Plevnik. We give a different proof of AHO and also give more counterexamples in the $\tfrac{3}{2}, 1$ range. More importantly we show that the inequality conjectured in AHO does indeed hold in this range if $X,Y$ have a certain positivity property -- one which does hold for quantum mechanical operators, thus enabling us to prove our G-T monotonicity theorem.</description>
  </item>

</channel>

</rss>
<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>Improved single-shot decoding of higher dimensional hypergraph product codes</title>
    <link>http://arxiv.org/pdf/2206.03122</link>
    <author>Oscar Higgott, Nikolas P. Breuckmann</author>
    <pubDate>Jun 08 2022</pubDate>
    <description>In this work we study the single-shot performance of higher dimensional hypergraph product codes decoded using belief-propagation and ordered-statistics decoding [Panteleev and Kalachev, 2019]. We find that decoding data qubit and syndrome measurement errors together in a single stage leads to single-shot thresholds that greatly exceed all previously observed single-shot thresholds for these codes. For the 3D toric code and a phenomenological noise model, our results are consistent with a sustainable threshold of 7.1% for $Z$ errors, compared to the threshold of 2.90% previously found using a two-stage decoder [Quintavalle et al., 2021]. For the 4D toric code, for which both $X$ and $Z$ error correction is single-shot, our results are consistent with a sustainable single-shot threshold of 4.3% which is even higher than the threshold of 2.93% for the 2D toric code for the same noise model but using $L$ rounds of stabiliser measurement. We also explore the performance of balanced product and 4D hypergraph product codes which we show lead to a reduction in qubit overhead compared the surface code for phenomenological error rates as high as 1%.</description>
  </item>

  <item>
    <title>Quantum Neural Network Classifiers: A Tutorial</title>
    <link>http://arxiv.org/pdf/2206.02806</link>
    <author>Weikang Li, Zhide Lu, Dong-Ling Deng</author>
    <pubDate>Jun 08 2022</pubDate>
    <description>Machine learning has achieved dramatic success over the past decade, with applications ranging from face recognition to natural language processing. Meanwhile, rapid progress has been made in the field of quantum computation including developing both powerful quantum algorithms and advanced quantum devices. The interplay between machine learning and quantum physics holds the intriguing potential for bringing practical applications to the modern society. Here, we focus on quantum neural networks in the form of parameterized quantum circuits. We will mainly discuss different structures and encoding strategies of quantum neural networks for supervised learning tasks, and benchmark their performance utilizing Yao.jl, a quantum simulation package written in Julia Language. The codes are efficient, aiming to provide convenience for beginners in scientific works such as developing powerful variational quantum learning models and assisting the corresponding experimental demonstrations.</description>
  </item>

  <item>
    <title>Minimising statistical errors in calibration of quantum-gate sets</title>
    <link>http://arxiv.org/pdf/2206.03417</link>
    <author>Yaiza Aragonés-Soria, René Otten, Tobias Hangleiter, Pascal Cerfontaine, David Gross</author>
    <pubDate>Jun 08 2022</pubDate>
    <description>Calibration of quantum gates is a necessary hurdle to overcome on the way to a reliable quantum computer. In a recent paper, a protocol called Gate Set Calibration protocol (GSC) has been introduced and used to learn coherent errors from multi-qubit quantum gates. Here, we extend this study in a number of ways: First, we perform a statistical analysis of the measurement uncertainties. Second, we find explicit measurement settings that minimize this uncertainty, while also requiring that the protocol involves only a small number of distinct gates, aiding physical realizability. We numerically demonstrate that, just by adding two more single-qubit gates to GSC, the statistical error produced in the calibration of a CNOT gate is divided by a factor of more than two.</description>
  </item>

  <item>
    <title>Real Schur norms and Hadamard matrices</title>
    <link>http://arxiv.org/pdf/2206.02863</link>
    <author>John Holbrook, Nathaniel Johnston, Jean-Pierre Schoch</author>
    <pubDate>Jun 08 2022</pubDate>
    <description>We present a preliminary study of Schur norms $\|M\|_{S}=\max\{ \|M\circ C\|: \|C\|=1\}$, where M is a matrix whose entries are $\pm1$, and $\circ$ denotes the entrywise (i.e., Schur or Hadamard) product of the matrices. We show that, if such a matrix M is n-by-n, then its Schur norm is bounded by $\sqrt{n}$, and equality holds if and only if it is a Hadamard matrix. We develop a numerically efficient method of computing Schur norms, and as an application of our results we present several almost Hadamard matrices that are better than were previously known.</description>
  </item>

  <item>
    <title>Recent Advances for Quantum Neural Networks in Generative Learning</title>
    <link>http://arxiv.org/pdf/2206.03066</link>
    <author>Jinkai Tian, Xiaoyu Sun, Yuxuan Du, Shanshan Zhao, Qing Liu, Kaining Zhang, Wei Yi, Wanrong Huang, Chaoyue Wang, Xingyao Wu, Min-Hsiu Hsieh, Tongliang Liu, Wenjing Yang, Dacheng Tao</author>
    <pubDate>Jun 08 2022</pubDate>
    <description>Quantum computers are next-generation devices that hold promise to perform calculations beyond the reach of classical computers. A leading method towards achieving this goal is through quantum machine learning, especially quantum generative learning. Due to the intrinsic probabilistic nature of quantum mechanics, it is reasonable to postulate that quantum generative learning models (QGLMs) may surpass their classical counterparts. As such, QGLMs are receiving growing attention from the quantum physics and computer science communities, where various QGLMs that can be efficiently implemented on near-term quantum machines with potential computational advantages are proposed. In this paper, we review the current progress of QGLMs from the perspective of machine learning. Particularly, we interpret these QGLMs, covering quantum circuit born machines, quantum generative adversarial networks, quantum Boltzmann machines, and quantum autoencoders, as the quantum extension of classical generative learning models. In this context, we explore their intrinsic relation and their fundamental differences. We further summarize the potential applications of QGLMs in both conventional machine learning tasks and quantum physics. Last, we discuss the challenges and further research directions for QGLMs.</description>
  </item>

</channel>

</rss>
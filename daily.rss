<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>Emergence of Kac-Moody Symmetry in Critical Quantum Spin Chains</title>
    <link>http://arxiv.org/pdf/2206.01656</link>
    <author>Ruoshui Wang, Yijian Zou, Guifre Vidal</author>
    <pubDate>Jun 06 2022</pubDate>
    <description>Given a critical quantum spin chain with a microscopic Lie-group symmetry, corresponding e.g. to $U(1)$ or $SU(2)$ spin isotropy, we numerically investigate the emergence of Kac-Moody symmetry at low energies and long distances. In that regime, one such critical quantum spin chain is described by a conformal field theory where the usual Virasoro algebra associated to conformal invariance is augmented with a Kac-Moody algebra associated to conserved currents. Specifically, we first propose a method to construct lattice operators corresponding to the Kac-Moody generators. We then numerically show that, when projected onto low energy states of the quantum spin chain, these operators indeed approximately fulfill the Kac-Moody algebra. The lattice version of the Kac-Moody generators allow us to compute the so-called level constant and to organize the low-energy eigenstates of the lattice Hamiltonian into Kac-Moody towers. We illustrate the proposal with the XXZ model and the Heisenberg model with a next-to-nearest-neighbor coupling.</description>
  </item>

  <item>
    <title>Ternary unitary quantum lattice models and circuits in $2 + 1$ dimensions</title>
    <link>http://arxiv.org/pdf/2206.01499</link>
    <author>Richard Milbradt, Lisa Scheller, Christopher AÃŸmus, Christian B. Mendl</author>
    <pubDate>Jun 06 2022</pubDate>
    <description>We extend the concept of dual unitary quantum gates to quantum lattice models in $2 + 1$ dimensions, by introducing and studying ternary unitary four-particle gates, which are unitary in time and both spatial dimensions. When used as building blocks of lattice models with periodic boundary conditions in time and space (corresponding to infinite temperature states), dynamical correlation functions exhibit a light-ray structure. We also generalize solvable MPS to two spatial dimensions with cylindrical boundary conditions, by showing that the analogous solvable PEPS can be identified with matrix product unitaries. In the resulting tensor network for evaluating equal-time correlation functions, the bulk ternary unitary gates cancel out. We delineate and implement a numerical algorithm for computing such correlations by contracting the remaining tensors.</description>
  </item>

  <item>
    <title>A Theoretical Analysis on Feature Learning in Neural Networks: Emergence from Inputs and Advantage over Fixed Features</title>
    <link>http://arxiv.org/pdf/2206.01717</link>
    <author>Zhenmei Shi, Junyi Wei, Yingyu Liang</author>
    <pubDate>Jun 06 2022</pubDate>
    <description>An important characteristic of neural networks is their ability to learn representations of the input data with effective features for prediction, which is believed to be a key factor to their superior empirical performance. To better understand the source and benefit of feature learning in neural networks, we consider learning problems motivated by practical data, where the labels are determined by a set of class relevant patterns and the inputs are generated from these along with some background patterns. We prove that neural networks trained by gradient descent can succeed on these problems. The success relies on the emergence and improvement of effective features, which are learned among exponentially many candidates efficiently by exploiting the data (in particular, the structure of the input distribution). In contrast, no linear models on data-independent features of polynomial sizes can learn to as good errors. Furthermore, if the specific input structure is removed, then no polynomial algorithm in the Statistical Query model can learn even weakly. These results provide theoretical evidence showing that feature learning in neural networks depends strongly on the input structure and leads to the superior performance. Our preliminary experimental results on synthetic and real data also provide positive support.</description>
  </item>

  <item>
    <title>Riemann surfaces for integer counting processes</title>
    <link>http://arxiv.org/pdf/2206.01698</link>
    <author>Sylvain Prolhac</author>
    <pubDate>Jun 06 2022</pubDate>
    <description>Integer counting processes increment of an integer value at transitions between states of an underlying Markov process. The generator of a counting process, which depends on a parameter conjugate to the increments, defines a complex algebraic curve through its characteristic equation, and thus a compact Riemann surface. We show that the probability of a counting process can then be written as a contour integral on that Riemann surface. Several examples are discussed in details.</description>
  </item>

  <item>
    <title>QMLP: An Error-Tolerant Nonlinear Quantum MLP Architecture using Parameterized Two-Qubit Gates</title>
    <link>http://arxiv.org/pdf/2206.01345</link>
    <author>Cheng Chu, Nai-Hui Chia, Lei Jiang, Fan Chen</author>
    <pubDate>Jun 06 2022</pubDate>
    <description>Despite potential quantum supremacy, state-of-the-art quantum neural networks (QNNs) suffer from low inference accuracy. First, the current Noisy Intermediate-Scale Quantum (NISQ) devices with high error rates of 0.001 to 0.01 significantly degrade the accuracy of a QNN. Second, although recently proposed Re-Uploading Units (RUUs) introduce some non-linearity into the QNN circuits, the theory behind it is not fully understood. Furthermore, previous RUUs that repeatedly upload original data can only provide marginal accuracy improvements. Third, current QNN circuit ansatz uses fixed two-qubit gates to enforce maximum entanglement capability, making task-specific entanglement tuning impossible, resulting in poor overall performance. In this paper, we propose a Quantum Multilayer Perceptron (QMLP) architecture featured by error-tolerant input embedding, rich nonlinearity, and enhanced variational circuit ansatz with parameterized two-qubit entangling gates. Compared to prior arts, QMLP increases the inference accuracy on the 10-class MNIST dataset by 10% with 2 times fewer quantum gates and 3 times reduced parameters. Our source code is available and can be found in [1]</description>
  </item>

</channel>

</rss>
<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>Efficient realization of quantum primitives for Shor's algorithm using PennyLane library</title>
    <link>http://arxiv.org/pdf/2201.05426</link>
    <author>A.V. Antipov, E.O. Kiktenko, A.K. Fedorov</author>
    <pubDate>Jan 17 2022</pubDate>
    <description>Efficient realization of quantum algorithms is among main challenges on the way towards practical quantum computing. Various libraries and frameworks for quantum software engineering have been developed. Here we present a software package containing implementations of various quantum gates and well-known quantum algorithms using PennyLane library. Templates within the package include all required elements from the quantum part of Shor's algorithm, specifically, efficient modular exponentiation and quantum Fourier transform that can be realized for an arbitrary number of qubits specified by a user. All the qubit operations are decomposed into elementary gates realized in PennyLane library. Templates from the developed package can be used as qubit-operations when defining a QNode.</description>
  </item>

  <item>
    <title>Depth optimization of CZ, CNOT, and Clifford circuits</title>
    <link>http://arxiv.org/pdf/2201.05215</link>
    <author>Dmitri Maslov, Ben Zindorf</author>
    <pubDate>Jan 17 2022</pubDate>
    <description>We seek to develop better upper bound guarantees on the depth of quantum CZ gate, CNOT gate, and Clifford circuits than those reported previously. We focus on the number of qubits $n\,{\leq}\,$1,345,000 [1], which represents the most practical use case. Our upper bound on the depth of CZ circuits is $\lfloor n/2 + 0.4993{\cdot}\log^2(n) + 3.0191{\cdot}\log(n) - 10.9139\rfloor$, improving best known depth by a factor of roughly 2. We extend the constructions used to prove this upper bound to obtain depth upper bound of $\lfloor n + 1.9496{\cdot}\log^2(n) + 3.5075{\cdot}\log(n) - 23.4269 \rfloor$ for CNOT gate circuits, offering an improvement by a factor of roughly $4/3$ over state of the art, and depth upper bound of $\lfloor 2n + 2.9487{\cdot}\log^2(n) + 8.4909{\cdot}\log(n) - 44.4798\rfloor$ for Clifford circuits, offering an improvement by a factor of roughly $5/3$.</description>
  </item>

  <item>
    <title>When less is more: Simplifying inputs aids neural network understanding</title>
    <link>http://arxiv.org/pdf/2201.05610</link>
    <author>Robin Tibor Schirrmeister, Rosanne Liu, Sara Hooker, Tonio Ball</author>
    <pubDate>Jan 17 2022</pubDate>
    <description>How do neural network image classifiers respond to simpler and simpler inputs? And what do such responses reveal about the learning process? To answer these questions, we need a clear measure of input simplicity (or inversely, complexity), an optimization objective that correlates with simplification, and a framework to incorporate such objective into training and inference. Lastly we need a variety of testbeds to experiment and evaluate the impact of such simplification on learning. In this work, we measure simplicity with the encoding bit size given by a pretrained generative model, and minimize the bit size to simplify inputs in training and inference. We investigate the effect of such simplification in several scenarios: conventional training, dataset condensation and post-hoc explanations. In all settings, inputs are simplified along with the original classification task, and we investigate the trade-off between input simplicity and task performance. For images with injected distractors, such simplification naturally removes superfluous information. For dataset condensation, we find that inputs can be simplified with almost no accuracy degradation. When used in post-hoc explanation, our learning-based simplification approach offers a valuable new tool to explore the basis of network decisions.</description>
  </item>

  <item>
    <title>Multilingual Open Text 1.0: Public Domain News in 44 Languages</title>
    <link>http://arxiv.org/pdf/2201.05609</link>
    <author>Chester Palen-Michel, June Kim, Constantine Lignos</author>
    <pubDate>Jan 17 2022</pubDate>
    <description>We present a new multilingual corpus containing text in 44 languages, many of which have relatively few existing resources for natural language processing. The first release of the corpus contains over 2.7 million news articles and 1 million shorter passages published between 2001--2021, collected from Voice of America news websites. We describe our process for collecting, filtering, and processing the data. The source material is in the public domain, our collection is licensed using a creative commons license (CC BY 4.0), and all software used to create the corpus is released under the MIT License. The corpus will be regularly updated as additional documents are published.</description>
  </item>

  <item>
    <title>Energies for elastic plates and shells from quadratic-stretch elasticity</title>
    <link>http://arxiv.org/pdf/2201.05608</link>
    <author>E. Vitral, J. A. Hanna</author>
    <pubDate>Jan 17 2022</pubDate>
    <description>We derive stretching and bending energies for isotropic elastic plates and shells. Through the dimensional reduction of a bulk elastic energy quadratic in Biot strains, we obtain two-dimensional bending energies quadratic in bending measures featuring a bilinear coupling of stretches and geometric curvatures. For plates, the bending measure is invariant under spatial dilations and naturally extends primitive bending strains for straight rods. For shells or naturally-curved rods, the measure is not dilation invariant, and contrasts with previous \emphad hoc postulated forms. The corresponding field equations and boundary conditions feature moments linear in the bending measures, such that application of a pure moment results in isometric deformation of a unique neutral surface, a primitive behavior in agreement with classical linear response but not displayed by commonly used analytical models. We briefly comment on relations between our energies, those derived from a neo-Hookean bulk energy, and a commonly used discrete model for flat membranes. Although the derivation requires consideration of stretch and rotation fields, the resulting energy and field equations can be expressed entirely in terms of metric and curvature components of deformed and reference surfaces.</description>
  </item>

</channel>

</rss>
<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>Estimating Quantum Hamiltonians via Joint Measurements of Noisy Non-Commuting Observables</title>
    <link>http://arxiv.org/pdf/2206.08912</link>
    <author>Daniel McNulty, Filip B. Maciejewski, Michał Oszmaniec</author>
    <pubDate>Jun 20 2022</pubDate>
    <description>Estimation of expectation values of incompatible observables is an essential practical task in quantum computing, especially for approximating energies of chemical and other many-body quantum systems. In this work we introduce a method for this purpose based on performing a single joint measurement that can be implemented locally and whose marginals yield noisy (unsharp) versions of the target set of non-commuting Pauli observables. We derive bounds on the number of experimental repetitions required to estimate energies up to a certain precision. We compare this strategy to the classical shadow formalism and show that our method yields the same performance as the locally biased classical shadow protocol. We also highlight some general connections between the two approaches by showing that classical shadows can be used to construct joint measurements and vice versa. Finally, we adapt the joint measurement strategy to minimise the sample complexity when the implementation of measurements is assumed noisy. This can provide significant efficiency improvements compared to known generalisations of classical shadows to noisy scenarios.</description>
  </item>

  <item>
    <title>Quantum Simulation of Z2 Lattice Gauge theory with minimal requirements</title>
    <link>http://arxiv.org/pdf/2206.08909</link>
    <author>Reinis Irmejs, Mari Carmen Banuls, Juan Ignacio Cirac</author>
    <pubDate>Jun 20 2022</pubDate>
    <description>The quantum simulation of fermionic gauge field theories is one of the anticipated uses of quantum computers in the NISQ era. Recently work has been done to simulate properties of the fermionic Z2 gauge field theory in (1+1)D and the pure gauge theory in (2+1) D. In this work, we investigate various options for simulating the fermionic Z2 gauge field theory in (2+1) D. To simulate the theory on a NISQ device it is vital to minimize both the number of qubits used and the circuit depth. In this work we propose ways to optimize both criteria for simulating time dynamics. In particular, we develop a new way to simulate this theory on a quantum computer, with minimal qubit requirements. We provide a quantum circuit, simulating a single first order Trotter step, that minimizes the number of 2-qubit gates needed and gives comparable results to methods requiring more qubits. Furthermore, variational Trotterization approaches are investigated that allow to further decrease the circuit depth.</description>
  </item>

  <item>
    <title>Interior point methods are not worse than Simplex</title>
    <link>http://arxiv.org/pdf/2206.08810</link>
    <author>Xavier Allamigeon, Daniel Dadush, Georg Loho, Bento Natura, László A. Végh</author>
    <pubDate>Jun 20 2022</pubDate>
    <description>Whereas interior point methods provide polynomial-time linear programming algorithms, the running time bounds depend on bit-complexity or condition measures that can be unbounded in the problem dimension. This is in contrast with the simplex method that always admits an exponential bound. We introduce a new polynomial-time path-following interior point method where the number of iterations also admits a combinatorial upper bound $O(2^{n} n^{1.5}\log n)$ for an $n$-variable linear program in standard form. This complements previous work by Allamigeon, Benchimol, Gaubert, and Joswig (SIAGA 2018) that exhibited a family of instances where any path-following method must take exponentially many iterations. The number of iterations of our algorithm is at most $O(n^{1.5}\log n)$ times the number of segments of any piecewise linear curve in the wide neighborhood of the central path. In particular, it matches the number of iterations of any path following interior point method up to this polynomial factor. The overall exponential upper bound derives from studying the `max central path', a piecewise-linear curve with the number of pieces bounded by the total length of $2n$ shadow vertex simplex paths. Our algorithm falls into the family of layered least squares interior point methods introduced by Vavasis and Ye (Math. Prog. 1996). In contrast to previous layered least squares methods that partition the kernel of the constraint matrix into coordinate subspaces, our method creates layers based on a general subspace providing more flexibility. Our result also implies the same bound on the number of iterations of the trust region interior point method by Lan, Monteiro, and Tsuchiya (SIOPT 2009).</description>
  </item>

  <item>
    <title>The Topology and Geometry of Causality</title>
    <link>http://arxiv.org/pdf/2206.08911</link>
    <author>Stefano Gogioso, Nicola Pinzani</author>
    <pubDate>Jun 20 2022</pubDate>
    <description>We provide a unified operational framework for the study of causality, non-locality and contextuality, in a fully device-independent and theory-independent setting. Our investigation proceeds from two complementary fronts: a topological one, using tools from sheaf theory, and a geometric one, based on polytopes and linear programming. From the topological perspective, we understand experimental outcome probabilities as bundles of compatible contextual data over certain topological spaces, encoding causality constraints. From the geometric perspective, we understand the same experimental outcome probabilities as points in high-dimensional causal polytopes, which we explicitly construct and fully characterise. Our work is a significant extension of both the established Abramsky-Brandenburger framework for contextuality and the current body of work on indefinite causality. We provide definitions of causal fraction and causal separability for empirical models relative to a broad class of causal constraints: this allows us to construct and characterise novel examples which explicitly connect causal inseparability to non-locality and contextuality. In particular, we clearly demonstrate the existence of "causal contextuality", a phenomenon where causal structure is explicitly correlated to the classical inputs and outputs of local instruments, so that contextuality of the associated empirical model directly implies causal inseparability.</description>
  </item>

  <item>
    <title>Popular decision tree algorithms are provably noise tolerant</title>
    <link>http://arxiv.org/pdf/2206.08899</link>
    <author>Guy Blanc, Jane Lange, Ali Malik, Li-Yang Tan</author>
    <pubDate>Jun 20 2022</pubDate>
    <description>Using the framework of boosting, we prove that all impurity-based decision tree learning algorithms, including the classic ID3, C4.5, and CART, are highly noise tolerant. Our guarantees hold under the strongest noise model of nasty noise, and we provide near-matching upper and lower bounds on the allowable noise rate. We further show that these algorithms, which are simple and have long been central to everyday machine learning, enjoy provable guarantees in the noisy setting that are unmatched by existing algorithms in the theoretical literature on decision tree learning. Taken together, our results add to an ongoing line of research that seeks to place the empirical success of these practical decision tree algorithms on firm theoretical footing.</description>
  </item>

</channel>

</rss>
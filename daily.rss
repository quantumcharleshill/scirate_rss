<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Top Scirate Papers</title>
  <link>https://www.scirate.com</link>
  <description>The feed lists the top "scited" papers on the scirate website, often featuring the most widely appreciated quantum physics (quant-ph) preprints.</description>

  <item>
    <title>Improved machine learning algorithm for predicting ground state properties</title>
    <link>http://arxiv.org/pdf/2301.13169</link>
    <author>Laura Lewis, Hsin-Yuan Huang, Viet T. Tran, Sebastian Lehner, Richard Kueng, John Preskill</author>
    <pubDate>Jan 31 2023</pubDate>
    <description>Finding the ground state of a quantum many-body system is a fundamental problem in quantum physics. In this work, we give a classical machine learning (ML) algorithm for predicting ground state properties with an inductive bias encoding geometric locality. The proposed ML model can efficiently predict ground state properties of an $n$-qubit gapped local Hamiltonian after learning from only $\mathcal{O}(\log(n))$ data about other Hamiltonians in the same quantum phase of matter. This improves substantially upon previous results that require $\mathcal{O}(n^c)$ data for a large constant $c$. Furthermore, the training and prediction time of the proposed ML model scale as $\mathcal{O}(n \log n)$ in the number of qubits $n$. Numerical experiments on physical systems with up to 45 qubits confirm the favorable scaling in predicting ground state properties using a small training dataset.</description>
  </item>

  <item>
    <title>Efficient learning of ground & thermal states within phases of matter</title>
    <link>http://arxiv.org/pdf/2301.12946</link>
    <author>Emilio Onorati, Cambyse Rouzé, Daniel Stilck França, James D. Watson</author>
    <pubDate>Jan 31 2023</pubDate>
    <description>We consider two related tasks: (a) estimating a parameterisation of a given Gibbs state and expectation values of Lipschitz observables on this state; and (b) learning the expectation values of local observables within a thermal or quantum phase of matter. In both cases, we wish to minimise the number of samples we use to learn these properties to a given precision. For the first task, we develop new techniques to learn parameterisations of classes of systems, including quantum Gibbs states of non-commuting Hamiltonians with exponential decay of correlations and the approximate Markov property. We show it is possible to infer the expectation values of all extensive properties of the state from a number of copies that not only scales polylogarithmically with the system size, but polynomially in the observable's locality -- an exponential improvement. This set of properties includes expected values of quasi-local observables and entropies. For the second task, we develop efficient algorithms for learning observables in a phase of matter of a quantum system. By exploiting the locality of the Hamiltonian, we show that $M$ local observables can be learned with probability $1-\delta$ to precision $\epsilon$ with using only $N=O\big(\log\big(\frac{M}{\delta}\big)e^{polylog(\epsilon^{-1})}\big)$ samples -- an exponential improvement on the precision over previous bounds. Our results apply to both families of ground states of Hamiltonians displaying local topological quantum order, and thermal phases of matter with exponential decay of correlations. In addition, our sample complexity applies to the worse case setting whereas previous results only applied on average. Furthermore, we develop tools of independent interest, such as robust shadow tomography algorithms, Gibbs approximations to ground states, and generalisations of transportation cost inequalities for Gibbs states.</description>
  </item>

  <item>
    <title>State polynomials: positivity, optimization and nonlinear Bell inequalities</title>
    <link>http://arxiv.org/pdf/2301.12513</link>
    <author>Igor Klep, Victor Magron, Jurij Volčič, Jie Wang</author>
    <pubDate>Jan 31 2023</pubDate>
    <description>This paper introduces state polynomials, i.e., polynomials in noncommuting variables and formal states of their products. A state analog of Artin's solution to Hilbert's 17th problem is proved showing that state polynomials, positive over all matrices and matricial states, are sums of squares with denominators. Somewhat surprisingly, it is also established that a Krivine-Stengle Positivstellensatz fails to hold in the state polynomial setting. Further, archimedean Positivstellensätze in the spirit of Putinar and Helton-McCullough are presented leading to a hierarchy of semidefinite relaxations converging monotonically to the optimum of a state polynomial subject to state constraints. This hierarchy can be seen as a state analog of the Lasserre hierarchy for optimization of polynomials, and the Navascués-Pironio-Acín scheme for optimization of noncommutative polynomials. The motivation behind this theory arises from the study of correlations in quantum networks. Determining the maximal quantum violation of a polynomial Bell inequality for an arbitrary network is reformulated as a state polynomial optimization problem. Several examples of quadratic Bell inequalities in the bipartite and the bilocal tripartite scenario are analyzed. To reduce the size of the constructed SDPs, sparsity, sign symmetry and conditional expectation of the observables' group structure are exploited. To obtain the above-mentioned results, techniques from noncommutative algebra, real algebraic geometry, operator theory, and convex optimization are employed.</description>
  </item>

  <item>
    <title>How universal is the relation between sign problem and phase transition</title>
    <link>http://arxiv.org/pdf/2301.12438</link>
    <author>Zheng Yan, Jun-Song Sun, Gaopei Pan, Chen Cheng, Nvsen Ma</author>
    <pubDate>Jan 31 2023</pubDate>
    <description>The mystery of the infamous sign problem in quantum Monte Carlo simulations mightily restricts applications of the method in fermionic and frustrated systems. A recent work [Science \textbf375, 417 (2022)] made a remarkable breakthrough in the sign problem and suggested a positive connection between the sign and phase transition. How general this argument is can be crucial in various fields related to many-body systems, such as condensed matter physics, quantum chemistry, and nuclear physics. Based on universal analyses of typical examples and numerical simulations from different approaches, we discuss when and how studying the sign can provide helpful information on phase transitions in general systems independent of specific models and algorithms. While our results support that the notorious sign offers new angles in exploring quantum many-body problems, we also notice that taking advantage of the sign can even be as challenging as neutralizing the sign problem itself in unknown systems.</description>
  </item>

  <item>
    <title>Quantum Ridgelet Transform: Winning Lottery Ticket of Neural Networks with Quantum Computation</title>
    <link>http://arxiv.org/pdf/2301.11936</link>
    <author>Hayata Yamasaki, Sathyawageeswar Subramanian, Satoshi Hayakawa, Sho Sonoda</author>
    <pubDate>Jan 31 2023</pubDate>
    <description>Ridgelet transform has been a fundamental mathematical tool in the theoretical studies of neural networks. However, the practical applicability of ridgelet transform to conducting learning tasks was limited since its numerical implementation by conventional classical computation requires an exponential runtime $\exp(O(D))$ as data dimension $D$ increases. To address this problem, we develop a quantum ridgelet transform (QRT), which implements the ridgelet transform of a quantum state within a linear runtime $O(D)$ of quantum computation. As an application, we also show that one can use QRT as a fundamental subroutine for quantum machine learning (QML) to efficiently find a sparse trainable subnetwork of large shallow wide neural networks without conducting large-scale optimization of the original network. This application discovers an efficient way in this regime to demonstrate the lottery ticket hypothesis on finding such a sparse trainable neural network. These results open an avenue of QML for accelerating learning tasks with commonly used classical neural networks.</description>
  </item>

</channel>

</rss>